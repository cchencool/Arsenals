[0328 17:17:01 754 INFO ] [MLog-Init-Reporter] v2.log.MLog - MLog clients using slf4j logging.
[0328 17:17:01 973 INFO ] [main] v2.c3p0.C3P0Registry - Initializing c3p0-0.9.5.2 [built 08-December-2015 22:06:04 -0800; debug? true; trace: 10]
[0328 17:17:02 142 INFO ] [main] pmv6.dao.HiveDao - start to execute the sql :insert into test_table_double values (20180329, 010000, 77.12866255934544)
[0328 17:17:02 170 INFO ] [main] c3p0.impl.AbstractPoolBackedDataSource - Initializing c3p0 pool... com.mchange.v2.c3p0.ComboPooledDataSource [ acquireIncrement -> 1, acquireRetryAttempts -> 30, acquireRetryDelay -> 1000, autoCommitOnClose -> false, automaticTestTable -> null, breakAfterAcquireFailure -> false, checkoutTimeout -> 0, connectionCustomizerClassName -> null, connectionTesterClassName -> com.mchange.v2.c3p0.impl.DefaultConnectionTester, contextClassLoaderSource -> caller, dataSourceName -> 1hge0w29utxqujs1u4qdp4|80ec1f8, debugUnreturnedConnectionStackTraces -> false, description -> null, driverClass -> org.apache.hive.jdbc.HiveDriver, extensions -> {}, factoryClassLocation -> null, forceIgnoreUnresolvedTransactions -> false, forceSynchronousCheckins -> false, forceUseNamedDriverClass -> false, identityToken -> 1hge0w29utxqujs1u4qdp4|80ec1f8, idleConnectionTestPeriod -> 0, initialPoolSize -> 3, jdbcUrl -> jdbc:hive2://10.211.55.29:10000/default, maxAdministrativeTaskTime -> 0, maxConnectionAge -> 0, maxIdleTime -> 0, maxIdleTimeExcessConnections -> 0, maxPoolSize -> 2, maxStatements -> 0, maxStatementsPerConnection -> 0, minPoolSize -> 1, numHelperThreads -> 3, preferredTestQuery -> null, privilegeSpawnedThreads -> false, properties -> {user=******, password=******}, propertyCycle -> 0, statementCacheNumDeferredCloseThreads -> 0, testConnectionOnCheckin -> false, testConnectionOnCheckout -> false, unreturnedConnectionTimeout -> 0, userOverrides -> {}, usesTraditionalReflectiveProxies -> false ]
[0328 17:17:02 213 WARN ] [main] v2.resourcepool.BasicResourcePool - Bad pool size config, start 3 > max 2. Using 2 as start.
[0328 17:17:02 238 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29utxqujs1u4qdp4|80ec1f8]-HelperThread-#2] hive.jdbc.Utils - Supplied authorities: 10.211.55.29:10000
[0328 17:17:02 238 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29utxqujs1u4qdp4|80ec1f8]-HelperThread-#1] hive.jdbc.Utils - Supplied authorities: 10.211.55.29:10000
[0328 17:17:02 238 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29utxqujs1u4qdp4|80ec1f8]-HelperThread-#2] hive.jdbc.Utils - Resolved authority: 10.211.55.29:10000
[0328 17:17:02 238 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29utxqujs1u4qdp4|80ec1f8]-HelperThread-#1] hive.jdbc.Utils - Resolved authority: 10.211.55.29:10000
[0328 17:17:02 331 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29utxqujs1u4qdp4|80ec1f8]-HelperThread-#1] hive.jdbc.HiveConnection - Will try to open client transport with JDBC Uri: jdbc:hive2://10.211.55.29:10000/default
[0328 17:17:02 331 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29utxqujs1u4qdp4|80ec1f8]-HelperThread-#2] hive.jdbc.HiveConnection - Will try to open client transport with JDBC Uri: jdbc:hive2://10.211.55.29:10000/default
[0328 17:17:02 433 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29utxqujs1u4qdp4|80ec1f8]-HelperThread-#2] hive.jdbc.HiveConnection - Could not open client transport with JDBC Uri: jdbc:hive2://10.211.55.29:10000/default
[0328 17:17:02 434 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29utxqujs1u4qdp4|80ec1f8]-HelperThread-#2] hive.jdbc.HiveConnection - Transport Used for JDBC connection: null
[0328 17:17:02 434 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29utxqujs1u4qdp4|80ec1f8]-HelperThread-#1] hive.jdbc.HiveConnection - Could not open client transport with JDBC Uri: jdbc:hive2://10.211.55.29:10000/default
[0328 17:17:02 434 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29utxqujs1u4qdp4|80ec1f8]-HelperThread-#1] hive.jdbc.HiveConnection - Transport Used for JDBC connection: null
[0328 17:17:03 439 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29utxqujs1u4qdp4|80ec1f8]-HelperThread-#1] hive.jdbc.Utils - Supplied authorities: 10.211.55.29:10000
[0328 17:17:03 439 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29utxqujs1u4qdp4|80ec1f8]-HelperThread-#1] hive.jdbc.Utils - Resolved authority: 10.211.55.29:10000
[0328 17:17:03 440 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29utxqujs1u4qdp4|80ec1f8]-HelperThread-#2] hive.jdbc.Utils - Supplied authorities: 10.211.55.29:10000
[0328 17:17:03 440 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29utxqujs1u4qdp4|80ec1f8]-HelperThread-#1] hive.jdbc.HiveConnection - Will try to open client transport with JDBC Uri: jdbc:hive2://10.211.55.29:10000/default
[0328 17:17:03 440 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29utxqujs1u4qdp4|80ec1f8]-HelperThread-#2] hive.jdbc.Utils - Resolved authority: 10.211.55.29:10000
[0328 17:17:03 441 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29utxqujs1u4qdp4|80ec1f8]-HelperThread-#2] hive.jdbc.HiveConnection - Will try to open client transport with JDBC Uri: jdbc:hive2://10.211.55.29:10000/default
[0328 17:17:03 541 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29utxqujs1u4qdp4|80ec1f8]-HelperThread-#1] hive.jdbc.HiveConnection - Could not open client transport with JDBC Uri: jdbc:hive2://10.211.55.29:10000/default
[0328 17:17:03 542 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29utxqujs1u4qdp4|80ec1f8]-HelperThread-#1] hive.jdbc.HiveConnection - Transport Used for JDBC connection: null
[0328 17:17:03 543 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29utxqujs1u4qdp4|80ec1f8]-HelperThread-#2] hive.jdbc.HiveConnection - Could not open client transport with JDBC Uri: jdbc:hive2://10.211.55.29:10000/default
[0328 17:17:03 543 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29utxqujs1u4qdp4|80ec1f8]-HelperThread-#2] hive.jdbc.HiveConnection - Transport Used for JDBC connection: null
[0328 17:17:04 546 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29utxqujs1u4qdp4|80ec1f8]-HelperThread-#2] hive.jdbc.Utils - Supplied authorities: 10.211.55.29:10000
[0328 17:17:04 546 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29utxqujs1u4qdp4|80ec1f8]-HelperThread-#1] hive.jdbc.Utils - Supplied authorities: 10.211.55.29:10000
[0328 17:17:04 546 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29utxqujs1u4qdp4|80ec1f8]-HelperThread-#2] hive.jdbc.Utils - Resolved authority: 10.211.55.29:10000
[0328 17:17:04 547 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29utxqujs1u4qdp4|80ec1f8]-HelperThread-#1] hive.jdbc.Utils - Resolved authority: 10.211.55.29:10000
[0328 17:17:04 548 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29utxqujs1u4qdp4|80ec1f8]-HelperThread-#2] hive.jdbc.HiveConnection - Will try to open client transport with JDBC Uri: jdbc:hive2://10.211.55.29:10000/default
[0328 17:17:04 548 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29utxqujs1u4qdp4|80ec1f8]-HelperThread-#1] hive.jdbc.HiveConnection - Will try to open client transport with JDBC Uri: jdbc:hive2://10.211.55.29:10000/default
[0328 17:17:04 648 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29utxqujs1u4qdp4|80ec1f8]-HelperThread-#2] hive.jdbc.HiveConnection - Could not open client transport with JDBC Uri: jdbc:hive2://10.211.55.29:10000/default
[0328 17:17:04 649 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29utxqujs1u4qdp4|80ec1f8]-HelperThread-#2] hive.jdbc.HiveConnection - Transport Used for JDBC connection: null
[0328 17:17:04 650 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29utxqujs1u4qdp4|80ec1f8]-HelperThread-#1] hive.jdbc.HiveConnection - Could not open client transport with JDBC Uri: jdbc:hive2://10.211.55.29:10000/default
[0328 17:17:04 650 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29utxqujs1u4qdp4|80ec1f8]-HelperThread-#1] hive.jdbc.HiveConnection - Transport Used for JDBC connection: null
[0328 17:17:05 654 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29utxqujs1u4qdp4|80ec1f8]-HelperThread-#1] hive.jdbc.Utils - Supplied authorities: 10.211.55.29:10000
[0328 17:17:05 654 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29utxqujs1u4qdp4|80ec1f8]-HelperThread-#2] hive.jdbc.Utils - Supplied authorities: 10.211.55.29:10000
[0328 17:17:05 654 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29utxqujs1u4qdp4|80ec1f8]-HelperThread-#1] hive.jdbc.Utils - Resolved authority: 10.211.55.29:10000
[0328 17:17:05 654 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29utxqujs1u4qdp4|80ec1f8]-HelperThread-#2] hive.jdbc.Utils - Resolved authority: 10.211.55.29:10000
[0328 17:17:05 655 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29utxqujs1u4qdp4|80ec1f8]-HelperThread-#1] hive.jdbc.HiveConnection - Will try to open client transport with JDBC Uri: jdbc:hive2://10.211.55.29:10000/default
[0328 17:17:05 655 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29utxqujs1u4qdp4|80ec1f8]-HelperThread-#2] hive.jdbc.HiveConnection - Will try to open client transport with JDBC Uri: jdbc:hive2://10.211.55.29:10000/default
[0328 17:17:05 756 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29utxqujs1u4qdp4|80ec1f8]-HelperThread-#2] hive.jdbc.HiveConnection - Could not open client transport with JDBC Uri: jdbc:hive2://10.211.55.29:10000/default
[0328 17:17:05 756 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29utxqujs1u4qdp4|80ec1f8]-HelperThread-#1] hive.jdbc.HiveConnection - Could not open client transport with JDBC Uri: jdbc:hive2://10.211.55.29:10000/default
[0328 17:17:05 756 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29utxqujs1u4qdp4|80ec1f8]-HelperThread-#2] hive.jdbc.HiveConnection - Transport Used for JDBC connection: null
[0328 17:17:05 756 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29utxqujs1u4qdp4|80ec1f8]-HelperThread-#1] hive.jdbc.HiveConnection - Transport Used for JDBC connection: null
[0328 17:17:06 760 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29utxqujs1u4qdp4|80ec1f8]-HelperThread-#0] hive.jdbc.Utils - Supplied authorities: 10.211.55.29:10000
[0328 17:17:06 760 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29utxqujs1u4qdp4|80ec1f8]-HelperThread-#1] hive.jdbc.Utils - Supplied authorities: 10.211.55.29:10000
[0328 17:17:06 761 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29utxqujs1u4qdp4|80ec1f8]-HelperThread-#0] hive.jdbc.Utils - Resolved authority: 10.211.55.29:10000
[0328 17:17:06 761 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29utxqujs1u4qdp4|80ec1f8]-HelperThread-#1] hive.jdbc.Utils - Resolved authority: 10.211.55.29:10000
[0328 17:17:06 761 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29utxqujs1u4qdp4|80ec1f8]-HelperThread-#0] hive.jdbc.HiveConnection - Will try to open client transport with JDBC Uri: jdbc:hive2://10.211.55.29:10000/default
[0328 17:17:06 761 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29utxqujs1u4qdp4|80ec1f8]-HelperThread-#1] hive.jdbc.HiveConnection - Will try to open client transport with JDBC Uri: jdbc:hive2://10.211.55.29:10000/default
[0328 17:17:06 862 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29utxqujs1u4qdp4|80ec1f8]-HelperThread-#0] hive.jdbc.HiveConnection - Could not open client transport with JDBC Uri: jdbc:hive2://10.211.55.29:10000/default
[0328 17:17:06 862 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29utxqujs1u4qdp4|80ec1f8]-HelperThread-#1] hive.jdbc.HiveConnection - Could not open client transport with JDBC Uri: jdbc:hive2://10.211.55.29:10000/default
[0328 17:17:06 862 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29utxqujs1u4qdp4|80ec1f8]-HelperThread-#0] hive.jdbc.HiveConnection - Transport Used for JDBC connection: null
[0328 17:17:06 862 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29utxqujs1u4qdp4|80ec1f8]-HelperThread-#1] hive.jdbc.HiveConnection - Transport Used for JDBC connection: null
[0328 17:17:07 868 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29utxqujs1u4qdp4|80ec1f8]-HelperThread-#1] hive.jdbc.Utils - Supplied authorities: 10.211.55.29:10000
[0328 17:17:07 868 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29utxqujs1u4qdp4|80ec1f8]-HelperThread-#0] hive.jdbc.Utils - Supplied authorities: 10.211.55.29:10000
[0328 17:17:07 869 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29utxqujs1u4qdp4|80ec1f8]-HelperThread-#1] hive.jdbc.Utils - Resolved authority: 10.211.55.29:10000
[0328 17:17:07 869 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29utxqujs1u4qdp4|80ec1f8]-HelperThread-#0] hive.jdbc.Utils - Resolved authority: 10.211.55.29:10000
[0328 17:17:07 869 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29utxqujs1u4qdp4|80ec1f8]-HelperThread-#1] hive.jdbc.HiveConnection - Will try to open client transport with JDBC Uri: jdbc:hive2://10.211.55.29:10000/default
[0328 17:17:07 869 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29utxqujs1u4qdp4|80ec1f8]-HelperThread-#0] hive.jdbc.HiveConnection - Will try to open client transport with JDBC Uri: jdbc:hive2://10.211.55.29:10000/default
[0328 17:17:07 971 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29utxqujs1u4qdp4|80ec1f8]-HelperThread-#1] hive.jdbc.HiveConnection - Could not open client transport with JDBC Uri: jdbc:hive2://10.211.55.29:10000/default
[0328 17:17:07 971 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29utxqujs1u4qdp4|80ec1f8]-HelperThread-#0] hive.jdbc.HiveConnection - Could not open client transport with JDBC Uri: jdbc:hive2://10.211.55.29:10000/default
[0328 17:17:07 972 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29utxqujs1u4qdp4|80ec1f8]-HelperThread-#1] hive.jdbc.HiveConnection - Transport Used for JDBC connection: null
[0328 17:17:07 972 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29utxqujs1u4qdp4|80ec1f8]-HelperThread-#0] hive.jdbc.HiveConnection - Transport Used for JDBC connection: null
[0328 17:17:08 975 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29utxqujs1u4qdp4|80ec1f8]-HelperThread-#0] hive.jdbc.Utils - Supplied authorities: 10.211.55.29:10000
[0328 17:17:08 975 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29utxqujs1u4qdp4|80ec1f8]-HelperThread-#1] hive.jdbc.Utils - Supplied authorities: 10.211.55.29:10000
[0328 17:17:08 975 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29utxqujs1u4qdp4|80ec1f8]-HelperThread-#0] hive.jdbc.Utils - Resolved authority: 10.211.55.29:10000
[0328 17:17:08 976 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29utxqujs1u4qdp4|80ec1f8]-HelperThread-#1] hive.jdbc.Utils - Resolved authority: 10.211.55.29:10000
[0328 17:17:08 976 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29utxqujs1u4qdp4|80ec1f8]-HelperThread-#0] hive.jdbc.HiveConnection - Will try to open client transport with JDBC Uri: jdbc:hive2://10.211.55.29:10000/default
[0328 17:17:08 976 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29utxqujs1u4qdp4|80ec1f8]-HelperThread-#1] hive.jdbc.HiveConnection - Will try to open client transport with JDBC Uri: jdbc:hive2://10.211.55.29:10000/default
[0328 17:17:09 077 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29utxqujs1u4qdp4|80ec1f8]-HelperThread-#1] hive.jdbc.HiveConnection - Could not open client transport with JDBC Uri: jdbc:hive2://10.211.55.29:10000/default
[0328 17:17:09 077 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29utxqujs1u4qdp4|80ec1f8]-HelperThread-#0] hive.jdbc.HiveConnection - Could not open client transport with JDBC Uri: jdbc:hive2://10.211.55.29:10000/default
[0328 17:17:09 077 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29utxqujs1u4qdp4|80ec1f8]-HelperThread-#1] hive.jdbc.HiveConnection - Transport Used for JDBC connection: null
[0328 17:17:09 078 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29utxqujs1u4qdp4|80ec1f8]-HelperThread-#0] hive.jdbc.HiveConnection - Transport Used for JDBC connection: null
[0328 17:17:10 083 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29utxqujs1u4qdp4|80ec1f8]-HelperThread-#1] hive.jdbc.Utils - Supplied authorities: 10.211.55.29:10000
[0328 17:17:10 083 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29utxqujs1u4qdp4|80ec1f8]-HelperThread-#0] hive.jdbc.Utils - Supplied authorities: 10.211.55.29:10000
[0328 17:17:10 084 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29utxqujs1u4qdp4|80ec1f8]-HelperThread-#1] hive.jdbc.Utils - Resolved authority: 10.211.55.29:10000
[0328 17:17:10 084 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29utxqujs1u4qdp4|80ec1f8]-HelperThread-#0] hive.jdbc.Utils - Resolved authority: 10.211.55.29:10000
[0328 17:17:10 085 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29utxqujs1u4qdp4|80ec1f8]-HelperThread-#1] hive.jdbc.HiveConnection - Will try to open client transport with JDBC Uri: jdbc:hive2://10.211.55.29:10000/default
[0328 17:17:10 085 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29utxqujs1u4qdp4|80ec1f8]-HelperThread-#0] hive.jdbc.HiveConnection - Will try to open client transport with JDBC Uri: jdbc:hive2://10.211.55.29:10000/default
[0328 17:17:10 186 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29utxqujs1u4qdp4|80ec1f8]-HelperThread-#0] hive.jdbc.HiveConnection - Could not open client transport with JDBC Uri: jdbc:hive2://10.211.55.29:10000/default
[0328 17:17:10 186 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29utxqujs1u4qdp4|80ec1f8]-HelperThread-#1] hive.jdbc.HiveConnection - Could not open client transport with JDBC Uri: jdbc:hive2://10.211.55.29:10000/default
[0328 17:17:10 187 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29utxqujs1u4qdp4|80ec1f8]-HelperThread-#0] hive.jdbc.HiveConnection - Transport Used for JDBC connection: null
[0328 17:17:10 187 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29utxqujs1u4qdp4|80ec1f8]-HelperThread-#1] hive.jdbc.HiveConnection - Transport Used for JDBC connection: null
[0328 17:17:11 191 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29utxqujs1u4qdp4|80ec1f8]-HelperThread-#1] hive.jdbc.Utils - Supplied authorities: 10.211.55.29:10000
[0328 17:17:11 192 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29utxqujs1u4qdp4|80ec1f8]-HelperThread-#1] hive.jdbc.Utils - Resolved authority: 10.211.55.29:10000
[0328 17:17:11 191 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29utxqujs1u4qdp4|80ec1f8]-HelperThread-#0] hive.jdbc.Utils - Supplied authorities: 10.211.55.29:10000
[0328 17:17:11 193 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29utxqujs1u4qdp4|80ec1f8]-HelperThread-#0] hive.jdbc.Utils - Resolved authority: 10.211.55.29:10000
[0328 17:17:11 195 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29utxqujs1u4qdp4|80ec1f8]-HelperThread-#1] hive.jdbc.HiveConnection - Will try to open client transport with JDBC Uri: jdbc:hive2://10.211.55.29:10000/default
[0328 17:17:11 195 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29utxqujs1u4qdp4|80ec1f8]-HelperThread-#0] hive.jdbc.HiveConnection - Will try to open client transport with JDBC Uri: jdbc:hive2://10.211.55.29:10000/default
[0328 17:17:11 296 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29utxqujs1u4qdp4|80ec1f8]-HelperThread-#1] hive.jdbc.HiveConnection - Could not open client transport with JDBC Uri: jdbc:hive2://10.211.55.29:10000/default
[0328 17:17:11 296 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29utxqujs1u4qdp4|80ec1f8]-HelperThread-#0] hive.jdbc.HiveConnection - Could not open client transport with JDBC Uri: jdbc:hive2://10.211.55.29:10000/default
[0328 17:17:11 296 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29utxqujs1u4qdp4|80ec1f8]-HelperThread-#1] hive.jdbc.HiveConnection - Transport Used for JDBC connection: null
[0328 17:17:11 296 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29utxqujs1u4qdp4|80ec1f8]-HelperThread-#0] hive.jdbc.HiveConnection - Transport Used for JDBC connection: null
[0328 17:17:12 301 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29utxqujs1u4qdp4|80ec1f8]-HelperThread-#0] hive.jdbc.Utils - Supplied authorities: 10.211.55.29:10000
[0328 17:17:12 301 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29utxqujs1u4qdp4|80ec1f8]-HelperThread-#2] hive.jdbc.Utils - Supplied authorities: 10.211.55.29:10000
[0328 17:17:12 301 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29utxqujs1u4qdp4|80ec1f8]-HelperThread-#0] hive.jdbc.Utils - Resolved authority: 10.211.55.29:10000
[0328 17:17:12 301 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29utxqujs1u4qdp4|80ec1f8]-HelperThread-#2] hive.jdbc.Utils - Resolved authority: 10.211.55.29:10000
[0328 17:17:12 302 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29utxqujs1u4qdp4|80ec1f8]-HelperThread-#0] hive.jdbc.HiveConnection - Will try to open client transport with JDBC Uri: jdbc:hive2://10.211.55.29:10000/default
[0328 17:17:12 302 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29utxqujs1u4qdp4|80ec1f8]-HelperThread-#2] hive.jdbc.HiveConnection - Will try to open client transport with JDBC Uri: jdbc:hive2://10.211.55.29:10000/default
[0328 17:17:12 403 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29utxqujs1u4qdp4|80ec1f8]-HelperThread-#0] hive.jdbc.HiveConnection - Could not open client transport with JDBC Uri: jdbc:hive2://10.211.55.29:10000/default
[0328 17:17:12 403 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29utxqujs1u4qdp4|80ec1f8]-HelperThread-#2] hive.jdbc.HiveConnection - Could not open client transport with JDBC Uri: jdbc:hive2://10.211.55.29:10000/default
[0328 17:17:12 403 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29utxqujs1u4qdp4|80ec1f8]-HelperThread-#0] hive.jdbc.HiveConnection - Transport Used for JDBC connection: null
[0328 17:17:12 403 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29utxqujs1u4qdp4|80ec1f8]-HelperThread-#2] hive.jdbc.HiveConnection - Transport Used for JDBC connection: null
[0328 17:17:48 244 INFO ] [MLog-Init-Reporter] v2.log.MLog - MLog clients using slf4j logging.
[0328 17:17:48 721 INFO ] [main] v2.c3p0.C3P0Registry - Initializing c3p0-0.9.5.2 [built 08-December-2015 22:06:04 -0800; debug? true; trace: 10]
[0328 17:17:48 889 INFO ] [main] pmv6.dao.HiveDao - start to execute the sql :insert into test_table_double values (20180329, 010000, 61.64295145450528)
[0328 17:17:48 922 INFO ] [main] c3p0.impl.AbstractPoolBackedDataSource - Initializing c3p0 pool... com.mchange.v2.c3p0.ComboPooledDataSource [ acquireIncrement -> 1, acquireRetryAttempts -> 30, acquireRetryDelay -> 1000, autoCommitOnClose -> false, automaticTestTable -> null, breakAfterAcquireFailure -> false, checkoutTimeout -> 0, connectionCustomizerClassName -> null, connectionTesterClassName -> com.mchange.v2.c3p0.impl.DefaultConnectionTester, contextClassLoaderSource -> caller, dataSourceName -> 1hge0w29utxrumz1kq9f8v|80ec1f8, debugUnreturnedConnectionStackTraces -> false, description -> null, driverClass -> org.apache.hive.jdbc.HiveDriver, extensions -> {}, factoryClassLocation -> null, forceIgnoreUnresolvedTransactions -> false, forceSynchronousCheckins -> false, forceUseNamedDriverClass -> false, identityToken -> 1hge0w29utxrumz1kq9f8v|80ec1f8, idleConnectionTestPeriod -> 0, initialPoolSize -> 3, jdbcUrl -> jdbc:hive2://10.211.55.29:10000/default, maxAdministrativeTaskTime -> 0, maxConnectionAge -> 0, maxIdleTime -> 0, maxIdleTimeExcessConnections -> 0, maxPoolSize -> 2, maxStatements -> 0, maxStatementsPerConnection -> 0, minPoolSize -> 1, numHelperThreads -> 3, preferredTestQuery -> null, privilegeSpawnedThreads -> false, properties -> {user=******, password=******}, propertyCycle -> 0, statementCacheNumDeferredCloseThreads -> 0, testConnectionOnCheckin -> false, testConnectionOnCheckout -> false, unreturnedConnectionTimeout -> 0, userOverrides -> {}, usesTraditionalReflectiveProxies -> false ]
[0328 17:17:48 973 WARN ] [main] v2.resourcepool.BasicResourcePool - Bad pool size config, start 3 > max 2. Using 2 as start.
[0328 17:17:48 995 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29utxrumz1kq9f8v|80ec1f8]-HelperThread-#2] hive.jdbc.Utils - Supplied authorities: 10.211.55.29:10000
[0328 17:17:48 995 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29utxrumz1kq9f8v|80ec1f8]-HelperThread-#1] hive.jdbc.Utils - Supplied authorities: 10.211.55.29:10000
[0328 17:17:48 996 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29utxrumz1kq9f8v|80ec1f8]-HelperThread-#1] hive.jdbc.Utils - Resolved authority: 10.211.55.29:10000
[0328 17:17:48 996 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29utxrumz1kq9f8v|80ec1f8]-HelperThread-#2] hive.jdbc.Utils - Resolved authority: 10.211.55.29:10000
[0328 17:17:49 070 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29utxrumz1kq9f8v|80ec1f8]-HelperThread-#1] hive.jdbc.HiveConnection - Will try to open client transport with JDBC Uri: jdbc:hive2://10.211.55.29:10000/default
[0328 17:17:49 071 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29utxrumz1kq9f8v|80ec1f8]-HelperThread-#2] hive.jdbc.HiveConnection - Will try to open client transport with JDBC Uri: jdbc:hive2://10.211.55.29:10000/default
[0328 17:17:52 178 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29utxrumz1kq9f8v|80ec1f8]-HelperThread-#2] hive.jdbc.Utils - Supplied authorities: 10.211.55.29:10000
[0328 17:17:52 178 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29utxrumz1kq9f8v|80ec1f8]-HelperThread-#2] hive.jdbc.Utils - Resolved authority: 10.211.55.29:10000
[0328 17:17:52 179 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29utxrumz1kq9f8v|80ec1f8]-HelperThread-#2] hive.jdbc.HiveConnection - Will try to open client transport with JDBC Uri: jdbc:hive2://10.211.55.29:10000/default
[0328 17:17:52 179 ERROR] [main] pmv6.dao.HiveDao - ERROR SQL: insert into test_table_double values (20180329, 010000, 61.64295145450528)
[0328 17:17:52 179 ERROR] [main] pmv6.dao.HiveDao - java.lang.RuntimeException: Cannot create staging directory 'hdfs://localhost:9000/home/chen/hive/warehouse/test_table_double/.hive-staging_hive_2018-03-28_02-17-51_963_4651877234833669940-1': Permission denied: user=hive, access=WRITE, inode="/home/chen/hive/warehouse/test_table_double":chen:supergroup:drwxr-xr-x
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.check(FSPermissionChecker.java:308)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:214)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:190)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkPermission(FSDirectory.java:1752)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkPermission(FSDirectory.java:1736)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkAncestorAccess(FSDirectory.java:1719)
	at org.apache.hadoop.hdfs.server.namenode.FSDirMkdirOp.mkdirs(FSDirMkdirOp.java:69)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.mkdirs(FSNamesystem.java:3867)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.mkdirs(NameNodeRpcServer.java:984)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.mkdirs(ClientNamenodeProtocolServerSideTranslatorPB.java:634)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:616)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:982)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2217)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2213)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1754)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2213)

java.sql.SQLException: java.lang.RuntimeException: Cannot create staging directory 'hdfs://localhost:9000/home/chen/hive/warehouse/test_table_double/.hive-staging_hive_2018-03-28_02-17-51_963_4651877234833669940-1': Permission denied: user=hive, access=WRITE, inode="/home/chen/hive/warehouse/test_table_double":chen:supergroup:drwxr-xr-x
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.check(FSPermissionChecker.java:308)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:214)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:190)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkPermission(FSDirectory.java:1752)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkPermission(FSDirectory.java:1736)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkAncestorAccess(FSDirectory.java:1719)
	at org.apache.hadoop.hdfs.server.namenode.FSDirMkdirOp.mkdirs(FSDirMkdirOp.java:69)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.mkdirs(FSNamesystem.java:3867)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.mkdirs(NameNodeRpcServer.java:984)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.mkdirs(ClientNamenodeProtocolServerSideTranslatorPB.java:634)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:616)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:982)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2217)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2213)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1754)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2213)

	at org.apache.hive.jdbc.HiveStatement.execute(HiveStatement.java:296)
	at org.apache.hive.jdbc.HivePreparedStatement.execute(HivePreparedStatement.java:98)
	at com.mchange.v2.c3p0.impl.NewProxyPreparedStatement.execute(NewProxyPreparedStatement.java:67)
	at com.inspur.pmv6.dao.HiveDao.executesql(HiveDao.java:152)
	at com.inspur.pmv6.Entrance.lambda$null$0(Entrance.java:83)
	at java.util.stream.Streams$RangeIntSpliterator.forEachRemaining(Streams.java:110)
	at java.util.stream.IntPipeline$Head.forEach(IntPipeline.java:557)
	at com.inspur.pmv6.Entrance.lambda$myTestCodes$1(Entrance.java:76)
	at java.util.stream.Streams$RangeIntSpliterator.forEachRemaining(Streams.java:110)
	at java.util.stream.IntPipeline$Head.forEach(IntPipeline.java:557)
	at com.inspur.pmv6.Entrance.myTestCodes(Entrance.java:74)
	at com.inspur.pmv6.Entrance.main(Entrance.java:43)
[0328 17:17:52 232 INFO ] [main] pmv6.dao.HiveDao - start to execute the sql :insert into test_table_double values (20180329, 020000, 69.09389496765513)
[0328 17:17:52 430 ERROR] [main] pmv6.dao.HiveDao - ERROR SQL: insert into test_table_double values (20180329, 020000, 69.09389496765513)
[0328 17:17:52 430 ERROR] [main] pmv6.dao.HiveDao - java.lang.RuntimeException: Cannot create staging directory 'hdfs://localhost:9000/home/chen/hive/warehouse/test_table_double/.hive-staging_hive_2018-03-28_02-17-52_317_1411404785794723720-2': Permission denied: user=hive, access=WRITE, inode="/home/chen/hive/warehouse/test_table_double":chen:supergroup:drwxr-xr-x
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.check(FSPermissionChecker.java:308)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:214)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:190)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkPermission(FSDirectory.java:1752)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkPermission(FSDirectory.java:1736)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkAncestorAccess(FSDirectory.java:1719)
	at org.apache.hadoop.hdfs.server.namenode.FSDirMkdirOp.mkdirs(FSDirMkdirOp.java:69)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.mkdirs(FSNamesystem.java:3867)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.mkdirs(NameNodeRpcServer.java:984)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.mkdirs(ClientNamenodeProtocolServerSideTranslatorPB.java:634)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:616)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:982)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2217)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2213)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1754)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2213)

java.sql.SQLException: java.lang.RuntimeException: Cannot create staging directory 'hdfs://localhost:9000/home/chen/hive/warehouse/test_table_double/.hive-staging_hive_2018-03-28_02-17-52_317_1411404785794723720-2': Permission denied: user=hive, access=WRITE, inode="/home/chen/hive/warehouse/test_table_double":chen:supergroup:drwxr-xr-x
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.check(FSPermissionChecker.java:308)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:214)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:190)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkPermission(FSDirectory.java:1752)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkPermission(FSDirectory.java:1736)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkAncestorAccess(FSDirectory.java:1719)
	at org.apache.hadoop.hdfs.server.namenode.FSDirMkdirOp.mkdirs(FSDirMkdirOp.java:69)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.mkdirs(FSNamesystem.java:3867)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.mkdirs(NameNodeRpcServer.java:984)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.mkdirs(ClientNamenodeProtocolServerSideTranslatorPB.java:634)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:616)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:982)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2217)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2213)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1754)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2213)

	at org.apache.hive.jdbc.HiveStatement.execute(HiveStatement.java:296)
	at org.apache.hive.jdbc.HivePreparedStatement.execute(HivePreparedStatement.java:98)
	at com.mchange.v2.c3p0.impl.NewProxyPreparedStatement.execute(NewProxyPreparedStatement.java:67)
	at com.inspur.pmv6.dao.HiveDao.executesql(HiveDao.java:152)
	at com.inspur.pmv6.Entrance.lambda$null$0(Entrance.java:83)
	at java.util.stream.Streams$RangeIntSpliterator.forEachRemaining(Streams.java:110)
	at java.util.stream.IntPipeline$Head.forEach(IntPipeline.java:557)
	at com.inspur.pmv6.Entrance.lambda$myTestCodes$1(Entrance.java:76)
	at java.util.stream.Streams$RangeIntSpliterator.forEachRemaining(Streams.java:110)
	at java.util.stream.IntPipeline$Head.forEach(IntPipeline.java:557)
	at com.inspur.pmv6.Entrance.myTestCodes(Entrance.java:74)
	at com.inspur.pmv6.Entrance.main(Entrance.java:43)
[0328 17:17:52 430 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29utxrumz1kq9f8v|80ec1f8]-HelperThread-#0] hive.jdbc.Utils - Supplied authorities: 10.211.55.29:10000
[0328 17:17:52 433 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29utxrumz1kq9f8v|80ec1f8]-HelperThread-#0] hive.jdbc.Utils - Resolved authority: 10.211.55.29:10000
[0328 17:17:52 434 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29utxrumz1kq9f8v|80ec1f8]-HelperThread-#0] hive.jdbc.HiveConnection - Will try to open client transport with JDBC Uri: jdbc:hive2://10.211.55.29:10000/default
[0328 17:17:52 438 INFO ] [main] pmv6.dao.HiveDao - start to execute the sql :insert into test_table_double values (20180329, 030000, 69.12060920143084)
[0328 17:17:52 728 ERROR] [main] pmv6.dao.HiveDao - ERROR SQL: insert into test_table_double values (20180329, 030000, 69.12060920143084)
[0328 17:17:52 728 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29utxrumz1kq9f8v|80ec1f8]-HelperThread-#2] hive.jdbc.Utils - Supplied authorities: 10.211.55.29:10000
[0328 17:17:52 729 ERROR] [main] pmv6.dao.HiveDao - java.lang.RuntimeException: Cannot create staging directory 'hdfs://localhost:9000/home/chen/hive/warehouse/test_table_double/.hive-staging_hive_2018-03-28_02-17-52_608_3553828704918480354-3': Permission denied: user=hive, access=WRITE, inode="/home/chen/hive/warehouse/test_table_double":chen:supergroup:drwxr-xr-x
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.check(FSPermissionChecker.java:308)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:214)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:190)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkPermission(FSDirectory.java:1752)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkPermission(FSDirectory.java:1736)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkAncestorAccess(FSDirectory.java:1719)
	at org.apache.hadoop.hdfs.server.namenode.FSDirMkdirOp.mkdirs(FSDirMkdirOp.java:69)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.mkdirs(FSNamesystem.java:3867)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.mkdirs(NameNodeRpcServer.java:984)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.mkdirs(ClientNamenodeProtocolServerSideTranslatorPB.java:634)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:616)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:982)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2217)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2213)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1754)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2213)

java.sql.SQLException: java.lang.RuntimeException: Cannot create staging directory 'hdfs://localhost:9000/home/chen/hive/warehouse/test_table_double/.hive-staging_hive_2018-03-28_02-17-52_608_3553828704918480354-3': Permission denied: user=hive, access=WRITE, inode="/home/chen/hive/warehouse/test_table_double":chen:supergroup:drwxr-xr-x
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.check(FSPermissionChecker.java:308)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:214)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:190)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkPermission(FSDirectory.java:1752)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkPermission(FSDirectory.java:1736)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkAncestorAccess(FSDirectory.java:1719)
	at org.apache.hadoop.hdfs.server.namenode.FSDirMkdirOp.mkdirs(FSDirMkdirOp.java:69)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.mkdirs(FSNamesystem.java:3867)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.mkdirs(NameNodeRpcServer.java:984)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.mkdirs(ClientNamenodeProtocolServerSideTranslatorPB.java:634)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:616)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:982)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2217)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2213)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1754)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2213)

	at org.apache.hive.jdbc.HiveStatement.execute(HiveStatement.java:296)
	at org.apache.hive.jdbc.HivePreparedStatement.execute(HivePreparedStatement.java:98)
	at com.mchange.v2.c3p0.impl.NewProxyPreparedStatement.execute(NewProxyPreparedStatement.java:67)
	at com.inspur.pmv6.dao.HiveDao.executesql(HiveDao.java:152)
	at com.inspur.pmv6.Entrance.lambda$null$0(Entrance.java:83)
	at java.util.stream.Streams$RangeIntSpliterator.forEachRemaining(Streams.java:110)
	at java.util.stream.IntPipeline$Head.forEach(IntPipeline.java:557)
	at com.inspur.pmv6.Entrance.lambda$myTestCodes$1(Entrance.java:76)
	at java.util.stream.Streams$RangeIntSpliterator.forEachRemaining(Streams.java:110)
	at java.util.stream.IntPipeline$Head.forEach(IntPipeline.java:557)
	at com.inspur.pmv6.Entrance.myTestCodes(Entrance.java:74)
	at com.inspur.pmv6.Entrance.main(Entrance.java:43)
[0328 17:17:52 729 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29utxrumz1kq9f8v|80ec1f8]-HelperThread-#2] hive.jdbc.Utils - Resolved authority: 10.211.55.29:10000
[0328 17:17:52 731 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29utxrumz1kq9f8v|80ec1f8]-HelperThread-#2] hive.jdbc.HiveConnection - Will try to open client transport with JDBC Uri: jdbc:hive2://10.211.55.29:10000/default
[0328 17:17:52 731 INFO ] [main] pmv6.dao.HiveDao - start to execute the sql :insert into test_table_double values (20180329, 040000, 93.36133216159938)
[0328 17:17:53 058 ERROR] [main] pmv6.dao.HiveDao - ERROR SQL: insert into test_table_double values (20180329, 040000, 93.36133216159938)
[0328 17:17:53 058 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29utxrumz1kq9f8v|80ec1f8]-HelperThread-#0] hive.jdbc.Utils - Supplied authorities: 10.211.55.29:10000
[0328 17:17:53 058 ERROR] [main] pmv6.dao.HiveDao - java.lang.RuntimeException: Cannot create staging directory 'hdfs://localhost:9000/home/chen/hive/warehouse/test_table_double/.hive-staging_hive_2018-03-28_02-17-52_974_555061806804091443-4': Permission denied: user=hive, access=WRITE, inode="/home/chen/hive/warehouse/test_table_double":chen:supergroup:drwxr-xr-x
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.check(FSPermissionChecker.java:308)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:214)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:190)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkPermission(FSDirectory.java:1752)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkPermission(FSDirectory.java:1736)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkAncestorAccess(FSDirectory.java:1719)
	at org.apache.hadoop.hdfs.server.namenode.FSDirMkdirOp.mkdirs(FSDirMkdirOp.java:69)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.mkdirs(FSNamesystem.java:3867)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.mkdirs(NameNodeRpcServer.java:984)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.mkdirs(ClientNamenodeProtocolServerSideTranslatorPB.java:634)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:616)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:982)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2217)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2213)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1754)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2213)

java.sql.SQLException: java.lang.RuntimeException: Cannot create staging directory 'hdfs://localhost:9000/home/chen/hive/warehouse/test_table_double/.hive-staging_hive_2018-03-28_02-17-52_974_555061806804091443-4': Permission denied: user=hive, access=WRITE, inode="/home/chen/hive/warehouse/test_table_double":chen:supergroup:drwxr-xr-x
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.check(FSPermissionChecker.java:308)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:214)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:190)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkPermission(FSDirectory.java:1752)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkPermission(FSDirectory.java:1736)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkAncestorAccess(FSDirectory.java:1719)
	at org.apache.hadoop.hdfs.server.namenode.FSDirMkdirOp.mkdirs(FSDirMkdirOp.java:69)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.mkdirs(FSNamesystem.java:3867)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.mkdirs(NameNodeRpcServer.java:984)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.mkdirs(ClientNamenodeProtocolServerSideTranslatorPB.java:634)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:616)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:982)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2217)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2213)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1754)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2213)

	at org.apache.hive.jdbc.HiveStatement.execute(HiveStatement.java:296)
	at org.apache.hive.jdbc.HivePreparedStatement.execute(HivePreparedStatement.java:98)
	at com.mchange.v2.c3p0.impl.NewProxyPreparedStatement.execute(NewProxyPreparedStatement.java:67)
	at com.inspur.pmv6.dao.HiveDao.executesql(HiveDao.java:152)
	at com.inspur.pmv6.Entrance.lambda$null$0(Entrance.java:83)
	at java.util.stream.Streams$RangeIntSpliterator.forEachRemaining(Streams.java:110)
	at java.util.stream.IntPipeline$Head.forEach(IntPipeline.java:557)
	at com.inspur.pmv6.Entrance.lambda$myTestCodes$1(Entrance.java:76)
	at java.util.stream.Streams$RangeIntSpliterator.forEachRemaining(Streams.java:110)
	at java.util.stream.IntPipeline$Head.forEach(IntPipeline.java:557)
	at com.inspur.pmv6.Entrance.myTestCodes(Entrance.java:74)
	at com.inspur.pmv6.Entrance.main(Entrance.java:43)
[0328 17:17:53 059 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29utxrumz1kq9f8v|80ec1f8]-HelperThread-#0] hive.jdbc.Utils - Resolved authority: 10.211.55.29:10000
[0328 17:17:53 060 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29utxrumz1kq9f8v|80ec1f8]-HelperThread-#0] hive.jdbc.HiveConnection - Will try to open client transport with JDBC Uri: jdbc:hive2://10.211.55.29:10000/default
[0328 17:17:53 061 INFO ] [main] pmv6.dao.HiveDao - start to execute the sql :insert into test_table_double values (20180329, 050000, 64.24848568539741)
[0328 17:17:53 201 ERROR] [main] pmv6.dao.HiveDao - ERROR SQL: insert into test_table_double values (20180329, 050000, 64.24848568539741)
[0328 17:17:53 201 ERROR] [main] pmv6.dao.HiveDao - java.lang.RuntimeException: Cannot create staging directory 'hdfs://localhost:9000/home/chen/hive/warehouse/test_table_double/.hive-staging_hive_2018-03-28_02-17-53_117_6822290039864311068-5': Permission denied: user=hive, access=WRITE, inode="/home/chen/hive/warehouse/test_table_double":chen:supergroup:drwxr-xr-x
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.check(FSPermissionChecker.java:308)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:214)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:190)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkPermission(FSDirectory.java:1752)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkPermission(FSDirectory.java:1736)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkAncestorAccess(FSDirectory.java:1719)
	at org.apache.hadoop.hdfs.server.namenode.FSDirMkdirOp.mkdirs(FSDirMkdirOp.java:69)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.mkdirs(FSNamesystem.java:3867)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.mkdirs(NameNodeRpcServer.java:984)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.mkdirs(ClientNamenodeProtocolServerSideTranslatorPB.java:634)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:616)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:982)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2217)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2213)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1754)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2213)

java.sql.SQLException: java.lang.RuntimeException: Cannot create staging directory 'hdfs://localhost:9000/home/chen/hive/warehouse/test_table_double/.hive-staging_hive_2018-03-28_02-17-53_117_6822290039864311068-5': Permission denied: user=hive, access=WRITE, inode="/home/chen/hive/warehouse/test_table_double":chen:supergroup:drwxr-xr-x
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.check(FSPermissionChecker.java:308)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:214)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:190)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkPermission(FSDirectory.java:1752)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkPermission(FSDirectory.java:1736)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkAncestorAccess(FSDirectory.java:1719)
	at org.apache.hadoop.hdfs.server.namenode.FSDirMkdirOp.mkdirs(FSDirMkdirOp.java:69)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.mkdirs(FSNamesystem.java:3867)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.mkdirs(NameNodeRpcServer.java:984)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.mkdirs(ClientNamenodeProtocolServerSideTranslatorPB.java:634)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:616)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:982)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2217)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2213)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1754)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2213)

	at org.apache.hive.jdbc.HiveStatement.execute(HiveStatement.java:296)
	at org.apache.hive.jdbc.HivePreparedStatement.execute(HivePreparedStatement.java:98)
	at com.mchange.v2.c3p0.impl.NewProxyPreparedStatement.execute(NewProxyPreparedStatement.java:67)
	at com.inspur.pmv6.dao.HiveDao.executesql(HiveDao.java:152)
	at com.inspur.pmv6.Entrance.lambda$null$0(Entrance.java:83)
	at java.util.stream.Streams$RangeIntSpliterator.forEachRemaining(Streams.java:110)
	at java.util.stream.IntPipeline$Head.forEach(IntPipeline.java:557)
	at com.inspur.pmv6.Entrance.lambda$myTestCodes$1(Entrance.java:76)
	at java.util.stream.Streams$RangeIntSpliterator.forEachRemaining(Streams.java:110)
	at java.util.stream.IntPipeline$Head.forEach(IntPipeline.java:557)
	at com.inspur.pmv6.Entrance.myTestCodes(Entrance.java:74)
	at com.inspur.pmv6.Entrance.main(Entrance.java:43)
[0328 17:17:53 201 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29utxrumz1kq9f8v|80ec1f8]-HelperThread-#1] hive.jdbc.Utils - Supplied authorities: 10.211.55.29:10000
[0328 17:17:53 202 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29utxrumz1kq9f8v|80ec1f8]-HelperThread-#1] hive.jdbc.Utils - Resolved authority: 10.211.55.29:10000
[0328 17:17:53 203 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29utxrumz1kq9f8v|80ec1f8]-HelperThread-#1] hive.jdbc.HiveConnection - Will try to open client transport with JDBC Uri: jdbc:hive2://10.211.55.29:10000/default
[0328 17:17:53 203 INFO ] [main] pmv6.dao.HiveDao - start to execute the sql :insert into test_table_double values (20180329, 060000, 44.01520248447927)
[0328 17:17:53 691 ERROR] [main] pmv6.dao.HiveDao - ERROR SQL: insert into test_table_double values (20180329, 060000, 44.01520248447927)
[0328 17:17:53 691 ERROR] [main] pmv6.dao.HiveDao - java.lang.RuntimeException: Cannot create staging directory 'hdfs://localhost:9000/home/chen/hive/warehouse/test_table_double/.hive-staging_hive_2018-03-28_02-17-53_613_634376128577526291-6': Permission denied: user=hive, access=WRITE, inode="/home/chen/hive/warehouse/test_table_double":chen:supergroup:drwxr-xr-x
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.check(FSPermissionChecker.java:308)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:214)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:190)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkPermission(FSDirectory.java:1752)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkPermission(FSDirectory.java:1736)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkAncestorAccess(FSDirectory.java:1719)
	at org.apache.hadoop.hdfs.server.namenode.FSDirMkdirOp.mkdirs(FSDirMkdirOp.java:69)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.mkdirs(FSNamesystem.java:3867)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.mkdirs(NameNodeRpcServer.java:984)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.mkdirs(ClientNamenodeProtocolServerSideTranslatorPB.java:634)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:616)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:982)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2217)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2213)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1754)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2213)

java.sql.SQLException: java.lang.RuntimeException: Cannot create staging directory 'hdfs://localhost:9000/home/chen/hive/warehouse/test_table_double/.hive-staging_hive_2018-03-28_02-17-53_613_634376128577526291-6': Permission denied: user=hive, access=WRITE, inode="/home/chen/hive/warehouse/test_table_double":chen:supergroup:drwxr-xr-x
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.check(FSPermissionChecker.java:308)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:214)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:190)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkPermission(FSDirectory.java:1752)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkPermission(FSDirectory.java:1736)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkAncestorAccess(FSDirectory.java:1719)
	at org.apache.hadoop.hdfs.server.namenode.FSDirMkdirOp.mkdirs(FSDirMkdirOp.java:69)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.mkdirs(FSNamesystem.java:3867)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.mkdirs(NameNodeRpcServer.java:984)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.mkdirs(ClientNamenodeProtocolServerSideTranslatorPB.java:634)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:616)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:982)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2217)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2213)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1754)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2213)

	at org.apache.hive.jdbc.HiveStatement.execute(HiveStatement.java:296)
	at org.apache.hive.jdbc.HivePreparedStatement.execute(HivePreparedStatement.java:98)
	at com.mchange.v2.c3p0.impl.NewProxyPreparedStatement.execute(NewProxyPreparedStatement.java:67)
	at com.inspur.pmv6.dao.HiveDao.executesql(HiveDao.java:152)
	at com.inspur.pmv6.Entrance.lambda$null$0(Entrance.java:83)
	at java.util.stream.Streams$RangeIntSpliterator.forEachRemaining(Streams.java:110)
	at java.util.stream.IntPipeline$Head.forEach(IntPipeline.java:557)
	at com.inspur.pmv6.Entrance.lambda$myTestCodes$1(Entrance.java:76)
	at java.util.stream.Streams$RangeIntSpliterator.forEachRemaining(Streams.java:110)
	at java.util.stream.IntPipeline$Head.forEach(IntPipeline.java:557)
	at com.inspur.pmv6.Entrance.myTestCodes(Entrance.java:74)
	at com.inspur.pmv6.Entrance.main(Entrance.java:43)
[0328 17:17:53 691 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29utxrumz1kq9f8v|80ec1f8]-HelperThread-#0] hive.jdbc.Utils - Supplied authorities: 10.211.55.29:10000
[0328 17:17:53 692 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29utxrumz1kq9f8v|80ec1f8]-HelperThread-#0] hive.jdbc.Utils - Resolved authority: 10.211.55.29:10000
[0328 17:17:53 693 INFO ] [main] pmv6.dao.HiveDao - start to execute the sql :insert into test_table_double values (20180329, 070000, 22.97135869450778)
[0328 17:17:53 693 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29utxrumz1kq9f8v|80ec1f8]-HelperThread-#0] hive.jdbc.HiveConnection - Will try to open client transport with JDBC Uri: jdbc:hive2://10.211.55.29:10000/default
[0328 17:17:53 832 ERROR] [main] pmv6.dao.HiveDao - ERROR SQL: insert into test_table_double values (20180329, 070000, 22.97135869450778)
[0328 17:17:53 832 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29utxrumz1kq9f8v|80ec1f8]-HelperThread-#2] hive.jdbc.Utils - Supplied authorities: 10.211.55.29:10000
[0328 17:17:53 832 ERROR] [main] pmv6.dao.HiveDao - java.lang.RuntimeException: Cannot create staging directory 'hdfs://localhost:9000/home/chen/hive/warehouse/test_table_double/.hive-staging_hive_2018-03-28_02-17-53_737_6391561685383435508-7': Permission denied: user=hive, access=WRITE, inode="/home/chen/hive/warehouse/test_table_double":chen:supergroup:drwxr-xr-x
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.check(FSPermissionChecker.java:308)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:214)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:190)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkPermission(FSDirectory.java:1752)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkPermission(FSDirectory.java:1736)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkAncestorAccess(FSDirectory.java:1719)
	at org.apache.hadoop.hdfs.server.namenode.FSDirMkdirOp.mkdirs(FSDirMkdirOp.java:69)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.mkdirs(FSNamesystem.java:3867)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.mkdirs(NameNodeRpcServer.java:984)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.mkdirs(ClientNamenodeProtocolServerSideTranslatorPB.java:634)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:616)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:982)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2217)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2213)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1754)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2213)

java.sql.SQLException: java.lang.RuntimeException: Cannot create staging directory 'hdfs://localhost:9000/home/chen/hive/warehouse/test_table_double/.hive-staging_hive_2018-03-28_02-17-53_737_6391561685383435508-7': Permission denied: user=hive, access=WRITE, inode="/home/chen/hive/warehouse/test_table_double":chen:supergroup:drwxr-xr-x
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.check(FSPermissionChecker.java:308)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:214)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:190)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkPermission(FSDirectory.java:1752)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkPermission(FSDirectory.java:1736)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkAncestorAccess(FSDirectory.java:1719)
	at org.apache.hadoop.hdfs.server.namenode.FSDirMkdirOp.mkdirs(FSDirMkdirOp.java:69)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.mkdirs(FSNamesystem.java:3867)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.mkdirs(NameNodeRpcServer.java:984)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.mkdirs(ClientNamenodeProtocolServerSideTranslatorPB.java:634)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:616)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:982)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2217)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2213)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1754)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2213)

	at org.apache.hive.jdbc.HiveStatement.execute(HiveStatement.java:296)
	at org.apache.hive.jdbc.HivePreparedStatement.execute(HivePreparedStatement.java:98)
	at com.mchange.v2.c3p0.impl.NewProxyPreparedStatement.execute(NewProxyPreparedStatement.java:67)
	at com.inspur.pmv6.dao.HiveDao.executesql(HiveDao.java:152)
	at com.inspur.pmv6.Entrance.lambda$null$0(Entrance.java:83)
	at java.util.stream.Streams$RangeIntSpliterator.forEachRemaining(Streams.java:110)
	at java.util.stream.IntPipeline$Head.forEach(IntPipeline.java:557)
	at com.inspur.pmv6.Entrance.lambda$myTestCodes$1(Entrance.java:76)
	at java.util.stream.Streams$RangeIntSpliterator.forEachRemaining(Streams.java:110)
	at java.util.stream.IntPipeline$Head.forEach(IntPipeline.java:557)
	at com.inspur.pmv6.Entrance.myTestCodes(Entrance.java:74)
	at com.inspur.pmv6.Entrance.main(Entrance.java:43)
[0328 17:17:53 833 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29utxrumz1kq9f8v|80ec1f8]-HelperThread-#2] hive.jdbc.Utils - Resolved authority: 10.211.55.29:10000
[0328 17:17:53 834 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29utxrumz1kq9f8v|80ec1f8]-HelperThread-#2] hive.jdbc.HiveConnection - Will try to open client transport with JDBC Uri: jdbc:hive2://10.211.55.29:10000/default
[0328 17:17:53 837 INFO ] [main] pmv6.dao.HiveDao - start to execute the sql :insert into test_table_double values (20180329, 080000, 52.18122180245035)
[0328 17:17:54 282 ERROR] [main] pmv6.dao.HiveDao - ERROR SQL: insert into test_table_double values (20180329, 080000, 52.18122180245035)
[0328 17:17:54 282 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29utxrumz1kq9f8v|80ec1f8]-HelperThread-#2] hive.jdbc.Utils - Supplied authorities: 10.211.55.29:10000
[0328 17:17:54 282 ERROR] [main] pmv6.dao.HiveDao - java.lang.RuntimeException: Cannot create staging directory 'hdfs://localhost:9000/home/chen/hive/warehouse/test_table_double/.hive-staging_hive_2018-03-28_02-17-54_198_4103910482064464208-8': Permission denied: user=hive, access=WRITE, inode="/home/chen/hive/warehouse/test_table_double":chen:supergroup:drwxr-xr-x
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.check(FSPermissionChecker.java:308)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:214)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:190)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkPermission(FSDirectory.java:1752)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkPermission(FSDirectory.java:1736)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkAncestorAccess(FSDirectory.java:1719)
	at org.apache.hadoop.hdfs.server.namenode.FSDirMkdirOp.mkdirs(FSDirMkdirOp.java:69)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.mkdirs(FSNamesystem.java:3867)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.mkdirs(NameNodeRpcServer.java:984)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.mkdirs(ClientNamenodeProtocolServerSideTranslatorPB.java:634)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:616)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:982)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2217)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2213)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1754)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2213)

java.sql.SQLException: java.lang.RuntimeException: Cannot create staging directory 'hdfs://localhost:9000/home/chen/hive/warehouse/test_table_double/.hive-staging_hive_2018-03-28_02-17-54_198_4103910482064464208-8': Permission denied: user=hive, access=WRITE, inode="/home/chen/hive/warehouse/test_table_double":chen:supergroup:drwxr-xr-x
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.check(FSPermissionChecker.java:308)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:214)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:190)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkPermission(FSDirectory.java:1752)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkPermission(FSDirectory.java:1736)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkAncestorAccess(FSDirectory.java:1719)
	at org.apache.hadoop.hdfs.server.namenode.FSDirMkdirOp.mkdirs(FSDirMkdirOp.java:69)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.mkdirs(FSNamesystem.java:3867)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.mkdirs(NameNodeRpcServer.java:984)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.mkdirs(ClientNamenodeProtocolServerSideTranslatorPB.java:634)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:616)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:982)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2217)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2213)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1754)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2213)

	at org.apache.hive.jdbc.HiveStatement.execute(HiveStatement.java:296)
	at org.apache.hive.jdbc.HivePreparedStatement.execute(HivePreparedStatement.java:98)
	at com.mchange.v2.c3p0.impl.NewProxyPreparedStatement.execute(NewProxyPreparedStatement.java:67)
	at com.inspur.pmv6.dao.HiveDao.executesql(HiveDao.java:152)
	at com.inspur.pmv6.Entrance.lambda$null$0(Entrance.java:83)
	at java.util.stream.Streams$RangeIntSpliterator.forEachRemaining(Streams.java:110)
	at java.util.stream.IntPipeline$Head.forEach(IntPipeline.java:557)
	at com.inspur.pmv6.Entrance.lambda$myTestCodes$1(Entrance.java:76)
	at java.util.stream.Streams$RangeIntSpliterator.forEachRemaining(Streams.java:110)
	at java.util.stream.IntPipeline$Head.forEach(IntPipeline.java:557)
	at com.inspur.pmv6.Entrance.myTestCodes(Entrance.java:74)
	at com.inspur.pmv6.Entrance.main(Entrance.java:43)
[0328 17:17:54 282 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29utxrumz1kq9f8v|80ec1f8]-HelperThread-#2] hive.jdbc.Utils - Resolved authority: 10.211.55.29:10000
[0328 17:17:54 283 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29utxrumz1kq9f8v|80ec1f8]-HelperThread-#2] hive.jdbc.HiveConnection - Will try to open client transport with JDBC Uri: jdbc:hive2://10.211.55.29:10000/default
[0328 17:17:54 284 INFO ] [main] pmv6.dao.HiveDao - start to execute the sql :insert into test_table_double values (20180329, 090000, 53.47488175429783)
[0328 17:17:54 427 ERROR] [main] pmv6.dao.HiveDao - ERROR SQL: insert into test_table_double values (20180329, 090000, 53.47488175429783)
[0328 17:17:54 427 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29utxrumz1kq9f8v|80ec1f8]-HelperThread-#1] hive.jdbc.Utils - Supplied authorities: 10.211.55.29:10000
[0328 17:17:54 427 ERROR] [main] pmv6.dao.HiveDao - java.lang.RuntimeException: Cannot create staging directory 'hdfs://localhost:9000/home/chen/hive/warehouse/test_table_double/.hive-staging_hive_2018-03-28_02-17-54_338_7375066514565678575-9': Permission denied: user=hive, access=WRITE, inode="/home/chen/hive/warehouse/test_table_double":chen:supergroup:drwxr-xr-x
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.check(FSPermissionChecker.java:308)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:214)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:190)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkPermission(FSDirectory.java:1752)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkPermission(FSDirectory.java:1736)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkAncestorAccess(FSDirectory.java:1719)
	at org.apache.hadoop.hdfs.server.namenode.FSDirMkdirOp.mkdirs(FSDirMkdirOp.java:69)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.mkdirs(FSNamesystem.java:3867)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.mkdirs(NameNodeRpcServer.java:984)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.mkdirs(ClientNamenodeProtocolServerSideTranslatorPB.java:634)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:616)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:982)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2217)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2213)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1754)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2213)

java.sql.SQLException: java.lang.RuntimeException: Cannot create staging directory 'hdfs://localhost:9000/home/chen/hive/warehouse/test_table_double/.hive-staging_hive_2018-03-28_02-17-54_338_7375066514565678575-9': Permission denied: user=hive, access=WRITE, inode="/home/chen/hive/warehouse/test_table_double":chen:supergroup:drwxr-xr-x
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.check(FSPermissionChecker.java:308)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:214)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:190)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkPermission(FSDirectory.java:1752)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkPermission(FSDirectory.java:1736)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkAncestorAccess(FSDirectory.java:1719)
	at org.apache.hadoop.hdfs.server.namenode.FSDirMkdirOp.mkdirs(FSDirMkdirOp.java:69)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.mkdirs(FSNamesystem.java:3867)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.mkdirs(NameNodeRpcServer.java:984)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.mkdirs(ClientNamenodeProtocolServerSideTranslatorPB.java:634)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:616)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:982)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2217)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2213)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1754)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2213)

	at org.apache.hive.jdbc.HiveStatement.execute(HiveStatement.java:296)
	at org.apache.hive.jdbc.HivePreparedStatement.execute(HivePreparedStatement.java:98)
	at com.mchange.v2.c3p0.impl.NewProxyPreparedStatement.execute(NewProxyPreparedStatement.java:67)
	at com.inspur.pmv6.dao.HiveDao.executesql(HiveDao.java:152)
	at com.inspur.pmv6.Entrance.lambda$null$0(Entrance.java:83)
	at java.util.stream.Streams$RangeIntSpliterator.forEachRemaining(Streams.java:110)
	at java.util.stream.IntPipeline$Head.forEach(IntPipeline.java:557)
	at com.inspur.pmv6.Entrance.lambda$myTestCodes$1(Entrance.java:76)
	at java.util.stream.Streams$RangeIntSpliterator.forEachRemaining(Streams.java:110)
	at java.util.stream.IntPipeline$Head.forEach(IntPipeline.java:557)
	at com.inspur.pmv6.Entrance.myTestCodes(Entrance.java:74)
	at com.inspur.pmv6.Entrance.main(Entrance.java:43)
[0328 17:17:54 428 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29utxrumz1kq9f8v|80ec1f8]-HelperThread-#1] hive.jdbc.Utils - Resolved authority: 10.211.55.29:10000
[0328 17:17:54 429 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29utxrumz1kq9f8v|80ec1f8]-HelperThread-#1] hive.jdbc.HiveConnection - Will try to open client transport with JDBC Uri: jdbc:hive2://10.211.55.29:10000/default
[0328 17:17:54 439 INFO ] [main] pmv6.dao.HiveDao - start to execute the sql :insert into test_table_double values (20180329, 100000, 36.199083761585804)
[0328 17:17:54 824 ERROR] [main] pmv6.dao.HiveDao - ERROR SQL: insert into test_table_double values (20180329, 100000, 36.199083761585804)
[0328 17:17:54 824 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29utxrumz1kq9f8v|80ec1f8]-HelperThread-#2] hive.jdbc.Utils - Supplied authorities: 10.211.55.29:10000
[0328 17:17:54 824 ERROR] [main] pmv6.dao.HiveDao - java.lang.RuntimeException: Cannot create staging directory 'hdfs://localhost:9000/home/chen/hive/warehouse/test_table_double/.hive-staging_hive_2018-03-28_02-17-54_730_141747116604126548-10': Permission denied: user=hive, access=WRITE, inode="/home/chen/hive/warehouse/test_table_double":chen:supergroup:drwxr-xr-x
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.check(FSPermissionChecker.java:308)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:214)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:190)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkPermission(FSDirectory.java:1752)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkPermission(FSDirectory.java:1736)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkAncestorAccess(FSDirectory.java:1719)
	at org.apache.hadoop.hdfs.server.namenode.FSDirMkdirOp.mkdirs(FSDirMkdirOp.java:69)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.mkdirs(FSNamesystem.java:3867)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.mkdirs(NameNodeRpcServer.java:984)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.mkdirs(ClientNamenodeProtocolServerSideTranslatorPB.java:634)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:616)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:982)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2217)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2213)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1754)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2213)

java.sql.SQLException: java.lang.RuntimeException: Cannot create staging directory 'hdfs://localhost:9000/home/chen/hive/warehouse/test_table_double/.hive-staging_hive_2018-03-28_02-17-54_730_141747116604126548-10': Permission denied: user=hive, access=WRITE, inode="/home/chen/hive/warehouse/test_table_double":chen:supergroup:drwxr-xr-x
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.check(FSPermissionChecker.java:308)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:214)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:190)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkPermission(FSDirectory.java:1752)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkPermission(FSDirectory.java:1736)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkAncestorAccess(FSDirectory.java:1719)
	at org.apache.hadoop.hdfs.server.namenode.FSDirMkdirOp.mkdirs(FSDirMkdirOp.java:69)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.mkdirs(FSNamesystem.java:3867)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.mkdirs(NameNodeRpcServer.java:984)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.mkdirs(ClientNamenodeProtocolServerSideTranslatorPB.java:634)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:616)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:982)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2217)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2213)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1754)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2213)

	at org.apache.hive.jdbc.HiveStatement.execute(HiveStatement.java:296)
	at org.apache.hive.jdbc.HivePreparedStatement.execute(HivePreparedStatement.java:98)
	at com.mchange.v2.c3p0.impl.NewProxyPreparedStatement.execute(NewProxyPreparedStatement.java:67)
	at com.inspur.pmv6.dao.HiveDao.executesql(HiveDao.java:152)
	at com.inspur.pmv6.Entrance.lambda$null$0(Entrance.java:83)
	at java.util.stream.Streams$RangeIntSpliterator.forEachRemaining(Streams.java:110)
	at java.util.stream.IntPipeline$Head.forEach(IntPipeline.java:557)
	at com.inspur.pmv6.Entrance.lambda$myTestCodes$1(Entrance.java:76)
	at java.util.stream.Streams$RangeIntSpliterator.forEachRemaining(Streams.java:110)
	at java.util.stream.IntPipeline$Head.forEach(IntPipeline.java:557)
	at com.inspur.pmv6.Entrance.myTestCodes(Entrance.java:74)
	at com.inspur.pmv6.Entrance.main(Entrance.java:43)
[0328 17:17:54 824 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29utxrumz1kq9f8v|80ec1f8]-HelperThread-#2] hive.jdbc.Utils - Resolved authority: 10.211.55.29:10000
[0328 17:17:54 825 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29utxrumz1kq9f8v|80ec1f8]-HelperThread-#2] hive.jdbc.HiveConnection - Will try to open client transport with JDBC Uri: jdbc:hive2://10.211.55.29:10000/default
[0328 17:17:54 826 INFO ] [main] pmv6.dao.HiveDao - start to execute the sql :insert into test_table_double values (20180329, 110000, 36.40970863293978)
[0328 17:17:54 971 ERROR] [main] pmv6.dao.HiveDao - ERROR SQL: insert into test_table_double values (20180329, 110000, 36.40970863293978)
[0328 17:17:54 971 ERROR] [main] pmv6.dao.HiveDao - java.lang.RuntimeException: Cannot create staging directory 'hdfs://localhost:9000/home/chen/hive/warehouse/test_table_double/.hive-staging_hive_2018-03-28_02-17-54_879_231332402527370701-11': Permission denied: user=hive, access=WRITE, inode="/home/chen/hive/warehouse/test_table_double":chen:supergroup:drwxr-xr-x
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.check(FSPermissionChecker.java:308)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:214)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:190)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkPermission(FSDirectory.java:1752)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkPermission(FSDirectory.java:1736)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkAncestorAccess(FSDirectory.java:1719)
	at org.apache.hadoop.hdfs.server.namenode.FSDirMkdirOp.mkdirs(FSDirMkdirOp.java:69)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.mkdirs(FSNamesystem.java:3867)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.mkdirs(NameNodeRpcServer.java:984)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.mkdirs(ClientNamenodeProtocolServerSideTranslatorPB.java:634)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:616)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:982)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2217)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2213)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1754)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2213)

java.sql.SQLException: java.lang.RuntimeException: Cannot create staging directory 'hdfs://localhost:9000/home/chen/hive/warehouse/test_table_double/.hive-staging_hive_2018-03-28_02-17-54_879_231332402527370701-11': Permission denied: user=hive, access=WRITE, inode="/home/chen/hive/warehouse/test_table_double":chen:supergroup:drwxr-xr-x
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.check(FSPermissionChecker.java:308)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:214)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:190)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkPermission(FSDirectory.java:1752)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkPermission(FSDirectory.java:1736)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkAncestorAccess(FSDirectory.java:1719)
	at org.apache.hadoop.hdfs.server.namenode.FSDirMkdirOp.mkdirs(FSDirMkdirOp.java:69)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.mkdirs(FSNamesystem.java:3867)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.mkdirs(NameNodeRpcServer.java:984)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.mkdirs(ClientNamenodeProtocolServerSideTranslatorPB.java:634)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:616)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:982)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2217)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2213)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1754)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2213)

	at org.apache.hive.jdbc.HiveStatement.execute(HiveStatement.java:296)
	at org.apache.hive.jdbc.HivePreparedStatement.execute(HivePreparedStatement.java:98)
	at com.mchange.v2.c3p0.impl.NewProxyPreparedStatement.execute(NewProxyPreparedStatement.java:67)
	at com.inspur.pmv6.dao.HiveDao.executesql(HiveDao.java:152)
	at com.inspur.pmv6.Entrance.lambda$null$0(Entrance.java:83)
	at java.util.stream.Streams$RangeIntSpliterator.forEachRemaining(Streams.java:110)
	at java.util.stream.IntPipeline$Head.forEach(IntPipeline.java:557)
	at com.inspur.pmv6.Entrance.lambda$myTestCodes$1(Entrance.java:76)
	at java.util.stream.Streams$RangeIntSpliterator.forEachRemaining(Streams.java:110)
	at java.util.stream.IntPipeline$Head.forEach(IntPipeline.java:557)
	at com.inspur.pmv6.Entrance.myTestCodes(Entrance.java:74)
	at com.inspur.pmv6.Entrance.main(Entrance.java:43)
[0328 17:17:54 971 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29utxrumz1kq9f8v|80ec1f8]-HelperThread-#0] hive.jdbc.Utils - Supplied authorities: 10.211.55.29:10000
[0328 17:17:54 972 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29utxrumz1kq9f8v|80ec1f8]-HelperThread-#0] hive.jdbc.Utils - Resolved authority: 10.211.55.29:10000
[0328 17:17:54 973 INFO ] [main] pmv6.dao.HiveDao - start to execute the sql :insert into test_table_double values (20180329, 120000, 33.8515884545783)
[0328 17:17:54 973 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29utxrumz1kq9f8v|80ec1f8]-HelperThread-#0] hive.jdbc.HiveConnection - Will try to open client transport with JDBC Uri: jdbc:hive2://10.211.55.29:10000/default
[0328 17:17:55 272 ERROR] [main] pmv6.dao.HiveDao - ERROR SQL: insert into test_table_double values (20180329, 120000, 33.8515884545783)
[0328 17:17:55 272 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29utxrumz1kq9f8v|80ec1f8]-HelperThread-#2] hive.jdbc.Utils - Supplied authorities: 10.211.55.29:10000
[0328 17:17:55 273 ERROR] [main] pmv6.dao.HiveDao - java.lang.RuntimeException: Cannot create staging directory 'hdfs://localhost:9000/home/chen/hive/warehouse/test_table_double/.hive-staging_hive_2018-03-28_02-17-55_183_8429309035666289331-12': Permission denied: user=hive, access=WRITE, inode="/home/chen/hive/warehouse/test_table_double":chen:supergroup:drwxr-xr-x
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.check(FSPermissionChecker.java:308)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:214)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:190)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkPermission(FSDirectory.java:1752)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkPermission(FSDirectory.java:1736)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkAncestorAccess(FSDirectory.java:1719)
	at org.apache.hadoop.hdfs.server.namenode.FSDirMkdirOp.mkdirs(FSDirMkdirOp.java:69)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.mkdirs(FSNamesystem.java:3867)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.mkdirs(NameNodeRpcServer.java:984)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.mkdirs(ClientNamenodeProtocolServerSideTranslatorPB.java:634)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:616)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:982)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2217)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2213)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1754)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2213)

java.sql.SQLException: java.lang.RuntimeException: Cannot create staging directory 'hdfs://localhost:9000/home/chen/hive/warehouse/test_table_double/.hive-staging_hive_2018-03-28_02-17-55_183_8429309035666289331-12': Permission denied: user=hive, access=WRITE, inode="/home/chen/hive/warehouse/test_table_double":chen:supergroup:drwxr-xr-x
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.check(FSPermissionChecker.java:308)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:214)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:190)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkPermission(FSDirectory.java:1752)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkPermission(FSDirectory.java:1736)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkAncestorAccess(FSDirectory.java:1719)
	at org.apache.hadoop.hdfs.server.namenode.FSDirMkdirOp.mkdirs(FSDirMkdirOp.java:69)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.mkdirs(FSNamesystem.java:3867)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.mkdirs(NameNodeRpcServer.java:984)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.mkdirs(ClientNamenodeProtocolServerSideTranslatorPB.java:634)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:616)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:982)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2217)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2213)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1754)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2213)

	at org.apache.hive.jdbc.HiveStatement.execute(HiveStatement.java:296)
	at org.apache.hive.jdbc.HivePreparedStatement.execute(HivePreparedStatement.java:98)
	at com.mchange.v2.c3p0.impl.NewProxyPreparedStatement.execute(NewProxyPreparedStatement.java:67)
	at com.inspur.pmv6.dao.HiveDao.executesql(HiveDao.java:152)
	at com.inspur.pmv6.Entrance.lambda$null$0(Entrance.java:83)
	at java.util.stream.Streams$RangeIntSpliterator.forEachRemaining(Streams.java:110)
	at java.util.stream.IntPipeline$Head.forEach(IntPipeline.java:557)
	at com.inspur.pmv6.Entrance.lambda$myTestCodes$1(Entrance.java:76)
	at java.util.stream.Streams$RangeIntSpliterator.forEachRemaining(Streams.java:110)
	at java.util.stream.IntPipeline$Head.forEach(IntPipeline.java:557)
	at com.inspur.pmv6.Entrance.myTestCodes(Entrance.java:74)
	at com.inspur.pmv6.Entrance.main(Entrance.java:43)
[0328 17:17:55 273 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29utxrumz1kq9f8v|80ec1f8]-HelperThread-#2] hive.jdbc.Utils - Resolved authority: 10.211.55.29:10000
[0328 17:17:55 274 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29utxrumz1kq9f8v|80ec1f8]-HelperThread-#2] hive.jdbc.HiveConnection - Will try to open client transport with JDBC Uri: jdbc:hive2://10.211.55.29:10000/default
[0328 17:17:55 274 INFO ] [main] pmv6.dao.HiveDao - start to execute the sql :insert into test_table_double values (20180329, 010000, 86.41558092251788)
[0328 17:17:55 408 ERROR] [main] pmv6.dao.HiveDao - ERROR SQL: insert into test_table_double values (20180329, 010000, 86.41558092251788)
[0328 17:17:55 409 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29utxrumz1kq9f8v|80ec1f8]-HelperThread-#1] hive.jdbc.Utils - Supplied authorities: 10.211.55.29:10000
[0328 17:17:55 409 ERROR] [main] pmv6.dao.HiveDao - java.lang.RuntimeException: Cannot create staging directory 'hdfs://localhost:9000/home/chen/hive/warehouse/test_table_double/.hive-staging_hive_2018-03-28_02-17-55_319_3520169250475607322-13': Permission denied: user=hive, access=WRITE, inode="/home/chen/hive/warehouse/test_table_double":chen:supergroup:drwxr-xr-x
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.check(FSPermissionChecker.java:308)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:214)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:190)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkPermission(FSDirectory.java:1752)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkPermission(FSDirectory.java:1736)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkAncestorAccess(FSDirectory.java:1719)
	at org.apache.hadoop.hdfs.server.namenode.FSDirMkdirOp.mkdirs(FSDirMkdirOp.java:69)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.mkdirs(FSNamesystem.java:3867)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.mkdirs(NameNodeRpcServer.java:984)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.mkdirs(ClientNamenodeProtocolServerSideTranslatorPB.java:634)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:616)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:982)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2217)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2213)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1754)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2213)

java.sql.SQLException: java.lang.RuntimeException: Cannot create staging directory 'hdfs://localhost:9000/home/chen/hive/warehouse/test_table_double/.hive-staging_hive_2018-03-28_02-17-55_319_3520169250475607322-13': Permission denied: user=hive, access=WRITE, inode="/home/chen/hive/warehouse/test_table_double":chen:supergroup:drwxr-xr-x
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.check(FSPermissionChecker.java:308)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:214)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:190)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkPermission(FSDirectory.java:1752)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkPermission(FSDirectory.java:1736)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkAncestorAccess(FSDirectory.java:1719)
	at org.apache.hadoop.hdfs.server.namenode.FSDirMkdirOp.mkdirs(FSDirMkdirOp.java:69)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.mkdirs(FSNamesystem.java:3867)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.mkdirs(NameNodeRpcServer.java:984)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.mkdirs(ClientNamenodeProtocolServerSideTranslatorPB.java:634)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:616)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:982)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2217)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2213)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1754)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2213)

	at org.apache.hive.jdbc.HiveStatement.execute(HiveStatement.java:296)
	at org.apache.hive.jdbc.HivePreparedStatement.execute(HivePreparedStatement.java:98)
	at com.mchange.v2.c3p0.impl.NewProxyPreparedStatement.execute(NewProxyPreparedStatement.java:67)
	at com.inspur.pmv6.dao.HiveDao.executesql(HiveDao.java:152)
	at com.inspur.pmv6.Entrance.lambda$null$0(Entrance.java:83)
	at java.util.stream.Streams$RangeIntSpliterator.forEachRemaining(Streams.java:110)
	at java.util.stream.IntPipeline$Head.forEach(IntPipeline.java:557)
	at com.inspur.pmv6.Entrance.lambda$myTestCodes$1(Entrance.java:76)
	at java.util.stream.Streams$RangeIntSpliterator.forEachRemaining(Streams.java:110)
	at java.util.stream.IntPipeline$Head.forEach(IntPipeline.java:557)
	at com.inspur.pmv6.Entrance.myTestCodes(Entrance.java:74)
	at com.inspur.pmv6.Entrance.main(Entrance.java:43)
[0328 17:17:55 409 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29utxrumz1kq9f8v|80ec1f8]-HelperThread-#1] hive.jdbc.Utils - Resolved authority: 10.211.55.29:10000
[0328 17:17:55 410 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29utxrumz1kq9f8v|80ec1f8]-HelperThread-#1] hive.jdbc.HiveConnection - Will try to open client transport with JDBC Uri: jdbc:hive2://10.211.55.29:10000/default
[0328 17:17:55 411 INFO ] [main] pmv6.dao.HiveDao - start to execute the sql :insert into test_table_double values (20180329, 020000, 8.424967000678162)
[0328 17:17:55 667 ERROR] [main] pmv6.dao.HiveDao - ERROR SQL: insert into test_table_double values (20180329, 020000, 8.424967000678162)
[0328 17:17:55 668 ERROR] [main] pmv6.dao.HiveDao - java.lang.RuntimeException: Cannot create staging directory 'hdfs://localhost:9000/home/chen/hive/warehouse/test_table_double/.hive-staging_hive_2018-03-28_02-17-55_584_7946580681350631036-14': Permission denied: user=hive, access=WRITE, inode="/home/chen/hive/warehouse/test_table_double":chen:supergroup:drwxr-xr-x
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.check(FSPermissionChecker.java:308)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:214)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:190)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkPermission(FSDirectory.java:1752)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkPermission(FSDirectory.java:1736)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkAncestorAccess(FSDirectory.java:1719)
	at org.apache.hadoop.hdfs.server.namenode.FSDirMkdirOp.mkdirs(FSDirMkdirOp.java:69)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.mkdirs(FSNamesystem.java:3867)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.mkdirs(NameNodeRpcServer.java:984)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.mkdirs(ClientNamenodeProtocolServerSideTranslatorPB.java:634)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:616)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:982)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2217)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2213)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1754)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2213)

java.sql.SQLException: java.lang.RuntimeException: Cannot create staging directory 'hdfs://localhost:9000/home/chen/hive/warehouse/test_table_double/.hive-staging_hive_2018-03-28_02-17-55_584_7946580681350631036-14': Permission denied: user=hive, access=WRITE, inode="/home/chen/hive/warehouse/test_table_double":chen:supergroup:drwxr-xr-x
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.check(FSPermissionChecker.java:308)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:214)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:190)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkPermission(FSDirectory.java:1752)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkPermission(FSDirectory.java:1736)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkAncestorAccess(FSDirectory.java:1719)
	at org.apache.hadoop.hdfs.server.namenode.FSDirMkdirOp.mkdirs(FSDirMkdirOp.java:69)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.mkdirs(FSNamesystem.java:3867)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.mkdirs(NameNodeRpcServer.java:984)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.mkdirs(ClientNamenodeProtocolServerSideTranslatorPB.java:634)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:616)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:982)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2217)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2213)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1754)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2213)

	at org.apache.hive.jdbc.HiveStatement.execute(HiveStatement.java:296)
	at org.apache.hive.jdbc.HivePreparedStatement.execute(HivePreparedStatement.java:98)
	at com.mchange.v2.c3p0.impl.NewProxyPreparedStatement.execute(NewProxyPreparedStatement.java:67)
	at com.inspur.pmv6.dao.HiveDao.executesql(HiveDao.java:152)
	at com.inspur.pmv6.Entrance.lambda$null$0(Entrance.java:83)
	at java.util.stream.Streams$RangeIntSpliterator.forEachRemaining(Streams.java:110)
	at java.util.stream.IntPipeline$Head.forEach(IntPipeline.java:557)
	at com.inspur.pmv6.Entrance.lambda$myTestCodes$1(Entrance.java:76)
	at java.util.stream.Streams$RangeIntSpliterator.forEachRemaining(Streams.java:110)
	at java.util.stream.IntPipeline$Head.forEach(IntPipeline.java:557)
	at com.inspur.pmv6.Entrance.myTestCodes(Entrance.java:74)
	at com.inspur.pmv6.Entrance.main(Entrance.java:43)
[0328 17:17:55 667 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29utxrumz1kq9f8v|80ec1f8]-HelperThread-#2] hive.jdbc.Utils - Supplied authorities: 10.211.55.29:10000
[0328 17:17:55 668 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29utxrumz1kq9f8v|80ec1f8]-HelperThread-#2] hive.jdbc.Utils - Resolved authority: 10.211.55.29:10000
[0328 17:17:55 669 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29utxrumz1kq9f8v|80ec1f8]-HelperThread-#2] hive.jdbc.HiveConnection - Will try to open client transport with JDBC Uri: jdbc:hive2://10.211.55.29:10000/default
[0328 17:17:55 669 INFO ] [main] pmv6.dao.HiveDao - start to execute the sql :insert into test_table_double values (20180329, 030000, 58.14223873792367)
[0328 17:17:55 877 ERROR] [main] pmv6.dao.HiveDao - ERROR SQL: insert into test_table_double values (20180329, 030000, 58.14223873792367)
[0328 17:17:55 877 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29utxrumz1kq9f8v|80ec1f8]-HelperThread-#1] hive.jdbc.Utils - Supplied authorities: 10.211.55.29:10000
[0328 17:17:55 877 ERROR] [main] pmv6.dao.HiveDao - java.lang.RuntimeException: Cannot create staging directory 'hdfs://localhost:9000/home/chen/hive/warehouse/test_table_double/.hive-staging_hive_2018-03-28_02-17-55_767_7609129982706889715-15': Permission denied: user=hive, access=WRITE, inode="/home/chen/hive/warehouse/test_table_double":chen:supergroup:drwxr-xr-x
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.check(FSPermissionChecker.java:308)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:214)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:190)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkPermission(FSDirectory.java:1752)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkPermission(FSDirectory.java:1736)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkAncestorAccess(FSDirectory.java:1719)
	at org.apache.hadoop.hdfs.server.namenode.FSDirMkdirOp.mkdirs(FSDirMkdirOp.java:69)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.mkdirs(FSNamesystem.java:3867)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.mkdirs(NameNodeRpcServer.java:984)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.mkdirs(ClientNamenodeProtocolServerSideTranslatorPB.java:634)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:616)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:982)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2217)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2213)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1754)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2213)

java.sql.SQLException: java.lang.RuntimeException: Cannot create staging directory 'hdfs://localhost:9000/home/chen/hive/warehouse/test_table_double/.hive-staging_hive_2018-03-28_02-17-55_767_7609129982706889715-15': Permission denied: user=hive, access=WRITE, inode="/home/chen/hive/warehouse/test_table_double":chen:supergroup:drwxr-xr-x
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.check(FSPermissionChecker.java:308)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:214)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:190)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkPermission(FSDirectory.java:1752)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkPermission(FSDirectory.java:1736)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkAncestorAccess(FSDirectory.java:1719)
	at org.apache.hadoop.hdfs.server.namenode.FSDirMkdirOp.mkdirs(FSDirMkdirOp.java:69)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.mkdirs(FSNamesystem.java:3867)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.mkdirs(NameNodeRpcServer.java:984)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.mkdirs(ClientNamenodeProtocolServerSideTranslatorPB.java:634)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:616)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:982)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2217)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2213)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1754)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2213)

	at org.apache.hive.jdbc.HiveStatement.execute(HiveStatement.java:296)
	at org.apache.hive.jdbc.HivePreparedStatement.execute(HivePreparedStatement.java:98)
	at com.mchange.v2.c3p0.impl.NewProxyPreparedStatement.execute(NewProxyPreparedStatement.java:67)
	at com.inspur.pmv6.dao.HiveDao.executesql(HiveDao.java:152)
	at com.inspur.pmv6.Entrance.lambda$null$0(Entrance.java:83)
	at java.util.stream.Streams$RangeIntSpliterator.forEachRemaining(Streams.java:110)
	at java.util.stream.IntPipeline$Head.forEach(IntPipeline.java:557)
	at com.inspur.pmv6.Entrance.lambda$myTestCodes$1(Entrance.java:76)
	at java.util.stream.Streams$RangeIntSpliterator.forEachRemaining(Streams.java:110)
	at java.util.stream.IntPipeline$Head.forEach(IntPipeline.java:557)
	at com.inspur.pmv6.Entrance.myTestCodes(Entrance.java:74)
	at com.inspur.pmv6.Entrance.main(Entrance.java:43)
[0328 17:17:55 877 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29utxrumz1kq9f8v|80ec1f8]-HelperThread-#1] hive.jdbc.Utils - Resolved authority: 10.211.55.29:10000
[0328 17:17:55 879 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29utxrumz1kq9f8v|80ec1f8]-HelperThread-#1] hive.jdbc.HiveConnection - Will try to open client transport with JDBC Uri: jdbc:hive2://10.211.55.29:10000/default
[0328 17:17:55 885 INFO ] [main] pmv6.dao.HiveDao - start to execute the sql :insert into test_table_double values (20180329, 040000, 98.11621127251426)
[0328 17:17:56 138 ERROR] [main] pmv6.dao.HiveDao - ERROR SQL: insert into test_table_double values (20180329, 040000, 98.11621127251426)
[0328 17:17:56 138 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29utxrumz1kq9f8v|80ec1f8]-HelperThread-#2] hive.jdbc.Utils - Supplied authorities: 10.211.55.29:10000
[0328 17:17:56 138 ERROR] [main] pmv6.dao.HiveDao - java.lang.RuntimeException: Cannot create staging directory 'hdfs://localhost:9000/home/chen/hive/warehouse/test_table_double/.hive-staging_hive_2018-03-28_02-17-56_055_6259080725256400472-16': Permission denied: user=hive, access=WRITE, inode="/home/chen/hive/warehouse/test_table_double":chen:supergroup:drwxr-xr-x
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.check(FSPermissionChecker.java:308)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:214)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:190)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkPermission(FSDirectory.java:1752)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkPermission(FSDirectory.java:1736)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkAncestorAccess(FSDirectory.java:1719)
	at org.apache.hadoop.hdfs.server.namenode.FSDirMkdirOp.mkdirs(FSDirMkdirOp.java:69)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.mkdirs(FSNamesystem.java:3867)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.mkdirs(NameNodeRpcServer.java:984)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.mkdirs(ClientNamenodeProtocolServerSideTranslatorPB.java:634)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:616)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:982)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2217)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2213)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1754)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2213)

java.sql.SQLException: java.lang.RuntimeException: Cannot create staging directory 'hdfs://localhost:9000/home/chen/hive/warehouse/test_table_double/.hive-staging_hive_2018-03-28_02-17-56_055_6259080725256400472-16': Permission denied: user=hive, access=WRITE, inode="/home/chen/hive/warehouse/test_table_double":chen:supergroup:drwxr-xr-x
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.check(FSPermissionChecker.java:308)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:214)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:190)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkPermission(FSDirectory.java:1752)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkPermission(FSDirectory.java:1736)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkAncestorAccess(FSDirectory.java:1719)
	at org.apache.hadoop.hdfs.server.namenode.FSDirMkdirOp.mkdirs(FSDirMkdirOp.java:69)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.mkdirs(FSNamesystem.java:3867)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.mkdirs(NameNodeRpcServer.java:984)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.mkdirs(ClientNamenodeProtocolServerSideTranslatorPB.java:634)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:616)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:982)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2217)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2213)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1754)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2213)

	at org.apache.hive.jdbc.HiveStatement.execute(HiveStatement.java:296)
	at org.apache.hive.jdbc.HivePreparedStatement.execute(HivePreparedStatement.java:98)
	at com.mchange.v2.c3p0.impl.NewProxyPreparedStatement.execute(NewProxyPreparedStatement.java:67)
	at com.inspur.pmv6.dao.HiveDao.executesql(HiveDao.java:152)
	at com.inspur.pmv6.Entrance.lambda$null$0(Entrance.java:83)
	at java.util.stream.Streams$RangeIntSpliterator.forEachRemaining(Streams.java:110)
	at java.util.stream.IntPipeline$Head.forEach(IntPipeline.java:557)
	at com.inspur.pmv6.Entrance.lambda$myTestCodes$1(Entrance.java:76)
	at java.util.stream.Streams$RangeIntSpliterator.forEachRemaining(Streams.java:110)
	at java.util.stream.IntPipeline$Head.forEach(IntPipeline.java:557)
	at com.inspur.pmv6.Entrance.myTestCodes(Entrance.java:74)
	at com.inspur.pmv6.Entrance.main(Entrance.java:43)
[0328 17:17:56 139 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29utxrumz1kq9f8v|80ec1f8]-HelperThread-#2] hive.jdbc.Utils - Resolved authority: 10.211.55.29:10000
[0328 17:17:56 140 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29utxrumz1kq9f8v|80ec1f8]-HelperThread-#2] hive.jdbc.HiveConnection - Will try to open client transport with JDBC Uri: jdbc:hive2://10.211.55.29:10000/default
[0328 17:17:56 141 INFO ] [main] pmv6.dao.HiveDao - start to execute the sql :insert into test_table_double values (20180329, 050000, 6.438918594079601)
[0328 17:17:56 378 ERROR] [main] pmv6.dao.HiveDao - ERROR SQL: insert into test_table_double values (20180329, 050000, 6.438918594079601)
[0328 17:17:56 379 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29utxrumz1kq9f8v|80ec1f8]-HelperThread-#1] hive.jdbc.Utils - Supplied authorities: 10.211.55.29:10000
[0328 17:17:56 379 ERROR] [main] pmv6.dao.HiveDao - java.lang.RuntimeException: Cannot create staging directory 'hdfs://localhost:9000/home/chen/hive/warehouse/test_table_double/.hive-staging_hive_2018-03-28_02-17-56_273_4857153942455347543-17': Permission denied: user=hive, access=WRITE, inode="/home/chen/hive/warehouse/test_table_double":chen:supergroup:drwxr-xr-x
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.check(FSPermissionChecker.java:308)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:214)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:190)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkPermission(FSDirectory.java:1752)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkPermission(FSDirectory.java:1736)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkAncestorAccess(FSDirectory.java:1719)
	at org.apache.hadoop.hdfs.server.namenode.FSDirMkdirOp.mkdirs(FSDirMkdirOp.java:69)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.mkdirs(FSNamesystem.java:3867)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.mkdirs(NameNodeRpcServer.java:984)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.mkdirs(ClientNamenodeProtocolServerSideTranslatorPB.java:634)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:616)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:982)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2217)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2213)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1754)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2213)

java.sql.SQLException: java.lang.RuntimeException: Cannot create staging directory 'hdfs://localhost:9000/home/chen/hive/warehouse/test_table_double/.hive-staging_hive_2018-03-28_02-17-56_273_4857153942455347543-17': Permission denied: user=hive, access=WRITE, inode="/home/chen/hive/warehouse/test_table_double":chen:supergroup:drwxr-xr-x
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.check(FSPermissionChecker.java:308)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:214)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:190)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkPermission(FSDirectory.java:1752)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkPermission(FSDirectory.java:1736)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkAncestorAccess(FSDirectory.java:1719)
	at org.apache.hadoop.hdfs.server.namenode.FSDirMkdirOp.mkdirs(FSDirMkdirOp.java:69)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.mkdirs(FSNamesystem.java:3867)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.mkdirs(NameNodeRpcServer.java:984)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.mkdirs(ClientNamenodeProtocolServerSideTranslatorPB.java:634)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:616)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:982)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2217)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2213)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1754)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2213)

	at org.apache.hive.jdbc.HiveStatement.execute(HiveStatement.java:296)
	at org.apache.hive.jdbc.HivePreparedStatement.execute(HivePreparedStatement.java:98)
	at com.mchange.v2.c3p0.impl.NewProxyPreparedStatement.execute(NewProxyPreparedStatement.java:67)
	at com.inspur.pmv6.dao.HiveDao.executesql(HiveDao.java:152)
	at com.inspur.pmv6.Entrance.lambda$null$0(Entrance.java:83)
	at java.util.stream.Streams$RangeIntSpliterator.forEachRemaining(Streams.java:110)
	at java.util.stream.IntPipeline$Head.forEach(IntPipeline.java:557)
	at com.inspur.pmv6.Entrance.lambda$myTestCodes$1(Entrance.java:76)
	at java.util.stream.Streams$RangeIntSpliterator.forEachRemaining(Streams.java:110)
	at java.util.stream.IntPipeline$Head.forEach(IntPipeline.java:557)
	at com.inspur.pmv6.Entrance.myTestCodes(Entrance.java:74)
	at com.inspur.pmv6.Entrance.main(Entrance.java:43)
[0328 17:17:56 379 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29utxrumz1kq9f8v|80ec1f8]-HelperThread-#1] hive.jdbc.Utils - Resolved authority: 10.211.55.29:10000
[0328 17:17:56 380 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29utxrumz1kq9f8v|80ec1f8]-HelperThread-#1] hive.jdbc.HiveConnection - Will try to open client transport with JDBC Uri: jdbc:hive2://10.211.55.29:10000/default
[0328 17:17:56 380 INFO ] [main] pmv6.dao.HiveDao - start to execute the sql :insert into test_table_double values (20180329, 060000, 34.15384112103859)
[0328 17:17:56 636 ERROR] [main] pmv6.dao.HiveDao - ERROR SQL: insert into test_table_double values (20180329, 060000, 34.15384112103859)
[0328 17:17:56 636 ERROR] [main] pmv6.dao.HiveDao - java.lang.RuntimeException: Cannot create staging directory 'hdfs://localhost:9000/home/chen/hive/warehouse/test_table_double/.hive-staging_hive_2018-03-28_02-17-56_549_7032480119297086555-18': Permission denied: user=hive, access=WRITE, inode="/home/chen/hive/warehouse/test_table_double":chen:supergroup:drwxr-xr-x
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.check(FSPermissionChecker.java:308)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:214)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:190)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkPermission(FSDirectory.java:1752)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkPermission(FSDirectory.java:1736)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkAncestorAccess(FSDirectory.java:1719)
	at org.apache.hadoop.hdfs.server.namenode.FSDirMkdirOp.mkdirs(FSDirMkdirOp.java:69)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.mkdirs(FSNamesystem.java:3867)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.mkdirs(NameNodeRpcServer.java:984)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.mkdirs(ClientNamenodeProtocolServerSideTranslatorPB.java:634)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:616)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:982)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2217)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2213)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1754)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2213)

java.sql.SQLException: java.lang.RuntimeException: Cannot create staging directory 'hdfs://localhost:9000/home/chen/hive/warehouse/test_table_double/.hive-staging_hive_2018-03-28_02-17-56_549_7032480119297086555-18': Permission denied: user=hive, access=WRITE, inode="/home/chen/hive/warehouse/test_table_double":chen:supergroup:drwxr-xr-x
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.check(FSPermissionChecker.java:308)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:214)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:190)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkPermission(FSDirectory.java:1752)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkPermission(FSDirectory.java:1736)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkAncestorAccess(FSDirectory.java:1719)
	at org.apache.hadoop.hdfs.server.namenode.FSDirMkdirOp.mkdirs(FSDirMkdirOp.java:69)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.mkdirs(FSNamesystem.java:3867)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.mkdirs(NameNodeRpcServer.java:984)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.mkdirs(ClientNamenodeProtocolServerSideTranslatorPB.java:634)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:616)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:982)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2217)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2213)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1754)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2213)

	at org.apache.hive.jdbc.HiveStatement.execute(HiveStatement.java:296)
	at org.apache.hive.jdbc.HivePreparedStatement.execute(HivePreparedStatement.java:98)
	at com.mchange.v2.c3p0.impl.NewProxyPreparedStatement.execute(NewProxyPreparedStatement.java:67)
	at com.inspur.pmv6.dao.HiveDao.executesql(HiveDao.java:152)
	at com.inspur.pmv6.Entrance.lambda$null$0(Entrance.java:83)
	at java.util.stream.Streams$RangeIntSpliterator.forEachRemaining(Streams.java:110)
	at java.util.stream.IntPipeline$Head.forEach(IntPipeline.java:557)
	at com.inspur.pmv6.Entrance.lambda$myTestCodes$1(Entrance.java:76)
	at java.util.stream.Streams$RangeIntSpliterator.forEachRemaining(Streams.java:110)
	at java.util.stream.IntPipeline$Head.forEach(IntPipeline.java:557)
	at com.inspur.pmv6.Entrance.myTestCodes(Entrance.java:74)
	at com.inspur.pmv6.Entrance.main(Entrance.java:43)
[0328 17:17:56 636 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29utxrumz1kq9f8v|80ec1f8]-HelperThread-#2] hive.jdbc.Utils - Supplied authorities: 10.211.55.29:10000
[0328 17:17:56 637 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29utxrumz1kq9f8v|80ec1f8]-HelperThread-#2] hive.jdbc.Utils - Resolved authority: 10.211.55.29:10000
[0328 17:17:56 638 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29utxrumz1kq9f8v|80ec1f8]-HelperThread-#2] hive.jdbc.HiveConnection - Will try to open client transport with JDBC Uri: jdbc:hive2://10.211.55.29:10000/default
[0328 17:17:56 638 INFO ] [main] pmv6.dao.HiveDao - start to execute the sql :insert into test_table_double values (20180329, 070000, 52.236468397605066)
[0328 17:17:56 761 ERROR] [main] pmv6.dao.HiveDao - ERROR SQL: insert into test_table_double values (20180329, 070000, 52.236468397605066)
[0328 17:17:56 761 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29utxrumz1kq9f8v|80ec1f8]-HelperThread-#0] hive.jdbc.Utils - Supplied authorities: 10.211.55.29:10000
[0328 17:17:56 761 ERROR] [main] pmv6.dao.HiveDao - java.lang.RuntimeException: Cannot create staging directory 'hdfs://localhost:9000/home/chen/hive/warehouse/test_table_double/.hive-staging_hive_2018-03-28_02-17-56_682_2322346958923328189-19': Permission denied: user=hive, access=WRITE, inode="/home/chen/hive/warehouse/test_table_double":chen:supergroup:drwxr-xr-x
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.check(FSPermissionChecker.java:308)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:214)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:190)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkPermission(FSDirectory.java:1752)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkPermission(FSDirectory.java:1736)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkAncestorAccess(FSDirectory.java:1719)
	at org.apache.hadoop.hdfs.server.namenode.FSDirMkdirOp.mkdirs(FSDirMkdirOp.java:69)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.mkdirs(FSNamesystem.java:3867)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.mkdirs(NameNodeRpcServer.java:984)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.mkdirs(ClientNamenodeProtocolServerSideTranslatorPB.java:634)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:616)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:982)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2217)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2213)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1754)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2213)

java.sql.SQLException: java.lang.RuntimeException: Cannot create staging directory 'hdfs://localhost:9000/home/chen/hive/warehouse/test_table_double/.hive-staging_hive_2018-03-28_02-17-56_682_2322346958923328189-19': Permission denied: user=hive, access=WRITE, inode="/home/chen/hive/warehouse/test_table_double":chen:supergroup:drwxr-xr-x
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.check(FSPermissionChecker.java:308)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:214)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:190)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkPermission(FSDirectory.java:1752)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkPermission(FSDirectory.java:1736)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkAncestorAccess(FSDirectory.java:1719)
	at org.apache.hadoop.hdfs.server.namenode.FSDirMkdirOp.mkdirs(FSDirMkdirOp.java:69)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.mkdirs(FSNamesystem.java:3867)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.mkdirs(NameNodeRpcServer.java:984)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.mkdirs(ClientNamenodeProtocolServerSideTranslatorPB.java:634)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:616)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:982)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2217)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2213)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1754)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2213)

	at org.apache.hive.jdbc.HiveStatement.execute(HiveStatement.java:296)
	at org.apache.hive.jdbc.HivePreparedStatement.execute(HivePreparedStatement.java:98)
	at com.mchange.v2.c3p0.impl.NewProxyPreparedStatement.execute(NewProxyPreparedStatement.java:67)
	at com.inspur.pmv6.dao.HiveDao.executesql(HiveDao.java:152)
	at com.inspur.pmv6.Entrance.lambda$null$0(Entrance.java:83)
	at java.util.stream.Streams$RangeIntSpliterator.forEachRemaining(Streams.java:110)
	at java.util.stream.IntPipeline$Head.forEach(IntPipeline.java:557)
	at com.inspur.pmv6.Entrance.lambda$myTestCodes$1(Entrance.java:76)
	at java.util.stream.Streams$RangeIntSpliterator.forEachRemaining(Streams.java:110)
	at java.util.stream.IntPipeline$Head.forEach(IntPipeline.java:557)
	at com.inspur.pmv6.Entrance.myTestCodes(Entrance.java:74)
	at com.inspur.pmv6.Entrance.main(Entrance.java:43)
[0328 17:17:56 761 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29utxrumz1kq9f8v|80ec1f8]-HelperThread-#0] hive.jdbc.Utils - Resolved authority: 10.211.55.29:10000
[0328 17:17:56 762 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29utxrumz1kq9f8v|80ec1f8]-HelperThread-#0] hive.jdbc.HiveConnection - Will try to open client transport with JDBC Uri: jdbc:hive2://10.211.55.29:10000/default
[0328 17:17:56 762 INFO ] [main] pmv6.dao.HiveDao - start to execute the sql :insert into test_table_double values (20180329, 080000, 89.07986150670177)
[0328 17:17:56 964 ERROR] [main] pmv6.dao.HiveDao - ERROR SQL: insert into test_table_double values (20180329, 080000, 89.07986150670177)
[0328 17:17:56 964 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29utxrumz1kq9f8v|80ec1f8]-HelperThread-#2] hive.jdbc.Utils - Supplied authorities: 10.211.55.29:10000
[0328 17:17:56 964 ERROR] [main] pmv6.dao.HiveDao - java.lang.RuntimeException: Cannot create staging directory 'hdfs://localhost:9000/home/chen/hive/warehouse/test_table_double/.hive-staging_hive_2018-03-28_02-17-56_889_9002691356237489009-20': Permission denied: user=hive, access=WRITE, inode="/home/chen/hive/warehouse/test_table_double":chen:supergroup:drwxr-xr-x
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.check(FSPermissionChecker.java:308)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:214)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:190)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkPermission(FSDirectory.java:1752)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkPermission(FSDirectory.java:1736)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkAncestorAccess(FSDirectory.java:1719)
	at org.apache.hadoop.hdfs.server.namenode.FSDirMkdirOp.mkdirs(FSDirMkdirOp.java:69)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.mkdirs(FSNamesystem.java:3867)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.mkdirs(NameNodeRpcServer.java:984)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.mkdirs(ClientNamenodeProtocolServerSideTranslatorPB.java:634)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:616)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:982)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2217)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2213)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1754)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2213)

java.sql.SQLException: java.lang.RuntimeException: Cannot create staging directory 'hdfs://localhost:9000/home/chen/hive/warehouse/test_table_double/.hive-staging_hive_2018-03-28_02-17-56_889_9002691356237489009-20': Permission denied: user=hive, access=WRITE, inode="/home/chen/hive/warehouse/test_table_double":chen:supergroup:drwxr-xr-x
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.check(FSPermissionChecker.java:308)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:214)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:190)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkPermission(FSDirectory.java:1752)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkPermission(FSDirectory.java:1736)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkAncestorAccess(FSDirectory.java:1719)
	at org.apache.hadoop.hdfs.server.namenode.FSDirMkdirOp.mkdirs(FSDirMkdirOp.java:69)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.mkdirs(FSNamesystem.java:3867)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.mkdirs(NameNodeRpcServer.java:984)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.mkdirs(ClientNamenodeProtocolServerSideTranslatorPB.java:634)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:616)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:982)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2217)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2213)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1754)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2213)

	at org.apache.hive.jdbc.HiveStatement.execute(HiveStatement.java:296)
	at org.apache.hive.jdbc.HivePreparedStatement.execute(HivePreparedStatement.java:98)
	at com.mchange.v2.c3p0.impl.NewProxyPreparedStatement.execute(NewProxyPreparedStatement.java:67)
	at com.inspur.pmv6.dao.HiveDao.executesql(HiveDao.java:152)
	at com.inspur.pmv6.Entrance.lambda$null$0(Entrance.java:83)
	at java.util.stream.Streams$RangeIntSpliterator.forEachRemaining(Streams.java:110)
	at java.util.stream.IntPipeline$Head.forEach(IntPipeline.java:557)
	at com.inspur.pmv6.Entrance.lambda$myTestCodes$1(Entrance.java:76)
	at java.util.stream.Streams$RangeIntSpliterator.forEachRemaining(Streams.java:110)
	at java.util.stream.IntPipeline$Head.forEach(IntPipeline.java:557)
	at com.inspur.pmv6.Entrance.myTestCodes(Entrance.java:74)
	at com.inspur.pmv6.Entrance.main(Entrance.java:43)
[0328 17:17:56 965 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29utxrumz1kq9f8v|80ec1f8]-HelperThread-#2] hive.jdbc.Utils - Resolved authority: 10.211.55.29:10000
[0328 17:17:56 965 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29utxrumz1kq9f8v|80ec1f8]-HelperThread-#2] hive.jdbc.HiveConnection - Will try to open client transport with JDBC Uri: jdbc:hive2://10.211.55.29:10000/default
[0328 17:17:56 966 INFO ] [main] pmv6.dao.HiveDao - start to execute the sql :insert into test_table_double values (20180329, 090000, 62.34809146169591)
[0328 17:17:57 164 ERROR] [main] pmv6.dao.HiveDao - ERROR SQL: insert into test_table_double values (20180329, 090000, 62.34809146169591)
[0328 17:17:57 164 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29utxrumz1kq9f8v|80ec1f8]-HelperThread-#0] hive.jdbc.Utils - Supplied authorities: 10.211.55.29:10000
[0328 17:17:57 164 ERROR] [main] pmv6.dao.HiveDao - java.lang.RuntimeException: Cannot create staging directory 'hdfs://localhost:9000/home/chen/hive/warehouse/test_table_double/.hive-staging_hive_2018-03-28_02-17-57_073_1024402274533477725-21': Permission denied: user=hive, access=WRITE, inode="/home/chen/hive/warehouse/test_table_double":chen:supergroup:drwxr-xr-x
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.check(FSPermissionChecker.java:308)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:214)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:190)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkPermission(FSDirectory.java:1752)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkPermission(FSDirectory.java:1736)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkAncestorAccess(FSDirectory.java:1719)
	at org.apache.hadoop.hdfs.server.namenode.FSDirMkdirOp.mkdirs(FSDirMkdirOp.java:69)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.mkdirs(FSNamesystem.java:3867)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.mkdirs(NameNodeRpcServer.java:984)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.mkdirs(ClientNamenodeProtocolServerSideTranslatorPB.java:634)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:616)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:982)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2217)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2213)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1754)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2213)

java.sql.SQLException: java.lang.RuntimeException: Cannot create staging directory 'hdfs://localhost:9000/home/chen/hive/warehouse/test_table_double/.hive-staging_hive_2018-03-28_02-17-57_073_1024402274533477725-21': Permission denied: user=hive, access=WRITE, inode="/home/chen/hive/warehouse/test_table_double":chen:supergroup:drwxr-xr-x
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.check(FSPermissionChecker.java:308)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:214)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:190)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkPermission(FSDirectory.java:1752)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkPermission(FSDirectory.java:1736)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkAncestorAccess(FSDirectory.java:1719)
	at org.apache.hadoop.hdfs.server.namenode.FSDirMkdirOp.mkdirs(FSDirMkdirOp.java:69)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.mkdirs(FSNamesystem.java:3867)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.mkdirs(NameNodeRpcServer.java:984)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.mkdirs(ClientNamenodeProtocolServerSideTranslatorPB.java:634)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:616)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:982)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2217)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2213)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1754)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2213)

	at org.apache.hive.jdbc.HiveStatement.execute(HiveStatement.java:296)
	at org.apache.hive.jdbc.HivePreparedStatement.execute(HivePreparedStatement.java:98)
	at com.mchange.v2.c3p0.impl.NewProxyPreparedStatement.execute(NewProxyPreparedStatement.java:67)
	at com.inspur.pmv6.dao.HiveDao.executesql(HiveDao.java:152)
	at com.inspur.pmv6.Entrance.lambda$null$0(Entrance.java:83)
	at java.util.stream.Streams$RangeIntSpliterator.forEachRemaining(Streams.java:110)
	at java.util.stream.IntPipeline$Head.forEach(IntPipeline.java:557)
	at com.inspur.pmv6.Entrance.lambda$myTestCodes$1(Entrance.java:76)
	at java.util.stream.Streams$RangeIntSpliterator.forEachRemaining(Streams.java:110)
	at java.util.stream.IntPipeline$Head.forEach(IntPipeline.java:557)
	at com.inspur.pmv6.Entrance.myTestCodes(Entrance.java:74)
	at com.inspur.pmv6.Entrance.main(Entrance.java:43)
[0328 17:17:57 164 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29utxrumz1kq9f8v|80ec1f8]-HelperThread-#0] hive.jdbc.Utils - Resolved authority: 10.211.55.29:10000
[0328 17:17:57 165 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29utxrumz1kq9f8v|80ec1f8]-HelperThread-#0] hive.jdbc.HiveConnection - Will try to open client transport with JDBC Uri: jdbc:hive2://10.211.55.29:10000/default
[0328 17:17:57 166 INFO ] [main] pmv6.dao.HiveDao - start to execute the sql :insert into test_table_double values (20180329, 100000, 27.581569761707126)
[0328 17:17:57 400 ERROR] [main] pmv6.dao.HiveDao - ERROR SQL: insert into test_table_double values (20180329, 100000, 27.581569761707126)
[0328 17:17:57 401 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29utxrumz1kq9f8v|80ec1f8]-HelperThread-#2] hive.jdbc.Utils - Supplied authorities: 10.211.55.29:10000
[0328 17:17:57 401 ERROR] [main] pmv6.dao.HiveDao - java.lang.RuntimeException: Cannot create staging directory 'hdfs://localhost:9000/home/chen/hive/warehouse/test_table_double/.hive-staging_hive_2018-03-28_02-17-57_303_8031205737150259439-22': Permission denied: user=hive, access=WRITE, inode="/home/chen/hive/warehouse/test_table_double":chen:supergroup:drwxr-xr-x
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.check(FSPermissionChecker.java:308)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:214)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:190)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkPermission(FSDirectory.java:1752)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkPermission(FSDirectory.java:1736)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkAncestorAccess(FSDirectory.java:1719)
	at org.apache.hadoop.hdfs.server.namenode.FSDirMkdirOp.mkdirs(FSDirMkdirOp.java:69)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.mkdirs(FSNamesystem.java:3867)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.mkdirs(NameNodeRpcServer.java:984)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.mkdirs(ClientNamenodeProtocolServerSideTranslatorPB.java:634)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:616)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:982)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2217)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2213)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1754)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2213)

java.sql.SQLException: java.lang.RuntimeException: Cannot create staging directory 'hdfs://localhost:9000/home/chen/hive/warehouse/test_table_double/.hive-staging_hive_2018-03-28_02-17-57_303_8031205737150259439-22': Permission denied: user=hive, access=WRITE, inode="/home/chen/hive/warehouse/test_table_double":chen:supergroup:drwxr-xr-x
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.check(FSPermissionChecker.java:308)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:214)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:190)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkPermission(FSDirectory.java:1752)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkPermission(FSDirectory.java:1736)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkAncestorAccess(FSDirectory.java:1719)
	at org.apache.hadoop.hdfs.server.namenode.FSDirMkdirOp.mkdirs(FSDirMkdirOp.java:69)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.mkdirs(FSNamesystem.java:3867)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.mkdirs(NameNodeRpcServer.java:984)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.mkdirs(ClientNamenodeProtocolServerSideTranslatorPB.java:634)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:616)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:982)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2217)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2213)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1754)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2213)

	at org.apache.hive.jdbc.HiveStatement.execute(HiveStatement.java:296)
	at org.apache.hive.jdbc.HivePreparedStatement.execute(HivePreparedStatement.java:98)
	at com.mchange.v2.c3p0.impl.NewProxyPreparedStatement.execute(NewProxyPreparedStatement.java:67)
	at com.inspur.pmv6.dao.HiveDao.executesql(HiveDao.java:152)
	at com.inspur.pmv6.Entrance.lambda$null$0(Entrance.java:83)
	at java.util.stream.Streams$RangeIntSpliterator.forEachRemaining(Streams.java:110)
	at java.util.stream.IntPipeline$Head.forEach(IntPipeline.java:557)
	at com.inspur.pmv6.Entrance.lambda$myTestCodes$1(Entrance.java:76)
	at java.util.stream.Streams$RangeIntSpliterator.forEachRemaining(Streams.java:110)
	at java.util.stream.IntPipeline$Head.forEach(IntPipeline.java:557)
	at com.inspur.pmv6.Entrance.myTestCodes(Entrance.java:74)
	at com.inspur.pmv6.Entrance.main(Entrance.java:43)
[0328 17:17:57 401 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29utxrumz1kq9f8v|80ec1f8]-HelperThread-#2] hive.jdbc.Utils - Resolved authority: 10.211.55.29:10000
[0328 17:17:57 402 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29utxrumz1kq9f8v|80ec1f8]-HelperThread-#2] hive.jdbc.HiveConnection - Will try to open client transport with JDBC Uri: jdbc:hive2://10.211.55.29:10000/default
[0328 17:17:57 404 INFO ] [main] pmv6.dao.HiveDao - start to execute the sql :insert into test_table_double values (20180329, 110000, 9.001827586437317)
[0328 17:17:57 602 ERROR] [main] pmv6.dao.HiveDao - ERROR SQL: insert into test_table_double values (20180329, 110000, 9.001827586437317)
[0328 17:17:57 602 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29utxrumz1kq9f8v|80ec1f8]-HelperThread-#0] hive.jdbc.Utils - Supplied authorities: 10.211.55.29:10000
[0328 17:17:57 602 ERROR] [main] pmv6.dao.HiveDao - java.lang.RuntimeException: Cannot create staging directory 'hdfs://localhost:9000/home/chen/hive/warehouse/test_table_double/.hive-staging_hive_2018-03-28_02-17-57_520_2826974312682653045-23': Permission denied: user=hive, access=WRITE, inode="/home/chen/hive/warehouse/test_table_double":chen:supergroup:drwxr-xr-x
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.check(FSPermissionChecker.java:308)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:214)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:190)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkPermission(FSDirectory.java:1752)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkPermission(FSDirectory.java:1736)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkAncestorAccess(FSDirectory.java:1719)
	at org.apache.hadoop.hdfs.server.namenode.FSDirMkdirOp.mkdirs(FSDirMkdirOp.java:69)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.mkdirs(FSNamesystem.java:3867)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.mkdirs(NameNodeRpcServer.java:984)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.mkdirs(ClientNamenodeProtocolServerSideTranslatorPB.java:634)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:616)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:982)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2217)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2213)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1754)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2213)

java.sql.SQLException: java.lang.RuntimeException: Cannot create staging directory 'hdfs://localhost:9000/home/chen/hive/warehouse/test_table_double/.hive-staging_hive_2018-03-28_02-17-57_520_2826974312682653045-23': Permission denied: user=hive, access=WRITE, inode="/home/chen/hive/warehouse/test_table_double":chen:supergroup:drwxr-xr-x
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.check(FSPermissionChecker.java:308)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:214)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:190)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkPermission(FSDirectory.java:1752)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkPermission(FSDirectory.java:1736)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkAncestorAccess(FSDirectory.java:1719)
	at org.apache.hadoop.hdfs.server.namenode.FSDirMkdirOp.mkdirs(FSDirMkdirOp.java:69)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.mkdirs(FSNamesystem.java:3867)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.mkdirs(NameNodeRpcServer.java:984)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.mkdirs(ClientNamenodeProtocolServerSideTranslatorPB.java:634)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:616)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:982)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2217)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2213)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1754)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2213)

	at org.apache.hive.jdbc.HiveStatement.execute(HiveStatement.java:296)
	at org.apache.hive.jdbc.HivePreparedStatement.execute(HivePreparedStatement.java:98)
	at com.mchange.v2.c3p0.impl.NewProxyPreparedStatement.execute(NewProxyPreparedStatement.java:67)
	at com.inspur.pmv6.dao.HiveDao.executesql(HiveDao.java:152)
	at com.inspur.pmv6.Entrance.lambda$null$0(Entrance.java:83)
	at java.util.stream.Streams$RangeIntSpliterator.forEachRemaining(Streams.java:110)
	at java.util.stream.IntPipeline$Head.forEach(IntPipeline.java:557)
	at com.inspur.pmv6.Entrance.lambda$myTestCodes$1(Entrance.java:76)
	at java.util.stream.Streams$RangeIntSpliterator.forEachRemaining(Streams.java:110)
	at java.util.stream.IntPipeline$Head.forEach(IntPipeline.java:557)
	at com.inspur.pmv6.Entrance.myTestCodes(Entrance.java:74)
	at com.inspur.pmv6.Entrance.main(Entrance.java:43)
[0328 17:17:57 602 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29utxrumz1kq9f8v|80ec1f8]-HelperThread-#0] hive.jdbc.Utils - Resolved authority: 10.211.55.29:10000
[0328 17:17:57 603 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29utxrumz1kq9f8v|80ec1f8]-HelperThread-#0] hive.jdbc.HiveConnection - Will try to open client transport with JDBC Uri: jdbc:hive2://10.211.55.29:10000/default
[0328 17:17:57 604 INFO ] [main] pmv6.dao.HiveDao - start to execute the sql :insert into test_table_double values (20180331, 120000, 1.7538372078627185)
[0328 17:17:57 849 ERROR] [main] pmv6.dao.HiveDao - ERROR SQL: insert into test_table_double values (20180331, 120000, 1.7538372078627185)
[0328 17:17:57 849 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29utxrumz1kq9f8v|80ec1f8]-HelperThread-#2] hive.jdbc.Utils - Supplied authorities: 10.211.55.29:10000
[0328 17:17:57 849 ERROR] [main] pmv6.dao.HiveDao - java.lang.RuntimeException: Cannot create staging directory 'hdfs://localhost:9000/home/chen/hive/warehouse/test_table_double/.hive-staging_hive_2018-03-28_02-17-57_767_4761704892073698425-24': Permission denied: user=hive, access=WRITE, inode="/home/chen/hive/warehouse/test_table_double":chen:supergroup:drwxr-xr-x
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.check(FSPermissionChecker.java:308)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:214)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:190)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkPermission(FSDirectory.java:1752)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkPermission(FSDirectory.java:1736)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkAncestorAccess(FSDirectory.java:1719)
	at org.apache.hadoop.hdfs.server.namenode.FSDirMkdirOp.mkdirs(FSDirMkdirOp.java:69)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.mkdirs(FSNamesystem.java:3867)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.mkdirs(NameNodeRpcServer.java:984)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.mkdirs(ClientNamenodeProtocolServerSideTranslatorPB.java:634)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:616)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:982)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2217)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2213)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1754)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2213)

java.sql.SQLException: java.lang.RuntimeException: Cannot create staging directory 'hdfs://localhost:9000/home/chen/hive/warehouse/test_table_double/.hive-staging_hive_2018-03-28_02-17-57_767_4761704892073698425-24': Permission denied: user=hive, access=WRITE, inode="/home/chen/hive/warehouse/test_table_double":chen:supergroup:drwxr-xr-x
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.check(FSPermissionChecker.java:308)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:214)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:190)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkPermission(FSDirectory.java:1752)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkPermission(FSDirectory.java:1736)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkAncestorAccess(FSDirectory.java:1719)
	at org.apache.hadoop.hdfs.server.namenode.FSDirMkdirOp.mkdirs(FSDirMkdirOp.java:69)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.mkdirs(FSNamesystem.java:3867)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.mkdirs(NameNodeRpcServer.java:984)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.mkdirs(ClientNamenodeProtocolServerSideTranslatorPB.java:634)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:616)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:982)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2217)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2213)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1754)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2213)

	at org.apache.hive.jdbc.HiveStatement.execute(HiveStatement.java:296)
	at org.apache.hive.jdbc.HivePreparedStatement.execute(HivePreparedStatement.java:98)
	at com.mchange.v2.c3p0.impl.NewProxyPreparedStatement.execute(NewProxyPreparedStatement.java:67)
	at com.inspur.pmv6.dao.HiveDao.executesql(HiveDao.java:152)
	at com.inspur.pmv6.Entrance.lambda$null$0(Entrance.java:83)
	at java.util.stream.Streams$RangeIntSpliterator.forEachRemaining(Streams.java:110)
	at java.util.stream.IntPipeline$Head.forEach(IntPipeline.java:557)
	at com.inspur.pmv6.Entrance.lambda$myTestCodes$1(Entrance.java:76)
	at java.util.stream.Streams$RangeIntSpliterator.forEachRemaining(Streams.java:110)
	at java.util.stream.IntPipeline$Head.forEach(IntPipeline.java:557)
	at com.inspur.pmv6.Entrance.myTestCodes(Entrance.java:74)
	at com.inspur.pmv6.Entrance.main(Entrance.java:43)
[0328 17:17:57 849 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29utxrumz1kq9f8v|80ec1f8]-HelperThread-#2] hive.jdbc.Utils - Resolved authority: 10.211.55.29:10000
[0328 17:17:57 850 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29utxrumz1kq9f8v|80ec1f8]-HelperThread-#2] hive.jdbc.HiveConnection - Will try to open client transport with JDBC Uri: jdbc:hive2://10.211.55.29:10000/default
[0328 17:17:57 857 INFO ] [main] pmv6.dao.HiveDao - start to execute the sql :insert into test_table_double values (20180331, 010000, 70.98756173402104)
[0328 17:17:57 978 ERROR] [main] pmv6.dao.HiveDao - ERROR SQL: insert into test_table_double values (20180331, 010000, 70.98756173402104)
[0328 17:17:57 978 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29utxrumz1kq9f8v|80ec1f8]-HelperThread-#1] hive.jdbc.Utils - Supplied authorities: 10.211.55.29:10000
[0328 17:17:57 978 ERROR] [main] pmv6.dao.HiveDao - java.lang.RuntimeException: Cannot create staging directory 'hdfs://localhost:9000/home/chen/hive/warehouse/test_table_double/.hive-staging_hive_2018-03-28_02-17-57_899_7883595263210560343-25': Permission denied: user=hive, access=WRITE, inode="/home/chen/hive/warehouse/test_table_double":chen:supergroup:drwxr-xr-x
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.check(FSPermissionChecker.java:308)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:214)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:190)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkPermission(FSDirectory.java:1752)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkPermission(FSDirectory.java:1736)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkAncestorAccess(FSDirectory.java:1719)
	at org.apache.hadoop.hdfs.server.namenode.FSDirMkdirOp.mkdirs(FSDirMkdirOp.java:69)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.mkdirs(FSNamesystem.java:3867)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.mkdirs(NameNodeRpcServer.java:984)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.mkdirs(ClientNamenodeProtocolServerSideTranslatorPB.java:634)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:616)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:982)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2217)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2213)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1754)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2213)

java.sql.SQLException: java.lang.RuntimeException: Cannot create staging directory 'hdfs://localhost:9000/home/chen/hive/warehouse/test_table_double/.hive-staging_hive_2018-03-28_02-17-57_899_7883595263210560343-25': Permission denied: user=hive, access=WRITE, inode="/home/chen/hive/warehouse/test_table_double":chen:supergroup:drwxr-xr-x
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.check(FSPermissionChecker.java:308)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:214)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:190)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkPermission(FSDirectory.java:1752)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkPermission(FSDirectory.java:1736)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkAncestorAccess(FSDirectory.java:1719)
	at org.apache.hadoop.hdfs.server.namenode.FSDirMkdirOp.mkdirs(FSDirMkdirOp.java:69)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.mkdirs(FSNamesystem.java:3867)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.mkdirs(NameNodeRpcServer.java:984)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.mkdirs(ClientNamenodeProtocolServerSideTranslatorPB.java:634)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:616)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:982)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2217)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2213)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1754)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2213)

	at org.apache.hive.jdbc.HiveStatement.execute(HiveStatement.java:296)
	at org.apache.hive.jdbc.HivePreparedStatement.execute(HivePreparedStatement.java:98)
	at com.mchange.v2.c3p0.impl.NewProxyPreparedStatement.execute(NewProxyPreparedStatement.java:67)
	at com.inspur.pmv6.dao.HiveDao.executesql(HiveDao.java:152)
	at com.inspur.pmv6.Entrance.lambda$null$0(Entrance.java:83)
	at java.util.stream.Streams$RangeIntSpliterator.forEachRemaining(Streams.java:110)
	at java.util.stream.IntPipeline$Head.forEach(IntPipeline.java:557)
	at com.inspur.pmv6.Entrance.lambda$myTestCodes$1(Entrance.java:76)
	at java.util.stream.Streams$RangeIntSpliterator.forEachRemaining(Streams.java:110)
	at java.util.stream.IntPipeline$Head.forEach(IntPipeline.java:557)
	at com.inspur.pmv6.Entrance.myTestCodes(Entrance.java:74)
	at com.inspur.pmv6.Entrance.main(Entrance.java:43)
[0328 17:17:57 978 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29utxrumz1kq9f8v|80ec1f8]-HelperThread-#1] hive.jdbc.Utils - Resolved authority: 10.211.55.29:10000
[0328 17:17:57 979 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29utxrumz1kq9f8v|80ec1f8]-HelperThread-#1] hive.jdbc.HiveConnection - Will try to open client transport with JDBC Uri: jdbc:hive2://10.211.55.29:10000/default
[0328 17:17:57 979 INFO ] [main] pmv6.dao.HiveDao - start to execute the sql :insert into test_table_double values (20180331, 020000, 58.469408413701494)
[0328 17:17:58 275 ERROR] [main] pmv6.dao.HiveDao - ERROR SQL: insert into test_table_double values (20180331, 020000, 58.469408413701494)
[0328 17:17:58 275 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29utxrumz1kq9f8v|80ec1f8]-HelperThread-#1] hive.jdbc.Utils - Supplied authorities: 10.211.55.29:10000
[0328 17:17:58 276 ERROR] [main] pmv6.dao.HiveDao - java.lang.RuntimeException: Cannot create staging directory 'hdfs://localhost:9000/home/chen/hive/warehouse/test_table_double/.hive-staging_hive_2018-03-28_02-17-58_200_1935260806963605140-26': Permission denied: user=hive, access=WRITE, inode="/home/chen/hive/warehouse/test_table_double":chen:supergroup:drwxr-xr-x
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.check(FSPermissionChecker.java:308)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:214)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:190)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkPermission(FSDirectory.java:1752)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkPermission(FSDirectory.java:1736)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkAncestorAccess(FSDirectory.java:1719)
	at org.apache.hadoop.hdfs.server.namenode.FSDirMkdirOp.mkdirs(FSDirMkdirOp.java:69)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.mkdirs(FSNamesystem.java:3867)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.mkdirs(NameNodeRpcServer.java:984)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.mkdirs(ClientNamenodeProtocolServerSideTranslatorPB.java:634)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:616)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:982)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2217)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2213)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1754)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2213)

java.sql.SQLException: java.lang.RuntimeException: Cannot create staging directory 'hdfs://localhost:9000/home/chen/hive/warehouse/test_table_double/.hive-staging_hive_2018-03-28_02-17-58_200_1935260806963605140-26': Permission denied: user=hive, access=WRITE, inode="/home/chen/hive/warehouse/test_table_double":chen:supergroup:drwxr-xr-x
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.check(FSPermissionChecker.java:308)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:214)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:190)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkPermission(FSDirectory.java:1752)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkPermission(FSDirectory.java:1736)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkAncestorAccess(FSDirectory.java:1719)
	at org.apache.hadoop.hdfs.server.namenode.FSDirMkdirOp.mkdirs(FSDirMkdirOp.java:69)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.mkdirs(FSNamesystem.java:3867)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.mkdirs(NameNodeRpcServer.java:984)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.mkdirs(ClientNamenodeProtocolServerSideTranslatorPB.java:634)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:616)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:982)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2217)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2213)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1754)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2213)

	at org.apache.hive.jdbc.HiveStatement.execute(HiveStatement.java:296)
	at org.apache.hive.jdbc.HivePreparedStatement.execute(HivePreparedStatement.java:98)
	at com.mchange.v2.c3p0.impl.NewProxyPreparedStatement.execute(NewProxyPreparedStatement.java:67)
	at com.inspur.pmv6.dao.HiveDao.executesql(HiveDao.java:152)
	at com.inspur.pmv6.Entrance.lambda$null$0(Entrance.java:83)
	at java.util.stream.Streams$RangeIntSpliterator.forEachRemaining(Streams.java:110)
	at java.util.stream.IntPipeline$Head.forEach(IntPipeline.java:557)
	at com.inspur.pmv6.Entrance.lambda$myTestCodes$1(Entrance.java:76)
	at java.util.stream.Streams$RangeIntSpliterator.forEachRemaining(Streams.java:110)
	at java.util.stream.IntPipeline$Head.forEach(IntPipeline.java:557)
	at com.inspur.pmv6.Entrance.myTestCodes(Entrance.java:74)
	at com.inspur.pmv6.Entrance.main(Entrance.java:43)
[0328 17:17:58 276 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29utxrumz1kq9f8v|80ec1f8]-HelperThread-#1] hive.jdbc.Utils - Resolved authority: 10.211.55.29:10000
[0328 17:17:58 276 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29utxrumz1kq9f8v|80ec1f8]-HelperThread-#1] hive.jdbc.HiveConnection - Will try to open client transport with JDBC Uri: jdbc:hive2://10.211.55.29:10000/default
[0328 17:17:58 277 INFO ] [main] pmv6.dao.HiveDao - start to execute the sql :insert into test_table_double values (20180331, 030000, 87.0139173829259)
[0328 17:17:58 391 ERROR] [main] pmv6.dao.HiveDao - ERROR SQL: insert into test_table_double values (20180331, 030000, 87.0139173829259)
[0328 17:17:58 391 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29utxrumz1kq9f8v|80ec1f8]-HelperThread-#0] hive.jdbc.Utils - Supplied authorities: 10.211.55.29:10000
[0328 17:17:58 391 ERROR] [main] pmv6.dao.HiveDao - java.lang.RuntimeException: Cannot create staging directory 'hdfs://localhost:9000/home/chen/hive/warehouse/test_table_double/.hive-staging_hive_2018-03-28_02-17-58_316_326471449885731497-27': Permission denied: user=hive, access=WRITE, inode="/home/chen/hive/warehouse/test_table_double":chen:supergroup:drwxr-xr-x
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.check(FSPermissionChecker.java:308)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:214)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:190)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkPermission(FSDirectory.java:1752)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkPermission(FSDirectory.java:1736)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkAncestorAccess(FSDirectory.java:1719)
	at org.apache.hadoop.hdfs.server.namenode.FSDirMkdirOp.mkdirs(FSDirMkdirOp.java:69)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.mkdirs(FSNamesystem.java:3867)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.mkdirs(NameNodeRpcServer.java:984)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.mkdirs(ClientNamenodeProtocolServerSideTranslatorPB.java:634)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:616)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:982)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2217)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2213)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1754)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2213)

java.sql.SQLException: java.lang.RuntimeException: Cannot create staging directory 'hdfs://localhost:9000/home/chen/hive/warehouse/test_table_double/.hive-staging_hive_2018-03-28_02-17-58_316_326471449885731497-27': Permission denied: user=hive, access=WRITE, inode="/home/chen/hive/warehouse/test_table_double":chen:supergroup:drwxr-xr-x
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.check(FSPermissionChecker.java:308)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:214)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:190)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkPermission(FSDirectory.java:1752)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkPermission(FSDirectory.java:1736)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkAncestorAccess(FSDirectory.java:1719)
	at org.apache.hadoop.hdfs.server.namenode.FSDirMkdirOp.mkdirs(FSDirMkdirOp.java:69)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.mkdirs(FSNamesystem.java:3867)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.mkdirs(NameNodeRpcServer.java:984)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.mkdirs(ClientNamenodeProtocolServerSideTranslatorPB.java:634)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:616)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:982)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2217)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2213)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1754)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2213)

	at org.apache.hive.jdbc.HiveStatement.execute(HiveStatement.java:296)
	at org.apache.hive.jdbc.HivePreparedStatement.execute(HivePreparedStatement.java:98)
	at com.mchange.v2.c3p0.impl.NewProxyPreparedStatement.execute(NewProxyPreparedStatement.java:67)
	at com.inspur.pmv6.dao.HiveDao.executesql(HiveDao.java:152)
	at com.inspur.pmv6.Entrance.lambda$null$0(Entrance.java:83)
	at java.util.stream.Streams$RangeIntSpliterator.forEachRemaining(Streams.java:110)
	at java.util.stream.IntPipeline$Head.forEach(IntPipeline.java:557)
	at com.inspur.pmv6.Entrance.lambda$myTestCodes$1(Entrance.java:76)
	at java.util.stream.Streams$RangeIntSpliterator.forEachRemaining(Streams.java:110)
	at java.util.stream.IntPipeline$Head.forEach(IntPipeline.java:557)
	at com.inspur.pmv6.Entrance.myTestCodes(Entrance.java:74)
	at com.inspur.pmv6.Entrance.main(Entrance.java:43)
[0328 17:17:58 392 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29utxrumz1kq9f8v|80ec1f8]-HelperThread-#0] hive.jdbc.Utils - Resolved authority: 10.211.55.29:10000
[0328 17:17:58 392 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29utxrumz1kq9f8v|80ec1f8]-HelperThread-#0] hive.jdbc.HiveConnection - Will try to open client transport with JDBC Uri: jdbc:hive2://10.211.55.29:10000/default
[0328 17:17:58 393 INFO ] [main] pmv6.dao.HiveDao - start to execute the sql :insert into test_table_double values (20180331, 040000, 45.452944334099875)
[0328 17:17:58 677 ERROR] [main] pmv6.dao.HiveDao - ERROR SQL: insert into test_table_double values (20180331, 040000, 45.452944334099875)
[0328 17:17:58 677 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29utxrumz1kq9f8v|80ec1f8]-HelperThread-#0] hive.jdbc.Utils - Supplied authorities: 10.211.55.29:10000
[0328 17:17:58 677 ERROR] [main] pmv6.dao.HiveDao - java.lang.RuntimeException: Cannot create staging directory 'hdfs://localhost:9000/home/chen/hive/warehouse/test_table_double/.hive-staging_hive_2018-03-28_02-17-58_606_1621271898744035569-28': Permission denied: user=hive, access=WRITE, inode="/home/chen/hive/warehouse/test_table_double":chen:supergroup:drwxr-xr-x
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.check(FSPermissionChecker.java:308)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:214)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:190)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkPermission(FSDirectory.java:1752)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkPermission(FSDirectory.java:1736)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkAncestorAccess(FSDirectory.java:1719)
	at org.apache.hadoop.hdfs.server.namenode.FSDirMkdirOp.mkdirs(FSDirMkdirOp.java:69)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.mkdirs(FSNamesystem.java:3867)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.mkdirs(NameNodeRpcServer.java:984)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.mkdirs(ClientNamenodeProtocolServerSideTranslatorPB.java:634)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:616)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:982)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2217)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2213)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1754)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2213)

java.sql.SQLException: java.lang.RuntimeException: Cannot create staging directory 'hdfs://localhost:9000/home/chen/hive/warehouse/test_table_double/.hive-staging_hive_2018-03-28_02-17-58_606_1621271898744035569-28': Permission denied: user=hive, access=WRITE, inode="/home/chen/hive/warehouse/test_table_double":chen:supergroup:drwxr-xr-x
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.check(FSPermissionChecker.java:308)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:214)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:190)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkPermission(FSDirectory.java:1752)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkPermission(FSDirectory.java:1736)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkAncestorAccess(FSDirectory.java:1719)
	at org.apache.hadoop.hdfs.server.namenode.FSDirMkdirOp.mkdirs(FSDirMkdirOp.java:69)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.mkdirs(FSNamesystem.java:3867)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.mkdirs(NameNodeRpcServer.java:984)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.mkdirs(ClientNamenodeProtocolServerSideTranslatorPB.java:634)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:616)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:982)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2217)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2213)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1754)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2213)

	at org.apache.hive.jdbc.HiveStatement.execute(HiveStatement.java:296)
	at org.apache.hive.jdbc.HivePreparedStatement.execute(HivePreparedStatement.java:98)
	at com.mchange.v2.c3p0.impl.NewProxyPreparedStatement.execute(NewProxyPreparedStatement.java:67)
	at com.inspur.pmv6.dao.HiveDao.executesql(HiveDao.java:152)
	at com.inspur.pmv6.Entrance.lambda$null$0(Entrance.java:83)
	at java.util.stream.Streams$RangeIntSpliterator.forEachRemaining(Streams.java:110)
	at java.util.stream.IntPipeline$Head.forEach(IntPipeline.java:557)
	at com.inspur.pmv6.Entrance.lambda$myTestCodes$1(Entrance.java:76)
	at java.util.stream.Streams$RangeIntSpliterator.forEachRemaining(Streams.java:110)
	at java.util.stream.IntPipeline$Head.forEach(IntPipeline.java:557)
	at com.inspur.pmv6.Entrance.myTestCodes(Entrance.java:74)
	at com.inspur.pmv6.Entrance.main(Entrance.java:43)
[0328 17:17:58 678 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29utxrumz1kq9f8v|80ec1f8]-HelperThread-#0] hive.jdbc.Utils - Resolved authority: 10.211.55.29:10000
[0328 17:17:58 678 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29utxrumz1kq9f8v|80ec1f8]-HelperThread-#0] hive.jdbc.HiveConnection - Will try to open client transport with JDBC Uri: jdbc:hive2://10.211.55.29:10000/default
[0328 17:17:58 679 INFO ] [main] pmv6.dao.HiveDao - start to execute the sql :insert into test_table_double values (20180331, 050000, 88.94838323822624)
[0328 17:17:58 798 ERROR] [main] pmv6.dao.HiveDao - ERROR SQL: insert into test_table_double values (20180331, 050000, 88.94838323822624)
[0328 17:17:58 798 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29utxrumz1kq9f8v|80ec1f8]-HelperThread-#2] hive.jdbc.Utils - Supplied authorities: 10.211.55.29:10000
[0328 17:17:58 798 ERROR] [main] pmv6.dao.HiveDao - java.lang.RuntimeException: Cannot create staging directory 'hdfs://localhost:9000/home/chen/hive/warehouse/test_table_double/.hive-staging_hive_2018-03-28_02-17-58_723_1788380639961610492-29': Permission denied: user=hive, access=WRITE, inode="/home/chen/hive/warehouse/test_table_double":chen:supergroup:drwxr-xr-x
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.check(FSPermissionChecker.java:308)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:214)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:190)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkPermission(FSDirectory.java:1752)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkPermission(FSDirectory.java:1736)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkAncestorAccess(FSDirectory.java:1719)
	at org.apache.hadoop.hdfs.server.namenode.FSDirMkdirOp.mkdirs(FSDirMkdirOp.java:69)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.mkdirs(FSNamesystem.java:3867)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.mkdirs(NameNodeRpcServer.java:984)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.mkdirs(ClientNamenodeProtocolServerSideTranslatorPB.java:634)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:616)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:982)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2217)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2213)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1754)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2213)

java.sql.SQLException: java.lang.RuntimeException: Cannot create staging directory 'hdfs://localhost:9000/home/chen/hive/warehouse/test_table_double/.hive-staging_hive_2018-03-28_02-17-58_723_1788380639961610492-29': Permission denied: user=hive, access=WRITE, inode="/home/chen/hive/warehouse/test_table_double":chen:supergroup:drwxr-xr-x
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.check(FSPermissionChecker.java:308)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:214)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:190)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkPermission(FSDirectory.java:1752)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkPermission(FSDirectory.java:1736)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkAncestorAccess(FSDirectory.java:1719)
	at org.apache.hadoop.hdfs.server.namenode.FSDirMkdirOp.mkdirs(FSDirMkdirOp.java:69)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.mkdirs(FSNamesystem.java:3867)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.mkdirs(NameNodeRpcServer.java:984)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.mkdirs(ClientNamenodeProtocolServerSideTranslatorPB.java:634)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:616)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:982)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2217)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2213)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1754)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2213)

	at org.apache.hive.jdbc.HiveStatement.execute(HiveStatement.java:296)
	at org.apache.hive.jdbc.HivePreparedStatement.execute(HivePreparedStatement.java:98)
	at com.mchange.v2.c3p0.impl.NewProxyPreparedStatement.execute(NewProxyPreparedStatement.java:67)
	at com.inspur.pmv6.dao.HiveDao.executesql(HiveDao.java:152)
	at com.inspur.pmv6.Entrance.lambda$null$0(Entrance.java:83)
	at java.util.stream.Streams$RangeIntSpliterator.forEachRemaining(Streams.java:110)
	at java.util.stream.IntPipeline$Head.forEach(IntPipeline.java:557)
	at com.inspur.pmv6.Entrance.lambda$myTestCodes$1(Entrance.java:76)
	at java.util.stream.Streams$RangeIntSpliterator.forEachRemaining(Streams.java:110)
	at java.util.stream.IntPipeline$Head.forEach(IntPipeline.java:557)
	at com.inspur.pmv6.Entrance.myTestCodes(Entrance.java:74)
	at com.inspur.pmv6.Entrance.main(Entrance.java:43)
[0328 17:17:58 798 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29utxrumz1kq9f8v|80ec1f8]-HelperThread-#2] hive.jdbc.Utils - Resolved authority: 10.211.55.29:10000
[0328 17:17:58 799 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29utxrumz1kq9f8v|80ec1f8]-HelperThread-#2] hive.jdbc.HiveConnection - Will try to open client transport with JDBC Uri: jdbc:hive2://10.211.55.29:10000/default
[0328 17:17:58 799 INFO ] [main] pmv6.dao.HiveDao - start to execute the sql :insert into test_table_double values (20180331, 060000, 15.573057751204578)
[0328 17:17:59 048 ERROR] [main] pmv6.dao.HiveDao - ERROR SQL: insert into test_table_double values (20180331, 060000, 15.573057751204578)
[0328 17:17:59 048 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29utxrumz1kq9f8v|80ec1f8]-HelperThread-#2] hive.jdbc.Utils - Supplied authorities: 10.211.55.29:10000
[0328 17:17:59 048 ERROR] [main] pmv6.dao.HiveDao - java.lang.RuntimeException: Cannot create staging directory 'hdfs://localhost:9000/home/chen/hive/warehouse/test_table_double/.hive-staging_hive_2018-03-28_02-17-58_970_1841142280828185802-30': Permission denied: user=hive, access=WRITE, inode="/home/chen/hive/warehouse/test_table_double":chen:supergroup:drwxr-xr-x
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.check(FSPermissionChecker.java:308)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:214)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:190)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkPermission(FSDirectory.java:1752)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkPermission(FSDirectory.java:1736)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkAncestorAccess(FSDirectory.java:1719)
	at org.apache.hadoop.hdfs.server.namenode.FSDirMkdirOp.mkdirs(FSDirMkdirOp.java:69)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.mkdirs(FSNamesystem.java:3867)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.mkdirs(NameNodeRpcServer.java:984)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.mkdirs(ClientNamenodeProtocolServerSideTranslatorPB.java:634)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:616)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:982)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2217)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2213)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1754)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2213)

java.sql.SQLException: java.lang.RuntimeException: Cannot create staging directory 'hdfs://localhost:9000/home/chen/hive/warehouse/test_table_double/.hive-staging_hive_2018-03-28_02-17-58_970_1841142280828185802-30': Permission denied: user=hive, access=WRITE, inode="/home/chen/hive/warehouse/test_table_double":chen:supergroup:drwxr-xr-x
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.check(FSPermissionChecker.java:308)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:214)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:190)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkPermission(FSDirectory.java:1752)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkPermission(FSDirectory.java:1736)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkAncestorAccess(FSDirectory.java:1719)
	at org.apache.hadoop.hdfs.server.namenode.FSDirMkdirOp.mkdirs(FSDirMkdirOp.java:69)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.mkdirs(FSNamesystem.java:3867)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.mkdirs(NameNodeRpcServer.java:984)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.mkdirs(ClientNamenodeProtocolServerSideTranslatorPB.java:634)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:616)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:982)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2217)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2213)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1754)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2213)

	at org.apache.hive.jdbc.HiveStatement.execute(HiveStatement.java:296)
	at org.apache.hive.jdbc.HivePreparedStatement.execute(HivePreparedStatement.java:98)
	at com.mchange.v2.c3p0.impl.NewProxyPreparedStatement.execute(NewProxyPreparedStatement.java:67)
	at com.inspur.pmv6.dao.HiveDao.executesql(HiveDao.java:152)
	at com.inspur.pmv6.Entrance.lambda$null$0(Entrance.java:83)
	at java.util.stream.Streams$RangeIntSpliterator.forEachRemaining(Streams.java:110)
	at java.util.stream.IntPipeline$Head.forEach(IntPipeline.java:557)
	at com.inspur.pmv6.Entrance.lambda$myTestCodes$1(Entrance.java:76)
	at java.util.stream.Streams$RangeIntSpliterator.forEachRemaining(Streams.java:110)
	at java.util.stream.IntPipeline$Head.forEach(IntPipeline.java:557)
	at com.inspur.pmv6.Entrance.myTestCodes(Entrance.java:74)
	at com.inspur.pmv6.Entrance.main(Entrance.java:43)
[0328 17:17:59 049 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29utxrumz1kq9f8v|80ec1f8]-HelperThread-#2] hive.jdbc.Utils - Resolved authority: 10.211.55.29:10000
[0328 17:17:59 049 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29utxrumz1kq9f8v|80ec1f8]-HelperThread-#2] hive.jdbc.HiveConnection - Will try to open client transport with JDBC Uri: jdbc:hive2://10.211.55.29:10000/default
[0328 17:17:59 050 INFO ] [main] pmv6.dao.HiveDao - start to execute the sql :insert into test_table_double values (20180331, 070000, 70.34271643661573)
[0328 17:17:59 164 ERROR] [main] pmv6.dao.HiveDao - ERROR SQL: insert into test_table_double values (20180331, 070000, 70.34271643661573)
[0328 17:17:59 164 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29utxrumz1kq9f8v|80ec1f8]-HelperThread-#1] hive.jdbc.Utils - Supplied authorities: 10.211.55.29:10000
[0328 17:17:59 165 ERROR] [main] pmv6.dao.HiveDao - java.lang.RuntimeException: Cannot create staging directory 'hdfs://localhost:9000/home/chen/hive/warehouse/test_table_double/.hive-staging_hive_2018-03-28_02-17-59_090_6658612151709490690-31': Permission denied: user=hive, access=WRITE, inode="/home/chen/hive/warehouse/test_table_double":chen:supergroup:drwxr-xr-x
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.check(FSPermissionChecker.java:308)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:214)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:190)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkPermission(FSDirectory.java:1752)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkPermission(FSDirectory.java:1736)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkAncestorAccess(FSDirectory.java:1719)
	at org.apache.hadoop.hdfs.server.namenode.FSDirMkdirOp.mkdirs(FSDirMkdirOp.java:69)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.mkdirs(FSNamesystem.java:3867)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.mkdirs(NameNodeRpcServer.java:984)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.mkdirs(ClientNamenodeProtocolServerSideTranslatorPB.java:634)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:616)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:982)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2217)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2213)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1754)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2213)

java.sql.SQLException: java.lang.RuntimeException: Cannot create staging directory 'hdfs://localhost:9000/home/chen/hive/warehouse/test_table_double/.hive-staging_hive_2018-03-28_02-17-59_090_6658612151709490690-31': Permission denied: user=hive, access=WRITE, inode="/home/chen/hive/warehouse/test_table_double":chen:supergroup:drwxr-xr-x
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.check(FSPermissionChecker.java:308)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:214)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:190)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkPermission(FSDirectory.java:1752)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkPermission(FSDirectory.java:1736)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkAncestorAccess(FSDirectory.java:1719)
	at org.apache.hadoop.hdfs.server.namenode.FSDirMkdirOp.mkdirs(FSDirMkdirOp.java:69)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.mkdirs(FSNamesystem.java:3867)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.mkdirs(NameNodeRpcServer.java:984)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.mkdirs(ClientNamenodeProtocolServerSideTranslatorPB.java:634)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:616)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:982)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2217)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2213)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1754)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2213)

	at org.apache.hive.jdbc.HiveStatement.execute(HiveStatement.java:296)
	at org.apache.hive.jdbc.HivePreparedStatement.execute(HivePreparedStatement.java:98)
	at com.mchange.v2.c3p0.impl.NewProxyPreparedStatement.execute(NewProxyPreparedStatement.java:67)
	at com.inspur.pmv6.dao.HiveDao.executesql(HiveDao.java:152)
	at com.inspur.pmv6.Entrance.lambda$null$0(Entrance.java:83)
	at java.util.stream.Streams$RangeIntSpliterator.forEachRemaining(Streams.java:110)
	at java.util.stream.IntPipeline$Head.forEach(IntPipeline.java:557)
	at com.inspur.pmv6.Entrance.lambda$myTestCodes$1(Entrance.java:76)
	at java.util.stream.Streams$RangeIntSpliterator.forEachRemaining(Streams.java:110)
	at java.util.stream.IntPipeline$Head.forEach(IntPipeline.java:557)
	at com.inspur.pmv6.Entrance.myTestCodes(Entrance.java:74)
	at com.inspur.pmv6.Entrance.main(Entrance.java:43)
[0328 17:17:59 165 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29utxrumz1kq9f8v|80ec1f8]-HelperThread-#1] hive.jdbc.Utils - Resolved authority: 10.211.55.29:10000
[0328 17:17:59 165 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29utxrumz1kq9f8v|80ec1f8]-HelperThread-#1] hive.jdbc.HiveConnection - Will try to open client transport with JDBC Uri: jdbc:hive2://10.211.55.29:10000/default
[0328 17:17:59 166 INFO ] [main] pmv6.dao.HiveDao - start to execute the sql :insert into test_table_double values (20180331, 080000, 25.72665820041451)
[0328 17:17:59 418 ERROR] [main] pmv6.dao.HiveDao - ERROR SQL: insert into test_table_double values (20180331, 080000, 25.72665820041451)
[0328 17:17:59 418 ERROR] [main] pmv6.dao.HiveDao - java.lang.RuntimeException: Cannot create staging directory 'hdfs://localhost:9000/home/chen/hive/warehouse/test_table_double/.hive-staging_hive_2018-03-28_02-17-59_337_3725309394358195604-32': Permission denied: user=hive, access=WRITE, inode="/home/chen/hive/warehouse/test_table_double":chen:supergroup:drwxr-xr-x
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.check(FSPermissionChecker.java:308)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:214)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:190)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkPermission(FSDirectory.java:1752)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkPermission(FSDirectory.java:1736)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkAncestorAccess(FSDirectory.java:1719)
	at org.apache.hadoop.hdfs.server.namenode.FSDirMkdirOp.mkdirs(FSDirMkdirOp.java:69)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.mkdirs(FSNamesystem.java:3867)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.mkdirs(NameNodeRpcServer.java:984)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.mkdirs(ClientNamenodeProtocolServerSideTranslatorPB.java:634)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:616)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:982)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2217)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2213)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1754)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2213)

java.sql.SQLException: java.lang.RuntimeException: Cannot create staging directory 'hdfs://localhost:9000/home/chen/hive/warehouse/test_table_double/.hive-staging_hive_2018-03-28_02-17-59_337_3725309394358195604-32': Permission denied: user=hive, access=WRITE, inode="/home/chen/hive/warehouse/test_table_double":chen:supergroup:drwxr-xr-x
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.check(FSPermissionChecker.java:308)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:214)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:190)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkPermission(FSDirectory.java:1752)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkPermission(FSDirectory.java:1736)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkAncestorAccess(FSDirectory.java:1719)
	at org.apache.hadoop.hdfs.server.namenode.FSDirMkdirOp.mkdirs(FSDirMkdirOp.java:69)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.mkdirs(FSNamesystem.java:3867)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.mkdirs(NameNodeRpcServer.java:984)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.mkdirs(ClientNamenodeProtocolServerSideTranslatorPB.java:634)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:616)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:982)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2217)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2213)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1754)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2213)

	at org.apache.hive.jdbc.HiveStatement.execute(HiveStatement.java:296)
	at org.apache.hive.jdbc.HivePreparedStatement.execute(HivePreparedStatement.java:98)
	at com.mchange.v2.c3p0.impl.NewProxyPreparedStatement.execute(NewProxyPreparedStatement.java:67)
	at com.inspur.pmv6.dao.HiveDao.executesql(HiveDao.java:152)
	at com.inspur.pmv6.Entrance.lambda$null$0(Entrance.java:83)
	at java.util.stream.Streams$RangeIntSpliterator.forEachRemaining(Streams.java:110)
	at java.util.stream.IntPipeline$Head.forEach(IntPipeline.java:557)
	at com.inspur.pmv6.Entrance.lambda$myTestCodes$1(Entrance.java:76)
	at java.util.stream.Streams$RangeIntSpliterator.forEachRemaining(Streams.java:110)
	at java.util.stream.IntPipeline$Head.forEach(IntPipeline.java:557)
	at com.inspur.pmv6.Entrance.myTestCodes(Entrance.java:74)
	at com.inspur.pmv6.Entrance.main(Entrance.java:43)
[0328 17:17:59 418 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29utxrumz1kq9f8v|80ec1f8]-HelperThread-#2] hive.jdbc.Utils - Supplied authorities: 10.211.55.29:10000
[0328 17:17:59 418 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29utxrumz1kq9f8v|80ec1f8]-HelperThread-#2] hive.jdbc.Utils - Resolved authority: 10.211.55.29:10000
[0328 17:17:59 419 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29utxrumz1kq9f8v|80ec1f8]-HelperThread-#2] hive.jdbc.HiveConnection - Will try to open client transport with JDBC Uri: jdbc:hive2://10.211.55.29:10000/default
[0328 17:17:59 419 INFO ] [main] pmv6.dao.HiveDao - start to execute the sql :insert into test_table_double values (20180331, 090000, 77.87254878418713)
[0328 17:17:59 623 ERROR] [main] pmv6.dao.HiveDao - ERROR SQL: insert into test_table_double values (20180331, 090000, 77.87254878418713)
[0328 17:17:59 623 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29utxrumz1kq9f8v|80ec1f8]-HelperThread-#1] hive.jdbc.Utils - Supplied authorities: 10.211.55.29:10000
[0328 17:17:59 623 ERROR] [main] pmv6.dao.HiveDao - java.lang.RuntimeException: Cannot create staging directory 'hdfs://localhost:9000/home/chen/hive/warehouse/test_table_double/.hive-staging_hive_2018-03-28_02-17-59_540_8069371756525574907-33': Permission denied: user=hive, access=WRITE, inode="/home/chen/hive/warehouse/test_table_double":chen:supergroup:drwxr-xr-x
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.check(FSPermissionChecker.java:308)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:214)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:190)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkPermission(FSDirectory.java:1752)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkPermission(FSDirectory.java:1736)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkAncestorAccess(FSDirectory.java:1719)
	at org.apache.hadoop.hdfs.server.namenode.FSDirMkdirOp.mkdirs(FSDirMkdirOp.java:69)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.mkdirs(FSNamesystem.java:3867)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.mkdirs(NameNodeRpcServer.java:984)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.mkdirs(ClientNamenodeProtocolServerSideTranslatorPB.java:634)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:616)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:982)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2217)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2213)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1754)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2213)

java.sql.SQLException: java.lang.RuntimeException: Cannot create staging directory 'hdfs://localhost:9000/home/chen/hive/warehouse/test_table_double/.hive-staging_hive_2018-03-28_02-17-59_540_8069371756525574907-33': Permission denied: user=hive, access=WRITE, inode="/home/chen/hive/warehouse/test_table_double":chen:supergroup:drwxr-xr-x
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.check(FSPermissionChecker.java:308)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:214)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:190)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkPermission(FSDirectory.java:1752)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkPermission(FSDirectory.java:1736)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkAncestorAccess(FSDirectory.java:1719)
	at org.apache.hadoop.hdfs.server.namenode.FSDirMkdirOp.mkdirs(FSDirMkdirOp.java:69)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.mkdirs(FSNamesystem.java:3867)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.mkdirs(NameNodeRpcServer.java:984)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.mkdirs(ClientNamenodeProtocolServerSideTranslatorPB.java:634)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:616)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:982)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2217)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2213)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1754)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2213)

	at org.apache.hive.jdbc.HiveStatement.execute(HiveStatement.java:296)
	at org.apache.hive.jdbc.HivePreparedStatement.execute(HivePreparedStatement.java:98)
	at com.mchange.v2.c3p0.impl.NewProxyPreparedStatement.execute(NewProxyPreparedStatement.java:67)
	at com.inspur.pmv6.dao.HiveDao.executesql(HiveDao.java:152)
	at com.inspur.pmv6.Entrance.lambda$null$0(Entrance.java:83)
	at java.util.stream.Streams$RangeIntSpliterator.forEachRemaining(Streams.java:110)
	at java.util.stream.IntPipeline$Head.forEach(IntPipeline.java:557)
	at com.inspur.pmv6.Entrance.lambda$myTestCodes$1(Entrance.java:76)
	at java.util.stream.Streams$RangeIntSpliterator.forEachRemaining(Streams.java:110)
	at java.util.stream.IntPipeline$Head.forEach(IntPipeline.java:557)
	at com.inspur.pmv6.Entrance.myTestCodes(Entrance.java:74)
	at com.inspur.pmv6.Entrance.main(Entrance.java:43)
[0328 17:17:59 624 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29utxrumz1kq9f8v|80ec1f8]-HelperThread-#1] hive.jdbc.Utils - Resolved authority: 10.211.55.29:10000
[0328 17:17:59 624 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29utxrumz1kq9f8v|80ec1f8]-HelperThread-#1] hive.jdbc.HiveConnection - Will try to open client transport with JDBC Uri: jdbc:hive2://10.211.55.29:10000/default
[0328 17:17:59 625 INFO ] [main] pmv6.dao.HiveDao - start to execute the sql :insert into test_table_double values (20180331, 100000, 11.49564762298022)
[0328 17:17:59 743 ERROR] [main] pmv6.dao.HiveDao - ERROR SQL: insert into test_table_double values (20180331, 100000, 11.49564762298022)
[0328 17:17:59 743 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29utxrumz1kq9f8v|80ec1f8]-HelperThread-#0] hive.jdbc.Utils - Supplied authorities: 10.211.55.29:10000
[0328 17:17:59 743 ERROR] [main] pmv6.dao.HiveDao - java.lang.RuntimeException: Cannot create staging directory 'hdfs://localhost:9000/home/chen/hive/warehouse/test_table_double/.hive-staging_hive_2018-03-28_02-17-59_670_5731724910545943572-34': Permission denied: user=hive, access=WRITE, inode="/home/chen/hive/warehouse/test_table_double":chen:supergroup:drwxr-xr-x
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.check(FSPermissionChecker.java:308)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:214)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:190)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkPermission(FSDirectory.java:1752)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkPermission(FSDirectory.java:1736)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkAncestorAccess(FSDirectory.java:1719)
	at org.apache.hadoop.hdfs.server.namenode.FSDirMkdirOp.mkdirs(FSDirMkdirOp.java:69)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.mkdirs(FSNamesystem.java:3867)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.mkdirs(NameNodeRpcServer.java:984)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.mkdirs(ClientNamenodeProtocolServerSideTranslatorPB.java:634)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:616)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:982)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2217)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2213)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1754)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2213)

java.sql.SQLException: java.lang.RuntimeException: Cannot create staging directory 'hdfs://localhost:9000/home/chen/hive/warehouse/test_table_double/.hive-staging_hive_2018-03-28_02-17-59_670_5731724910545943572-34': Permission denied: user=hive, access=WRITE, inode="/home/chen/hive/warehouse/test_table_double":chen:supergroup:drwxr-xr-x
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.check(FSPermissionChecker.java:308)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:214)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:190)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkPermission(FSDirectory.java:1752)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkPermission(FSDirectory.java:1736)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkAncestorAccess(FSDirectory.java:1719)
	at org.apache.hadoop.hdfs.server.namenode.FSDirMkdirOp.mkdirs(FSDirMkdirOp.java:69)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.mkdirs(FSNamesystem.java:3867)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.mkdirs(NameNodeRpcServer.java:984)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.mkdirs(ClientNamenodeProtocolServerSideTranslatorPB.java:634)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:616)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:982)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2217)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2213)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1754)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2213)

	at org.apache.hive.jdbc.HiveStatement.execute(HiveStatement.java:296)
	at org.apache.hive.jdbc.HivePreparedStatement.execute(HivePreparedStatement.java:98)
	at com.mchange.v2.c3p0.impl.NewProxyPreparedStatement.execute(NewProxyPreparedStatement.java:67)
	at com.inspur.pmv6.dao.HiveDao.executesql(HiveDao.java:152)
	at com.inspur.pmv6.Entrance.lambda$null$0(Entrance.java:83)
	at java.util.stream.Streams$RangeIntSpliterator.forEachRemaining(Streams.java:110)
	at java.util.stream.IntPipeline$Head.forEach(IntPipeline.java:557)
	at com.inspur.pmv6.Entrance.lambda$myTestCodes$1(Entrance.java:76)
	at java.util.stream.Streams$RangeIntSpliterator.forEachRemaining(Streams.java:110)
	at java.util.stream.IntPipeline$Head.forEach(IntPipeline.java:557)
	at com.inspur.pmv6.Entrance.myTestCodes(Entrance.java:74)
	at com.inspur.pmv6.Entrance.main(Entrance.java:43)
[0328 17:17:59 743 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29utxrumz1kq9f8v|80ec1f8]-HelperThread-#0] hive.jdbc.Utils - Resolved authority: 10.211.55.29:10000
[0328 17:17:59 744 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29utxrumz1kq9f8v|80ec1f8]-HelperThread-#0] hive.jdbc.HiveConnection - Will try to open client transport with JDBC Uri: jdbc:hive2://10.211.55.29:10000/default
[0328 17:17:59 744 INFO ] [main] pmv6.dao.HiveDao - start to execute the sql :insert into test_table_double values (20180331, 110000, 20.455575038077335)
[0328 17:17:59 993 ERROR] [main] pmv6.dao.HiveDao - ERROR SQL: insert into test_table_double values (20180331, 110000, 20.455575038077335)
[0328 17:17:59 993 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29utxrumz1kq9f8v|80ec1f8]-HelperThread-#1] hive.jdbc.Utils - Supplied authorities: 10.211.55.29:10000
[0328 17:17:59 993 ERROR] [main] pmv6.dao.HiveDao - java.lang.RuntimeException: Cannot create staging directory 'hdfs://localhost:9000/home/chen/hive/warehouse/test_table_double/.hive-staging_hive_2018-03-28_02-17-59_918_5031535665129861183-35': Permission denied: user=hive, access=WRITE, inode="/home/chen/hive/warehouse/test_table_double":chen:supergroup:drwxr-xr-x
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.check(FSPermissionChecker.java:308)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:214)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:190)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkPermission(FSDirectory.java:1752)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkPermission(FSDirectory.java:1736)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkAncestorAccess(FSDirectory.java:1719)
	at org.apache.hadoop.hdfs.server.namenode.FSDirMkdirOp.mkdirs(FSDirMkdirOp.java:69)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.mkdirs(FSNamesystem.java:3867)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.mkdirs(NameNodeRpcServer.java:984)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.mkdirs(ClientNamenodeProtocolServerSideTranslatorPB.java:634)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:616)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:982)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2217)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2213)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1754)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2213)

java.sql.SQLException: java.lang.RuntimeException: Cannot create staging directory 'hdfs://localhost:9000/home/chen/hive/warehouse/test_table_double/.hive-staging_hive_2018-03-28_02-17-59_918_5031535665129861183-35': Permission denied: user=hive, access=WRITE, inode="/home/chen/hive/warehouse/test_table_double":chen:supergroup:drwxr-xr-x
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.check(FSPermissionChecker.java:308)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:214)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:190)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkPermission(FSDirectory.java:1752)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkPermission(FSDirectory.java:1736)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkAncestorAccess(FSDirectory.java:1719)
	at org.apache.hadoop.hdfs.server.namenode.FSDirMkdirOp.mkdirs(FSDirMkdirOp.java:69)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.mkdirs(FSNamesystem.java:3867)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.mkdirs(NameNodeRpcServer.java:984)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.mkdirs(ClientNamenodeProtocolServerSideTranslatorPB.java:634)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:616)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:982)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2217)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2213)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1754)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2213)

	at org.apache.hive.jdbc.HiveStatement.execute(HiveStatement.java:296)
	at org.apache.hive.jdbc.HivePreparedStatement.execute(HivePreparedStatement.java:98)
	at com.mchange.v2.c3p0.impl.NewProxyPreparedStatement.execute(NewProxyPreparedStatement.java:67)
	at com.inspur.pmv6.dao.HiveDao.executesql(HiveDao.java:152)
	at com.inspur.pmv6.Entrance.lambda$null$0(Entrance.java:83)
	at java.util.stream.Streams$RangeIntSpliterator.forEachRemaining(Streams.java:110)
	at java.util.stream.IntPipeline$Head.forEach(IntPipeline.java:557)
	at com.inspur.pmv6.Entrance.lambda$myTestCodes$1(Entrance.java:76)
	at java.util.stream.Streams$RangeIntSpliterator.forEachRemaining(Streams.java:110)
	at java.util.stream.IntPipeline$Head.forEach(IntPipeline.java:557)
	at com.inspur.pmv6.Entrance.myTestCodes(Entrance.java:74)
	at com.inspur.pmv6.Entrance.main(Entrance.java:43)
[0328 17:17:59 993 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29utxrumz1kq9f8v|80ec1f8]-HelperThread-#1] hive.jdbc.Utils - Resolved authority: 10.211.55.29:10000
[0328 17:17:59 994 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29utxrumz1kq9f8v|80ec1f8]-HelperThread-#1] hive.jdbc.HiveConnection - Will try to open client transport with JDBC Uri: jdbc:hive2://10.211.55.29:10000/default
[0328 17:17:59 994 INFO ] [main] pmv6.dao.HiveDao - start to execute the sql :insert into test_table_double values (20180331, 120000, 34.57362586355806)
[0328 17:18:00 106 ERROR] [main] pmv6.dao.HiveDao - ERROR SQL: insert into test_table_double values (20180331, 120000, 34.57362586355806)
[0328 17:18:00 106 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29utxrumz1kq9f8v|80ec1f8]-HelperThread-#2] hive.jdbc.Utils - Supplied authorities: 10.211.55.29:10000
[0328 17:18:00 106 ERROR] [main] pmv6.dao.HiveDao - java.lang.RuntimeException: Cannot create staging directory 'hdfs://localhost:9000/home/chen/hive/warehouse/test_table_double/.hive-staging_hive_2018-03-28_02-18-00_037_7467407051691013265-36': Permission denied: user=hive, access=WRITE, inode="/home/chen/hive/warehouse/test_table_double":chen:supergroup:drwxr-xr-x
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.check(FSPermissionChecker.java:308)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:214)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:190)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkPermission(FSDirectory.java:1752)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkPermission(FSDirectory.java:1736)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkAncestorAccess(FSDirectory.java:1719)
	at org.apache.hadoop.hdfs.server.namenode.FSDirMkdirOp.mkdirs(FSDirMkdirOp.java:69)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.mkdirs(FSNamesystem.java:3867)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.mkdirs(NameNodeRpcServer.java:984)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.mkdirs(ClientNamenodeProtocolServerSideTranslatorPB.java:634)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:616)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:982)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2217)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2213)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1754)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2213)

java.sql.SQLException: java.lang.RuntimeException: Cannot create staging directory 'hdfs://localhost:9000/home/chen/hive/warehouse/test_table_double/.hive-staging_hive_2018-03-28_02-18-00_037_7467407051691013265-36': Permission denied: user=hive, access=WRITE, inode="/home/chen/hive/warehouse/test_table_double":chen:supergroup:drwxr-xr-x
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.check(FSPermissionChecker.java:308)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:214)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:190)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkPermission(FSDirectory.java:1752)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkPermission(FSDirectory.java:1736)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkAncestorAccess(FSDirectory.java:1719)
	at org.apache.hadoop.hdfs.server.namenode.FSDirMkdirOp.mkdirs(FSDirMkdirOp.java:69)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.mkdirs(FSNamesystem.java:3867)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.mkdirs(NameNodeRpcServer.java:984)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.mkdirs(ClientNamenodeProtocolServerSideTranslatorPB.java:634)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:616)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:982)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2217)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2213)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1754)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2213)

	at org.apache.hive.jdbc.HiveStatement.execute(HiveStatement.java:296)
	at org.apache.hive.jdbc.HivePreparedStatement.execute(HivePreparedStatement.java:98)
	at com.mchange.v2.c3p0.impl.NewProxyPreparedStatement.execute(NewProxyPreparedStatement.java:67)
	at com.inspur.pmv6.dao.HiveDao.executesql(HiveDao.java:152)
	at com.inspur.pmv6.Entrance.lambda$null$0(Entrance.java:83)
	at java.util.stream.Streams$RangeIntSpliterator.forEachRemaining(Streams.java:110)
	at java.util.stream.IntPipeline$Head.forEach(IntPipeline.java:557)
	at com.inspur.pmv6.Entrance.lambda$myTestCodes$1(Entrance.java:76)
	at java.util.stream.Streams$RangeIntSpliterator.forEachRemaining(Streams.java:110)
	at java.util.stream.IntPipeline$Head.forEach(IntPipeline.java:557)
	at com.inspur.pmv6.Entrance.myTestCodes(Entrance.java:74)
	at com.inspur.pmv6.Entrance.main(Entrance.java:43)
[0328 17:18:00 106 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29utxrumz1kq9f8v|80ec1f8]-HelperThread-#2] hive.jdbc.Utils - Resolved authority: 10.211.55.29:10000
[0328 17:18:00 107 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29utxrumz1kq9f8v|80ec1f8]-HelperThread-#2] hive.jdbc.HiveConnection - Will try to open client transport with JDBC Uri: jdbc:hive2://10.211.55.29:10000/default
[0328 17:18:00 107 INFO ] [main] pmv6.dao.HiveDao - start to execute the sql :insert into test_table_double values (20180331, 010000, 44.829160918484035)
[0328 17:18:00 418 ERROR] [main] pmv6.dao.HiveDao - ERROR SQL: insert into test_table_double values (20180331, 010000, 44.829160918484035)
[0328 17:18:00 418 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29utxrumz1kq9f8v|80ec1f8]-HelperThread-#1] hive.jdbc.Utils - Supplied authorities: 10.211.55.29:10000
[0328 17:18:00 418 ERROR] [main] pmv6.dao.HiveDao - java.lang.RuntimeException: Cannot create staging directory 'hdfs://localhost:9000/home/chen/hive/warehouse/test_table_double/.hive-staging_hive_2018-03-28_02-18-00_334_3602320713667889223-37': Permission denied: user=hive, access=WRITE, inode="/home/chen/hive/warehouse/test_table_double":chen:supergroup:drwxr-xr-x
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.check(FSPermissionChecker.java:308)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:214)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:190)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkPermission(FSDirectory.java:1752)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkPermission(FSDirectory.java:1736)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkAncestorAccess(FSDirectory.java:1719)
	at org.apache.hadoop.hdfs.server.namenode.FSDirMkdirOp.mkdirs(FSDirMkdirOp.java:69)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.mkdirs(FSNamesystem.java:3867)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.mkdirs(NameNodeRpcServer.java:984)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.mkdirs(ClientNamenodeProtocolServerSideTranslatorPB.java:634)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:616)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:982)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2217)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2213)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1754)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2213)

java.sql.SQLException: java.lang.RuntimeException: Cannot create staging directory 'hdfs://localhost:9000/home/chen/hive/warehouse/test_table_double/.hive-staging_hive_2018-03-28_02-18-00_334_3602320713667889223-37': Permission denied: user=hive, access=WRITE, inode="/home/chen/hive/warehouse/test_table_double":chen:supergroup:drwxr-xr-x
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.check(FSPermissionChecker.java:308)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:214)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:190)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkPermission(FSDirectory.java:1752)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkPermission(FSDirectory.java:1736)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkAncestorAccess(FSDirectory.java:1719)
	at org.apache.hadoop.hdfs.server.namenode.FSDirMkdirOp.mkdirs(FSDirMkdirOp.java:69)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.mkdirs(FSNamesystem.java:3867)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.mkdirs(NameNodeRpcServer.java:984)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.mkdirs(ClientNamenodeProtocolServerSideTranslatorPB.java:634)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:616)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:982)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2217)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2213)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1754)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2213)

	at org.apache.hive.jdbc.HiveStatement.execute(HiveStatement.java:296)
	at org.apache.hive.jdbc.HivePreparedStatement.execute(HivePreparedStatement.java:98)
	at com.mchange.v2.c3p0.impl.NewProxyPreparedStatement.execute(NewProxyPreparedStatement.java:67)
	at com.inspur.pmv6.dao.HiveDao.executesql(HiveDao.java:152)
	at com.inspur.pmv6.Entrance.lambda$null$0(Entrance.java:83)
	at java.util.stream.Streams$RangeIntSpliterator.forEachRemaining(Streams.java:110)
	at java.util.stream.IntPipeline$Head.forEach(IntPipeline.java:557)
	at com.inspur.pmv6.Entrance.lambda$myTestCodes$1(Entrance.java:76)
	at java.util.stream.Streams$RangeIntSpliterator.forEachRemaining(Streams.java:110)
	at java.util.stream.IntPipeline$Head.forEach(IntPipeline.java:557)
	at com.inspur.pmv6.Entrance.myTestCodes(Entrance.java:74)
	at com.inspur.pmv6.Entrance.main(Entrance.java:43)
[0328 17:18:00 418 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29utxrumz1kq9f8v|80ec1f8]-HelperThread-#1] hive.jdbc.Utils - Resolved authority: 10.211.55.29:10000
[0328 17:18:00 419 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29utxrumz1kq9f8v|80ec1f8]-HelperThread-#1] hive.jdbc.HiveConnection - Will try to open client transport with JDBC Uri: jdbc:hive2://10.211.55.29:10000/default
[0328 17:18:00 419 INFO ] [main] pmv6.dao.HiveDao - start to execute the sql :insert into test_table_double values (20180331, 020000, 53.91880119905109)
[0328 17:18:00 551 ERROR] [main] pmv6.dao.HiveDao - ERROR SQL: insert into test_table_double values (20180331, 020000, 53.91880119905109)
[0328 17:18:00 552 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29utxrumz1kq9f8v|80ec1f8]-HelperThread-#0] hive.jdbc.Utils - Supplied authorities: 10.211.55.29:10000
[0328 17:18:00 552 ERROR] [main] pmv6.dao.HiveDao - java.lang.RuntimeException: Cannot create staging directory 'hdfs://localhost:9000/home/chen/hive/warehouse/test_table_double/.hive-staging_hive_2018-03-28_02-18-00_470_8941970217620034079-38': Permission denied: user=hive, access=WRITE, inode="/home/chen/hive/warehouse/test_table_double":chen:supergroup:drwxr-xr-x
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.check(FSPermissionChecker.java:308)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:214)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:190)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkPermission(FSDirectory.java:1752)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkPermission(FSDirectory.java:1736)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkAncestorAccess(FSDirectory.java:1719)
	at org.apache.hadoop.hdfs.server.namenode.FSDirMkdirOp.mkdirs(FSDirMkdirOp.java:69)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.mkdirs(FSNamesystem.java:3867)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.mkdirs(NameNodeRpcServer.java:984)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.mkdirs(ClientNamenodeProtocolServerSideTranslatorPB.java:634)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:616)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:982)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2217)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2213)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1754)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2213)

java.sql.SQLException: java.lang.RuntimeException: Cannot create staging directory 'hdfs://localhost:9000/home/chen/hive/warehouse/test_table_double/.hive-staging_hive_2018-03-28_02-18-00_470_8941970217620034079-38': Permission denied: user=hive, access=WRITE, inode="/home/chen/hive/warehouse/test_table_double":chen:supergroup:drwxr-xr-x
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.check(FSPermissionChecker.java:308)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:214)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:190)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkPermission(FSDirectory.java:1752)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkPermission(FSDirectory.java:1736)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkAncestorAccess(FSDirectory.java:1719)
	at org.apache.hadoop.hdfs.server.namenode.FSDirMkdirOp.mkdirs(FSDirMkdirOp.java:69)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.mkdirs(FSNamesystem.java:3867)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.mkdirs(NameNodeRpcServer.java:984)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.mkdirs(ClientNamenodeProtocolServerSideTranslatorPB.java:634)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:616)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:982)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2217)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2213)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1754)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2213)

	at org.apache.hive.jdbc.HiveStatement.execute(HiveStatement.java:296)
	at org.apache.hive.jdbc.HivePreparedStatement.execute(HivePreparedStatement.java:98)
	at com.mchange.v2.c3p0.impl.NewProxyPreparedStatement.execute(NewProxyPreparedStatement.java:67)
	at com.inspur.pmv6.dao.HiveDao.executesql(HiveDao.java:152)
	at com.inspur.pmv6.Entrance.lambda$null$0(Entrance.java:83)
	at java.util.stream.Streams$RangeIntSpliterator.forEachRemaining(Streams.java:110)
	at java.util.stream.IntPipeline$Head.forEach(IntPipeline.java:557)
	at com.inspur.pmv6.Entrance.lambda$myTestCodes$1(Entrance.java:76)
	at java.util.stream.Streams$RangeIntSpliterator.forEachRemaining(Streams.java:110)
	at java.util.stream.IntPipeline$Head.forEach(IntPipeline.java:557)
	at com.inspur.pmv6.Entrance.myTestCodes(Entrance.java:74)
	at com.inspur.pmv6.Entrance.main(Entrance.java:43)
[0328 17:18:00 552 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29utxrumz1kq9f8v|80ec1f8]-HelperThread-#0] hive.jdbc.Utils - Resolved authority: 10.211.55.29:10000
[0328 17:18:00 554 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29utxrumz1kq9f8v|80ec1f8]-HelperThread-#0] hive.jdbc.HiveConnection - Will try to open client transport with JDBC Uri: jdbc:hive2://10.211.55.29:10000/default
[0328 17:18:00 555 INFO ] [main] pmv6.dao.HiveDao - start to execute the sql :insert into test_table_double values (20180331, 030000, 25.80096065144206)
[0328 17:18:00 787 ERROR] [main] pmv6.dao.HiveDao - ERROR SQL: insert into test_table_double values (20180331, 030000, 25.80096065144206)
[0328 17:18:00 787 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29utxrumz1kq9f8v|80ec1f8]-HelperThread-#0] hive.jdbc.Utils - Supplied authorities: 10.211.55.29:10000
[0328 17:18:00 787 ERROR] [main] pmv6.dao.HiveDao - java.lang.RuntimeException: Cannot create staging directory 'hdfs://localhost:9000/home/chen/hive/warehouse/test_table_double/.hive-staging_hive_2018-03-28_02-18-00_708_823080624384616565-39': Permission denied: user=hive, access=WRITE, inode="/home/chen/hive/warehouse/test_table_double":chen:supergroup:drwxr-xr-x
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.check(FSPermissionChecker.java:308)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:214)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:190)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkPermission(FSDirectory.java:1752)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkPermission(FSDirectory.java:1736)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkAncestorAccess(FSDirectory.java:1719)
	at org.apache.hadoop.hdfs.server.namenode.FSDirMkdirOp.mkdirs(FSDirMkdirOp.java:69)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.mkdirs(FSNamesystem.java:3867)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.mkdirs(NameNodeRpcServer.java:984)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.mkdirs(ClientNamenodeProtocolServerSideTranslatorPB.java:634)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:616)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:982)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2217)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2213)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1754)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2213)

java.sql.SQLException: java.lang.RuntimeException: Cannot create staging directory 'hdfs://localhost:9000/home/chen/hive/warehouse/test_table_double/.hive-staging_hive_2018-03-28_02-18-00_708_823080624384616565-39': Permission denied: user=hive, access=WRITE, inode="/home/chen/hive/warehouse/test_table_double":chen:supergroup:drwxr-xr-x
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.check(FSPermissionChecker.java:308)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:214)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:190)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkPermission(FSDirectory.java:1752)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkPermission(FSDirectory.java:1736)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkAncestorAccess(FSDirectory.java:1719)
	at org.apache.hadoop.hdfs.server.namenode.FSDirMkdirOp.mkdirs(FSDirMkdirOp.java:69)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.mkdirs(FSNamesystem.java:3867)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.mkdirs(NameNodeRpcServer.java:984)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.mkdirs(ClientNamenodeProtocolServerSideTranslatorPB.java:634)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:616)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:982)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2217)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2213)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1754)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2213)

	at org.apache.hive.jdbc.HiveStatement.execute(HiveStatement.java:296)
	at org.apache.hive.jdbc.HivePreparedStatement.execute(HivePreparedStatement.java:98)
	at com.mchange.v2.c3p0.impl.NewProxyPreparedStatement.execute(NewProxyPreparedStatement.java:67)
	at com.inspur.pmv6.dao.HiveDao.executesql(HiveDao.java:152)
	at com.inspur.pmv6.Entrance.lambda$null$0(Entrance.java:83)
	at java.util.stream.Streams$RangeIntSpliterator.forEachRemaining(Streams.java:110)
	at java.util.stream.IntPipeline$Head.forEach(IntPipeline.java:557)
	at com.inspur.pmv6.Entrance.lambda$myTestCodes$1(Entrance.java:76)
	at java.util.stream.Streams$RangeIntSpliterator.forEachRemaining(Streams.java:110)
	at java.util.stream.IntPipeline$Head.forEach(IntPipeline.java:557)
	at com.inspur.pmv6.Entrance.myTestCodes(Entrance.java:74)
	at com.inspur.pmv6.Entrance.main(Entrance.java:43)
[0328 17:18:00 788 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29utxrumz1kq9f8v|80ec1f8]-HelperThread-#0] hive.jdbc.Utils - Resolved authority: 10.211.55.29:10000
[0328 17:18:00 788 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29utxrumz1kq9f8v|80ec1f8]-HelperThread-#0] hive.jdbc.HiveConnection - Will try to open client transport with JDBC Uri: jdbc:hive2://10.211.55.29:10000/default
[0328 17:18:00 796 INFO ] [main] pmv6.dao.HiveDao - start to execute the sql :insert into test_table_double values (20180331, 040000, 59.880029493453634)
[0328 17:18:00 914 ERROR] [main] pmv6.dao.HiveDao - ERROR SQL: insert into test_table_double values (20180331, 040000, 59.880029493453634)
[0328 17:18:00 914 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29utxrumz1kq9f8v|80ec1f8]-HelperThread-#2] hive.jdbc.Utils - Supplied authorities: 10.211.55.29:10000
[0328 17:18:00 914 ERROR] [main] pmv6.dao.HiveDao - java.lang.RuntimeException: Cannot create staging directory 'hdfs://localhost:9000/home/chen/hive/warehouse/test_table_double/.hive-staging_hive_2018-03-28_02-18-00_838_7732978209895515789-40': Permission denied: user=hive, access=WRITE, inode="/home/chen/hive/warehouse/test_table_double":chen:supergroup:drwxr-xr-x
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.check(FSPermissionChecker.java:308)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:214)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:190)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkPermission(FSDirectory.java:1752)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkPermission(FSDirectory.java:1736)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkAncestorAccess(FSDirectory.java:1719)
	at org.apache.hadoop.hdfs.server.namenode.FSDirMkdirOp.mkdirs(FSDirMkdirOp.java:69)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.mkdirs(FSNamesystem.java:3867)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.mkdirs(NameNodeRpcServer.java:984)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.mkdirs(ClientNamenodeProtocolServerSideTranslatorPB.java:634)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:616)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:982)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2217)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2213)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1754)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2213)

java.sql.SQLException: java.lang.RuntimeException: Cannot create staging directory 'hdfs://localhost:9000/home/chen/hive/warehouse/test_table_double/.hive-staging_hive_2018-03-28_02-18-00_838_7732978209895515789-40': Permission denied: user=hive, access=WRITE, inode="/home/chen/hive/warehouse/test_table_double":chen:supergroup:drwxr-xr-x
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.check(FSPermissionChecker.java:308)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:214)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:190)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkPermission(FSDirectory.java:1752)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkPermission(FSDirectory.java:1736)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkAncestorAccess(FSDirectory.java:1719)
	at org.apache.hadoop.hdfs.server.namenode.FSDirMkdirOp.mkdirs(FSDirMkdirOp.java:69)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.mkdirs(FSNamesystem.java:3867)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.mkdirs(NameNodeRpcServer.java:984)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.mkdirs(ClientNamenodeProtocolServerSideTranslatorPB.java:634)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:616)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:982)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2217)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2213)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1754)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2213)

	at org.apache.hive.jdbc.HiveStatement.execute(HiveStatement.java:296)
	at org.apache.hive.jdbc.HivePreparedStatement.execute(HivePreparedStatement.java:98)
	at com.mchange.v2.c3p0.impl.NewProxyPreparedStatement.execute(NewProxyPreparedStatement.java:67)
	at com.inspur.pmv6.dao.HiveDao.executesql(HiveDao.java:152)
	at com.inspur.pmv6.Entrance.lambda$null$0(Entrance.java:83)
	at java.util.stream.Streams$RangeIntSpliterator.forEachRemaining(Streams.java:110)
	at java.util.stream.IntPipeline$Head.forEach(IntPipeline.java:557)
	at com.inspur.pmv6.Entrance.lambda$myTestCodes$1(Entrance.java:76)
	at java.util.stream.Streams$RangeIntSpliterator.forEachRemaining(Streams.java:110)
	at java.util.stream.IntPipeline$Head.forEach(IntPipeline.java:557)
	at com.inspur.pmv6.Entrance.myTestCodes(Entrance.java:74)
	at com.inspur.pmv6.Entrance.main(Entrance.java:43)
[0328 17:18:00 914 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29utxrumz1kq9f8v|80ec1f8]-HelperThread-#2] hive.jdbc.Utils - Resolved authority: 10.211.55.29:10000
[0328 17:18:00 915 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29utxrumz1kq9f8v|80ec1f8]-HelperThread-#2] hive.jdbc.HiveConnection - Will try to open client transport with JDBC Uri: jdbc:hive2://10.211.55.29:10000/default
[0328 17:18:00 916 INFO ] [main] pmv6.dao.HiveDao - start to execute the sql :insert into test_table_double values (20180331, 050000, 14.332840274076709)
[0328 17:18:01 084 ERROR] [main] pmv6.dao.HiveDao - ERROR SQL: insert into test_table_double values (20180331, 050000, 14.332840274076709)
[0328 17:18:01 084 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29utxrumz1kq9f8v|80ec1f8]-HelperThread-#0] hive.jdbc.Utils - Supplied authorities: 10.211.55.29:10000
[0328 17:18:01 084 ERROR] [main] pmv6.dao.HiveDao - java.lang.RuntimeException: Cannot create staging directory 'hdfs://localhost:9000/home/chen/hive/warehouse/test_table_double/.hive-staging_hive_2018-03-28_02-18-01_014_2130161794140830646-41': Permission denied: user=hive, access=WRITE, inode="/home/chen/hive/warehouse/test_table_double":chen:supergroup:drwxr-xr-x
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.check(FSPermissionChecker.java:308)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:214)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:190)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkPermission(FSDirectory.java:1752)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkPermission(FSDirectory.java:1736)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkAncestorAccess(FSDirectory.java:1719)
	at org.apache.hadoop.hdfs.server.namenode.FSDirMkdirOp.mkdirs(FSDirMkdirOp.java:69)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.mkdirs(FSNamesystem.java:3867)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.mkdirs(NameNodeRpcServer.java:984)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.mkdirs(ClientNamenodeProtocolServerSideTranslatorPB.java:634)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:616)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:982)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2217)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2213)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1754)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2213)

java.sql.SQLException: java.lang.RuntimeException: Cannot create staging directory 'hdfs://localhost:9000/home/chen/hive/warehouse/test_table_double/.hive-staging_hive_2018-03-28_02-18-01_014_2130161794140830646-41': Permission denied: user=hive, access=WRITE, inode="/home/chen/hive/warehouse/test_table_double":chen:supergroup:drwxr-xr-x
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.check(FSPermissionChecker.java:308)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:214)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:190)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkPermission(FSDirectory.java:1752)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkPermission(FSDirectory.java:1736)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkAncestorAccess(FSDirectory.java:1719)
	at org.apache.hadoop.hdfs.server.namenode.FSDirMkdirOp.mkdirs(FSDirMkdirOp.java:69)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.mkdirs(FSNamesystem.java:3867)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.mkdirs(NameNodeRpcServer.java:984)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.mkdirs(ClientNamenodeProtocolServerSideTranslatorPB.java:634)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:616)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:982)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2217)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2213)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1754)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2213)

	at org.apache.hive.jdbc.HiveStatement.execute(HiveStatement.java:296)
	at org.apache.hive.jdbc.HivePreparedStatement.execute(HivePreparedStatement.java:98)
	at com.mchange.v2.c3p0.impl.NewProxyPreparedStatement.execute(NewProxyPreparedStatement.java:67)
	at com.inspur.pmv6.dao.HiveDao.executesql(HiveDao.java:152)
	at com.inspur.pmv6.Entrance.lambda$null$0(Entrance.java:83)
	at java.util.stream.Streams$RangeIntSpliterator.forEachRemaining(Streams.java:110)
	at java.util.stream.IntPipeline$Head.forEach(IntPipeline.java:557)
	at com.inspur.pmv6.Entrance.lambda$myTestCodes$1(Entrance.java:76)
	at java.util.stream.Streams$RangeIntSpliterator.forEachRemaining(Streams.java:110)
	at java.util.stream.IntPipeline$Head.forEach(IntPipeline.java:557)
	at com.inspur.pmv6.Entrance.myTestCodes(Entrance.java:74)
	at com.inspur.pmv6.Entrance.main(Entrance.java:43)
[0328 17:18:01 084 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29utxrumz1kq9f8v|80ec1f8]-HelperThread-#0] hive.jdbc.Utils - Resolved authority: 10.211.55.29:10000
[0328 17:18:01 085 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29utxrumz1kq9f8v|80ec1f8]-HelperThread-#0] hive.jdbc.HiveConnection - Will try to open client transport with JDBC Uri: jdbc:hive2://10.211.55.29:10000/default
[0328 17:18:01 085 INFO ] [main] pmv6.dao.HiveDao - start to execute the sql :insert into test_table_double values (20180331, 060000, 43.41997497944764)
[0328 17:18:01 325 ERROR] [main] pmv6.dao.HiveDao - ERROR SQL: insert into test_table_double values (20180331, 060000, 43.41997497944764)
[0328 17:18:01 325 ERROR] [main] pmv6.dao.HiveDao - java.lang.RuntimeException: Cannot create staging directory 'hdfs://localhost:9000/home/chen/hive/warehouse/test_table_double/.hive-staging_hive_2018-03-28_02-18-01_248_435568664315864693-42': Permission denied: user=hive, access=WRITE, inode="/home/chen/hive/warehouse/test_table_double":chen:supergroup:drwxr-xr-x
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.check(FSPermissionChecker.java:308)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:214)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:190)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkPermission(FSDirectory.java:1752)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkPermission(FSDirectory.java:1736)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkAncestorAccess(FSDirectory.java:1719)
	at org.apache.hadoop.hdfs.server.namenode.FSDirMkdirOp.mkdirs(FSDirMkdirOp.java:69)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.mkdirs(FSNamesystem.java:3867)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.mkdirs(NameNodeRpcServer.java:984)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.mkdirs(ClientNamenodeProtocolServerSideTranslatorPB.java:634)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:616)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:982)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2217)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2213)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1754)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2213)

java.sql.SQLException: java.lang.RuntimeException: Cannot create staging directory 'hdfs://localhost:9000/home/chen/hive/warehouse/test_table_double/.hive-staging_hive_2018-03-28_02-18-01_248_435568664315864693-42': Permission denied: user=hive, access=WRITE, inode="/home/chen/hive/warehouse/test_table_double":chen:supergroup:drwxr-xr-x
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.check(FSPermissionChecker.java:308)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:214)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:190)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkPermission(FSDirectory.java:1752)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkPermission(FSDirectory.java:1736)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkAncestorAccess(FSDirectory.java:1719)
	at org.apache.hadoop.hdfs.server.namenode.FSDirMkdirOp.mkdirs(FSDirMkdirOp.java:69)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.mkdirs(FSNamesystem.java:3867)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.mkdirs(NameNodeRpcServer.java:984)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.mkdirs(ClientNamenodeProtocolServerSideTranslatorPB.java:634)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:616)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:982)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2217)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2213)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1754)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2213)

	at org.apache.hive.jdbc.HiveStatement.execute(HiveStatement.java:296)
	at org.apache.hive.jdbc.HivePreparedStatement.execute(HivePreparedStatement.java:98)
	at com.mchange.v2.c3p0.impl.NewProxyPreparedStatement.execute(NewProxyPreparedStatement.java:67)
	at com.inspur.pmv6.dao.HiveDao.executesql(HiveDao.java:152)
	at com.inspur.pmv6.Entrance.lambda$null$0(Entrance.java:83)
	at java.util.stream.Streams$RangeIntSpliterator.forEachRemaining(Streams.java:110)
	at java.util.stream.IntPipeline$Head.forEach(IntPipeline.java:557)
	at com.inspur.pmv6.Entrance.lambda$myTestCodes$1(Entrance.java:76)
	at java.util.stream.Streams$RangeIntSpliterator.forEachRemaining(Streams.java:110)
	at java.util.stream.IntPipeline$Head.forEach(IntPipeline.java:557)
	at com.inspur.pmv6.Entrance.myTestCodes(Entrance.java:74)
	at com.inspur.pmv6.Entrance.main(Entrance.java:43)
[0328 17:18:01 325 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29utxrumz1kq9f8v|80ec1f8]-HelperThread-#0] hive.jdbc.Utils - Supplied authorities: 10.211.55.29:10000
[0328 17:18:01 326 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29utxrumz1kq9f8v|80ec1f8]-HelperThread-#0] hive.jdbc.Utils - Resolved authority: 10.211.55.29:10000
[0328 17:18:01 326 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29utxrumz1kq9f8v|80ec1f8]-HelperThread-#0] hive.jdbc.HiveConnection - Will try to open client transport with JDBC Uri: jdbc:hive2://10.211.55.29:10000/default
[0328 17:18:01 326 INFO ] [main] pmv6.dao.HiveDao - start to execute the sql :insert into test_table_double values (20180331, 070000, 3.7391000672485797)
[0328 17:18:01 449 ERROR] [main] pmv6.dao.HiveDao - ERROR SQL: insert into test_table_double values (20180331, 070000, 3.7391000672485797)
[0328 17:18:01 450 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29utxrumz1kq9f8v|80ec1f8]-HelperThread-#1] hive.jdbc.Utils - Supplied authorities: 10.211.55.29:10000
[0328 17:18:01 450 ERROR] [main] pmv6.dao.HiveDao - java.lang.RuntimeException: Cannot create staging directory 'hdfs://localhost:9000/home/chen/hive/warehouse/test_table_double/.hive-staging_hive_2018-03-28_02-18-01_378_1262555719107931674-43': Permission denied: user=hive, access=WRITE, inode="/home/chen/hive/warehouse/test_table_double":chen:supergroup:drwxr-xr-x
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.check(FSPermissionChecker.java:308)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:214)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:190)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkPermission(FSDirectory.java:1752)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkPermission(FSDirectory.java:1736)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkAncestorAccess(FSDirectory.java:1719)
	at org.apache.hadoop.hdfs.server.namenode.FSDirMkdirOp.mkdirs(FSDirMkdirOp.java:69)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.mkdirs(FSNamesystem.java:3867)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.mkdirs(NameNodeRpcServer.java:984)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.mkdirs(ClientNamenodeProtocolServerSideTranslatorPB.java:634)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:616)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:982)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2217)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2213)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1754)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2213)

java.sql.SQLException: java.lang.RuntimeException: Cannot create staging directory 'hdfs://localhost:9000/home/chen/hive/warehouse/test_table_double/.hive-staging_hive_2018-03-28_02-18-01_378_1262555719107931674-43': Permission denied: user=hive, access=WRITE, inode="/home/chen/hive/warehouse/test_table_double":chen:supergroup:drwxr-xr-x
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.check(FSPermissionChecker.java:308)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:214)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:190)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkPermission(FSDirectory.java:1752)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkPermission(FSDirectory.java:1736)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkAncestorAccess(FSDirectory.java:1719)
	at org.apache.hadoop.hdfs.server.namenode.FSDirMkdirOp.mkdirs(FSDirMkdirOp.java:69)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.mkdirs(FSNamesystem.java:3867)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.mkdirs(NameNodeRpcServer.java:984)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.mkdirs(ClientNamenodeProtocolServerSideTranslatorPB.java:634)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:616)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:982)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2217)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2213)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1754)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2213)

	at org.apache.hive.jdbc.HiveStatement.execute(HiveStatement.java:296)
	at org.apache.hive.jdbc.HivePreparedStatement.execute(HivePreparedStatement.java:98)
	at com.mchange.v2.c3p0.impl.NewProxyPreparedStatement.execute(NewProxyPreparedStatement.java:67)
	at com.inspur.pmv6.dao.HiveDao.executesql(HiveDao.java:152)
	at com.inspur.pmv6.Entrance.lambda$null$0(Entrance.java:83)
	at java.util.stream.Streams$RangeIntSpliterator.forEachRemaining(Streams.java:110)
	at java.util.stream.IntPipeline$Head.forEach(IntPipeline.java:557)
	at com.inspur.pmv6.Entrance.lambda$myTestCodes$1(Entrance.java:76)
	at java.util.stream.Streams$RangeIntSpliterator.forEachRemaining(Streams.java:110)
	at java.util.stream.IntPipeline$Head.forEach(IntPipeline.java:557)
	at com.inspur.pmv6.Entrance.myTestCodes(Entrance.java:74)
	at com.inspur.pmv6.Entrance.main(Entrance.java:43)
[0328 17:18:01 450 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29utxrumz1kq9f8v|80ec1f8]-HelperThread-#1] hive.jdbc.Utils - Resolved authority: 10.211.55.29:10000
[0328 17:18:01 450 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29utxrumz1kq9f8v|80ec1f8]-HelperThread-#1] hive.jdbc.HiveConnection - Will try to open client transport with JDBC Uri: jdbc:hive2://10.211.55.29:10000/default
[0328 17:18:01 451 INFO ] [main] pmv6.dao.HiveDao - start to execute the sql :insert into test_table_double values (20180331, 080000, 99.33881229056276)
[0328 17:18:01 699 ERROR] [main] pmv6.dao.HiveDao - ERROR SQL: insert into test_table_double values (20180331, 080000, 99.33881229056276)
[0328 17:18:01 699 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29utxrumz1kq9f8v|80ec1f8]-HelperThread-#1] hive.jdbc.Utils - Supplied authorities: 10.211.55.29:10000
[0328 17:18:01 699 ERROR] [main] pmv6.dao.HiveDao - java.lang.RuntimeException: Cannot create staging directory 'hdfs://localhost:9000/home/chen/hive/warehouse/test_table_double/.hive-staging_hive_2018-03-28_02-18-01_620_7562854897102609300-44': Permission denied: user=hive, access=WRITE, inode="/home/chen/hive/warehouse/test_table_double":chen:supergroup:drwxr-xr-x
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.check(FSPermissionChecker.java:308)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:214)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:190)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkPermission(FSDirectory.java:1752)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkPermission(FSDirectory.java:1736)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkAncestorAccess(FSDirectory.java:1719)
	at org.apache.hadoop.hdfs.server.namenode.FSDirMkdirOp.mkdirs(FSDirMkdirOp.java:69)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.mkdirs(FSNamesystem.java:3867)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.mkdirs(NameNodeRpcServer.java:984)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.mkdirs(ClientNamenodeProtocolServerSideTranslatorPB.java:634)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:616)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:982)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2217)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2213)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1754)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2213)

java.sql.SQLException: java.lang.RuntimeException: Cannot create staging directory 'hdfs://localhost:9000/home/chen/hive/warehouse/test_table_double/.hive-staging_hive_2018-03-28_02-18-01_620_7562854897102609300-44': Permission denied: user=hive, access=WRITE, inode="/home/chen/hive/warehouse/test_table_double":chen:supergroup:drwxr-xr-x
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.check(FSPermissionChecker.java:308)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:214)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:190)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkPermission(FSDirectory.java:1752)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkPermission(FSDirectory.java:1736)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkAncestorAccess(FSDirectory.java:1719)
	at org.apache.hadoop.hdfs.server.namenode.FSDirMkdirOp.mkdirs(FSDirMkdirOp.java:69)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.mkdirs(FSNamesystem.java:3867)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.mkdirs(NameNodeRpcServer.java:984)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.mkdirs(ClientNamenodeProtocolServerSideTranslatorPB.java:634)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:616)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:982)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2217)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2213)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1754)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2213)

	at org.apache.hive.jdbc.HiveStatement.execute(HiveStatement.java:296)
	at org.apache.hive.jdbc.HivePreparedStatement.execute(HivePreparedStatement.java:98)
	at com.mchange.v2.c3p0.impl.NewProxyPreparedStatement.execute(NewProxyPreparedStatement.java:67)
	at com.inspur.pmv6.dao.HiveDao.executesql(HiveDao.java:152)
	at com.inspur.pmv6.Entrance.lambda$null$0(Entrance.java:83)
	at java.util.stream.Streams$RangeIntSpliterator.forEachRemaining(Streams.java:110)
	at java.util.stream.IntPipeline$Head.forEach(IntPipeline.java:557)
	at com.inspur.pmv6.Entrance.lambda$myTestCodes$1(Entrance.java:76)
	at java.util.stream.Streams$RangeIntSpliterator.forEachRemaining(Streams.java:110)
	at java.util.stream.IntPipeline$Head.forEach(IntPipeline.java:557)
	at com.inspur.pmv6.Entrance.myTestCodes(Entrance.java:74)
	at com.inspur.pmv6.Entrance.main(Entrance.java:43)
[0328 17:18:01 700 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29utxrumz1kq9f8v|80ec1f8]-HelperThread-#1] hive.jdbc.Utils - Resolved authority: 10.211.55.29:10000
[0328 17:18:01 700 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29utxrumz1kq9f8v|80ec1f8]-HelperThread-#1] hive.jdbc.HiveConnection - Will try to open client transport with JDBC Uri: jdbc:hive2://10.211.55.29:10000/default
[0328 17:18:01 702 INFO ] [main] pmv6.dao.HiveDao - start to execute the sql :insert into test_table_double values (20180331, 090000, 41.797479988394834)
[0328 17:18:01 814 ERROR] [main] pmv6.dao.HiveDao - ERROR SQL: insert into test_table_double values (20180331, 090000, 41.797479988394834)
[0328 17:18:01 814 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29utxrumz1kq9f8v|80ec1f8]-HelperThread-#2] hive.jdbc.Utils - Supplied authorities: 10.211.55.29:10000
[0328 17:18:01 814 ERROR] [main] pmv6.dao.HiveDao - java.lang.RuntimeException: Cannot create staging directory 'hdfs://localhost:9000/home/chen/hive/warehouse/test_table_double/.hive-staging_hive_2018-03-28_02-18-01_743_4705106489685226868-45': Permission denied: user=hive, access=WRITE, inode="/home/chen/hive/warehouse/test_table_double":chen:supergroup:drwxr-xr-x
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.check(FSPermissionChecker.java:308)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:214)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:190)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkPermission(FSDirectory.java:1752)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkPermission(FSDirectory.java:1736)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkAncestorAccess(FSDirectory.java:1719)
	at org.apache.hadoop.hdfs.server.namenode.FSDirMkdirOp.mkdirs(FSDirMkdirOp.java:69)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.mkdirs(FSNamesystem.java:3867)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.mkdirs(NameNodeRpcServer.java:984)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.mkdirs(ClientNamenodeProtocolServerSideTranslatorPB.java:634)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:616)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:982)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2217)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2213)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1754)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2213)

java.sql.SQLException: java.lang.RuntimeException: Cannot create staging directory 'hdfs://localhost:9000/home/chen/hive/warehouse/test_table_double/.hive-staging_hive_2018-03-28_02-18-01_743_4705106489685226868-45': Permission denied: user=hive, access=WRITE, inode="/home/chen/hive/warehouse/test_table_double":chen:supergroup:drwxr-xr-x
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.check(FSPermissionChecker.java:308)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:214)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:190)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkPermission(FSDirectory.java:1752)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkPermission(FSDirectory.java:1736)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkAncestorAccess(FSDirectory.java:1719)
	at org.apache.hadoop.hdfs.server.namenode.FSDirMkdirOp.mkdirs(FSDirMkdirOp.java:69)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.mkdirs(FSNamesystem.java:3867)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.mkdirs(NameNodeRpcServer.java:984)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.mkdirs(ClientNamenodeProtocolServerSideTranslatorPB.java:634)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:616)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:982)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2217)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2213)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1754)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2213)

	at org.apache.hive.jdbc.HiveStatement.execute(HiveStatement.java:296)
	at org.apache.hive.jdbc.HivePreparedStatement.execute(HivePreparedStatement.java:98)
	at com.mchange.v2.c3p0.impl.NewProxyPreparedStatement.execute(NewProxyPreparedStatement.java:67)
	at com.inspur.pmv6.dao.HiveDao.executesql(HiveDao.java:152)
	at com.inspur.pmv6.Entrance.lambda$null$0(Entrance.java:83)
	at java.util.stream.Streams$RangeIntSpliterator.forEachRemaining(Streams.java:110)
	at java.util.stream.IntPipeline$Head.forEach(IntPipeline.java:557)
	at com.inspur.pmv6.Entrance.lambda$myTestCodes$1(Entrance.java:76)
	at java.util.stream.Streams$RangeIntSpliterator.forEachRemaining(Streams.java:110)
	at java.util.stream.IntPipeline$Head.forEach(IntPipeline.java:557)
	at com.inspur.pmv6.Entrance.myTestCodes(Entrance.java:74)
	at com.inspur.pmv6.Entrance.main(Entrance.java:43)
[0328 17:18:01 814 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29utxrumz1kq9f8v|80ec1f8]-HelperThread-#2] hive.jdbc.Utils - Resolved authority: 10.211.55.29:10000
[0328 17:18:01 815 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29utxrumz1kq9f8v|80ec1f8]-HelperThread-#2] hive.jdbc.HiveConnection - Will try to open client transport with JDBC Uri: jdbc:hive2://10.211.55.29:10000/default
[0328 17:18:01 817 INFO ] [main] pmv6.dao.HiveDao - start to execute the sql :insert into test_table_double values (20180331, 100000, 96.46307131981378)
[0328 17:18:02 076 ERROR] [main] pmv6.dao.HiveDao - ERROR SQL: insert into test_table_double values (20180331, 100000, 96.46307131981378)
[0328 17:18:02 077 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29utxrumz1kq9f8v|80ec1f8]-HelperThread-#1] hive.jdbc.Utils - Supplied authorities: 10.211.55.29:10000
[0328 17:18:02 077 ERROR] [main] pmv6.dao.HiveDao - java.lang.RuntimeException: Cannot create staging directory 'hdfs://localhost:9000/home/chen/hive/warehouse/test_table_double/.hive-staging_hive_2018-03-28_02-18-01_978_1812994746015943484-46': Permission denied: user=hive, access=WRITE, inode="/home/chen/hive/warehouse/test_table_double":chen:supergroup:drwxr-xr-x
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.check(FSPermissionChecker.java:308)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:214)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:190)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkPermission(FSDirectory.java:1752)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkPermission(FSDirectory.java:1736)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkAncestorAccess(FSDirectory.java:1719)
	at org.apache.hadoop.hdfs.server.namenode.FSDirMkdirOp.mkdirs(FSDirMkdirOp.java:69)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.mkdirs(FSNamesystem.java:3867)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.mkdirs(NameNodeRpcServer.java:984)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.mkdirs(ClientNamenodeProtocolServerSideTranslatorPB.java:634)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:616)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:982)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2217)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2213)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1754)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2213)

java.sql.SQLException: java.lang.RuntimeException: Cannot create staging directory 'hdfs://localhost:9000/home/chen/hive/warehouse/test_table_double/.hive-staging_hive_2018-03-28_02-18-01_978_1812994746015943484-46': Permission denied: user=hive, access=WRITE, inode="/home/chen/hive/warehouse/test_table_double":chen:supergroup:drwxr-xr-x
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.check(FSPermissionChecker.java:308)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:214)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:190)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkPermission(FSDirectory.java:1752)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkPermission(FSDirectory.java:1736)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkAncestorAccess(FSDirectory.java:1719)
	at org.apache.hadoop.hdfs.server.namenode.FSDirMkdirOp.mkdirs(FSDirMkdirOp.java:69)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.mkdirs(FSNamesystem.java:3867)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.mkdirs(NameNodeRpcServer.java:984)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.mkdirs(ClientNamenodeProtocolServerSideTranslatorPB.java:634)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:616)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:982)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2217)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2213)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1754)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2213)

	at org.apache.hive.jdbc.HiveStatement.execute(HiveStatement.java:296)
	at org.apache.hive.jdbc.HivePreparedStatement.execute(HivePreparedStatement.java:98)
	at com.mchange.v2.c3p0.impl.NewProxyPreparedStatement.execute(NewProxyPreparedStatement.java:67)
	at com.inspur.pmv6.dao.HiveDao.executesql(HiveDao.java:152)
	at com.inspur.pmv6.Entrance.lambda$null$0(Entrance.java:83)
	at java.util.stream.Streams$RangeIntSpliterator.forEachRemaining(Streams.java:110)
	at java.util.stream.IntPipeline$Head.forEach(IntPipeline.java:557)
	at com.inspur.pmv6.Entrance.lambda$myTestCodes$1(Entrance.java:76)
	at java.util.stream.Streams$RangeIntSpliterator.forEachRemaining(Streams.java:110)
	at java.util.stream.IntPipeline$Head.forEach(IntPipeline.java:557)
	at com.inspur.pmv6.Entrance.myTestCodes(Entrance.java:74)
	at com.inspur.pmv6.Entrance.main(Entrance.java:43)
[0328 17:18:02 077 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29utxrumz1kq9f8v|80ec1f8]-HelperThread-#1] hive.jdbc.Utils - Resolved authority: 10.211.55.29:10000
[0328 17:18:02 077 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29utxrumz1kq9f8v|80ec1f8]-HelperThread-#1] hive.jdbc.HiveConnection - Will try to open client transport with JDBC Uri: jdbc:hive2://10.211.55.29:10000/default
[0328 17:18:02 078 INFO ] [main] pmv6.dao.HiveDao - start to execute the sql :insert into test_table_double values (20180401, 110000, 89.27081878737269)
[0328 17:18:02 196 ERROR] [main] pmv6.dao.HiveDao - ERROR SQL: insert into test_table_double values (20180401, 110000, 89.27081878737269)
[0328 17:18:02 196 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29utxrumz1kq9f8v|80ec1f8]-HelperThread-#0] hive.jdbc.Utils - Supplied authorities: 10.211.55.29:10000
[0328 17:18:02 196 ERROR] [main] pmv6.dao.HiveDao - java.lang.RuntimeException: Cannot create staging directory 'hdfs://localhost:9000/home/chen/hive/warehouse/test_table_double/.hive-staging_hive_2018-03-28_02-18-02_122_1342494797047623202-47': Permission denied: user=hive, access=WRITE, inode="/home/chen/hive/warehouse/test_table_double":chen:supergroup:drwxr-xr-x
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.check(FSPermissionChecker.java:308)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:214)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:190)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkPermission(FSDirectory.java:1752)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkPermission(FSDirectory.java:1736)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkAncestorAccess(FSDirectory.java:1719)
	at org.apache.hadoop.hdfs.server.namenode.FSDirMkdirOp.mkdirs(FSDirMkdirOp.java:69)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.mkdirs(FSNamesystem.java:3867)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.mkdirs(NameNodeRpcServer.java:984)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.mkdirs(ClientNamenodeProtocolServerSideTranslatorPB.java:634)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:616)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:982)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2217)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2213)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1754)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2213)

java.sql.SQLException: java.lang.RuntimeException: Cannot create staging directory 'hdfs://localhost:9000/home/chen/hive/warehouse/test_table_double/.hive-staging_hive_2018-03-28_02-18-02_122_1342494797047623202-47': Permission denied: user=hive, access=WRITE, inode="/home/chen/hive/warehouse/test_table_double":chen:supergroup:drwxr-xr-x
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.check(FSPermissionChecker.java:308)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:214)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:190)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkPermission(FSDirectory.java:1752)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkPermission(FSDirectory.java:1736)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkAncestorAccess(FSDirectory.java:1719)
	at org.apache.hadoop.hdfs.server.namenode.FSDirMkdirOp.mkdirs(FSDirMkdirOp.java:69)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.mkdirs(FSNamesystem.java:3867)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.mkdirs(NameNodeRpcServer.java:984)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.mkdirs(ClientNamenodeProtocolServerSideTranslatorPB.java:634)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:616)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:982)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2217)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2213)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1754)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2213)

	at org.apache.hive.jdbc.HiveStatement.execute(HiveStatement.java:296)
	at org.apache.hive.jdbc.HivePreparedStatement.execute(HivePreparedStatement.java:98)
	at com.mchange.v2.c3p0.impl.NewProxyPreparedStatement.execute(NewProxyPreparedStatement.java:67)
	at com.inspur.pmv6.dao.HiveDao.executesql(HiveDao.java:152)
	at com.inspur.pmv6.Entrance.lambda$null$0(Entrance.java:83)
	at java.util.stream.Streams$RangeIntSpliterator.forEachRemaining(Streams.java:110)
	at java.util.stream.IntPipeline$Head.forEach(IntPipeline.java:557)
	at com.inspur.pmv6.Entrance.lambda$myTestCodes$1(Entrance.java:76)
	at java.util.stream.Streams$RangeIntSpliterator.forEachRemaining(Streams.java:110)
	at java.util.stream.IntPipeline$Head.forEach(IntPipeline.java:557)
	at com.inspur.pmv6.Entrance.myTestCodes(Entrance.java:74)
	at com.inspur.pmv6.Entrance.main(Entrance.java:43)
[0328 17:18:02 196 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29utxrumz1kq9f8v|80ec1f8]-HelperThread-#0] hive.jdbc.Utils - Resolved authority: 10.211.55.29:10000
[0328 17:18:02 197 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29utxrumz1kq9f8v|80ec1f8]-HelperThread-#0] hive.jdbc.HiveConnection - Will try to open client transport with JDBC Uri: jdbc:hive2://10.211.55.29:10000/default
[0328 17:18:02 197 INFO ] [main] pmv6.dao.HiveDao - start to execute the sql :insert into test_table_double values (20180402, 120000, 91.54808149389302)
[0328 17:18:02 458 ERROR] [main] pmv6.dao.HiveDao - ERROR SQL: insert into test_table_double values (20180402, 120000, 91.54808149389302)
[0328 17:18:02 458 ERROR] [main] pmv6.dao.HiveDao - java.lang.RuntimeException: Cannot create staging directory 'hdfs://localhost:9000/home/chen/hive/warehouse/test_table_double/.hive-staging_hive_2018-03-28_02-18-02_379_4754160083649502923-48': Permission denied: user=hive, access=WRITE, inode="/home/chen/hive/warehouse/test_table_double":chen:supergroup:drwxr-xr-x
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.check(FSPermissionChecker.java:308)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:214)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:190)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkPermission(FSDirectory.java:1752)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkPermission(FSDirectory.java:1736)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkAncestorAccess(FSDirectory.java:1719)
	at org.apache.hadoop.hdfs.server.namenode.FSDirMkdirOp.mkdirs(FSDirMkdirOp.java:69)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.mkdirs(FSNamesystem.java:3867)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.mkdirs(NameNodeRpcServer.java:984)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.mkdirs(ClientNamenodeProtocolServerSideTranslatorPB.java:634)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:616)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:982)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2217)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2213)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1754)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2213)

java.sql.SQLException: java.lang.RuntimeException: Cannot create staging directory 'hdfs://localhost:9000/home/chen/hive/warehouse/test_table_double/.hive-staging_hive_2018-03-28_02-18-02_379_4754160083649502923-48': Permission denied: user=hive, access=WRITE, inode="/home/chen/hive/warehouse/test_table_double":chen:supergroup:drwxr-xr-x
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.check(FSPermissionChecker.java:308)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:214)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:190)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkPermission(FSDirectory.java:1752)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkPermission(FSDirectory.java:1736)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkAncestorAccess(FSDirectory.java:1719)
	at org.apache.hadoop.hdfs.server.namenode.FSDirMkdirOp.mkdirs(FSDirMkdirOp.java:69)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.mkdirs(FSNamesystem.java:3867)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.mkdirs(NameNodeRpcServer.java:984)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.mkdirs(ClientNamenodeProtocolServerSideTranslatorPB.java:634)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:616)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:982)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2217)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2213)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1754)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2213)

	at org.apache.hive.jdbc.HiveStatement.execute(HiveStatement.java:296)
	at org.apache.hive.jdbc.HivePreparedStatement.execute(HivePreparedStatement.java:98)
	at com.mchange.v2.c3p0.impl.NewProxyPreparedStatement.execute(NewProxyPreparedStatement.java:67)
	at com.inspur.pmv6.dao.HiveDao.executesql(HiveDao.java:152)
	at com.inspur.pmv6.Entrance.lambda$null$0(Entrance.java:83)
	at java.util.stream.Streams$RangeIntSpliterator.forEachRemaining(Streams.java:110)
	at java.util.stream.IntPipeline$Head.forEach(IntPipeline.java:557)
	at com.inspur.pmv6.Entrance.lambda$myTestCodes$1(Entrance.java:76)
	at java.util.stream.Streams$RangeIntSpliterator.forEachRemaining(Streams.java:110)
	at java.util.stream.IntPipeline$Head.forEach(IntPipeline.java:557)
	at com.inspur.pmv6.Entrance.myTestCodes(Entrance.java:74)
	at com.inspur.pmv6.Entrance.main(Entrance.java:43)
[0328 17:18:02 458 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29utxrumz1kq9f8v|80ec1f8]-HelperThread-#0] hive.jdbc.Utils - Supplied authorities: 10.211.55.29:10000
[0328 17:18:02 458 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29utxrumz1kq9f8v|80ec1f8]-HelperThread-#0] hive.jdbc.Utils - Resolved authority: 10.211.55.29:10000
[0328 17:18:02 459 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29utxrumz1kq9f8v|80ec1f8]-HelperThread-#0] hive.jdbc.HiveConnection - Will try to open client transport with JDBC Uri: jdbc:hive2://10.211.55.29:10000/default
[0328 17:18:02 459 INFO ] [main] pmv6.dao.HiveDao - start to execute the sql :insert into test_table_double values (20180402, 010000, 9.566068696023045)
[0328 17:18:02 576 ERROR] [main] pmv6.dao.HiveDao - ERROR SQL: insert into test_table_double values (20180402, 010000, 9.566068696023045)
[0328 17:18:02 576 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29utxrumz1kq9f8v|80ec1f8]-HelperThread-#2] hive.jdbc.Utils - Supplied authorities: 10.211.55.29:10000
[0328 17:18:02 576 ERROR] [main] pmv6.dao.HiveDao - java.lang.RuntimeException: Cannot create staging directory 'hdfs://localhost:9000/home/chen/hive/warehouse/test_table_double/.hive-staging_hive_2018-03-28_02-18-02_499_2757508809108020666-49': Permission denied: user=hive, access=WRITE, inode="/home/chen/hive/warehouse/test_table_double":chen:supergroup:drwxr-xr-x
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.check(FSPermissionChecker.java:308)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:214)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:190)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkPermission(FSDirectory.java:1752)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkPermission(FSDirectory.java:1736)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkAncestorAccess(FSDirectory.java:1719)
	at org.apache.hadoop.hdfs.server.namenode.FSDirMkdirOp.mkdirs(FSDirMkdirOp.java:69)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.mkdirs(FSNamesystem.java:3867)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.mkdirs(NameNodeRpcServer.java:984)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.mkdirs(ClientNamenodeProtocolServerSideTranslatorPB.java:634)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:616)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:982)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2217)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2213)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1754)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2213)

java.sql.SQLException: java.lang.RuntimeException: Cannot create staging directory 'hdfs://localhost:9000/home/chen/hive/warehouse/test_table_double/.hive-staging_hive_2018-03-28_02-18-02_499_2757508809108020666-49': Permission denied: user=hive, access=WRITE, inode="/home/chen/hive/warehouse/test_table_double":chen:supergroup:drwxr-xr-x
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.check(FSPermissionChecker.java:308)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:214)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:190)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkPermission(FSDirectory.java:1752)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkPermission(FSDirectory.java:1736)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkAncestorAccess(FSDirectory.java:1719)
	at org.apache.hadoop.hdfs.server.namenode.FSDirMkdirOp.mkdirs(FSDirMkdirOp.java:69)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.mkdirs(FSNamesystem.java:3867)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.mkdirs(NameNodeRpcServer.java:984)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.mkdirs(ClientNamenodeProtocolServerSideTranslatorPB.java:634)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:616)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:982)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2217)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2213)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1754)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2213)

	at org.apache.hive.jdbc.HiveStatement.execute(HiveStatement.java:296)
	at org.apache.hive.jdbc.HivePreparedStatement.execute(HivePreparedStatement.java:98)
	at com.mchange.v2.c3p0.impl.NewProxyPreparedStatement.execute(NewProxyPreparedStatement.java:67)
	at com.inspur.pmv6.dao.HiveDao.executesql(HiveDao.java:152)
	at com.inspur.pmv6.Entrance.lambda$null$0(Entrance.java:83)
	at java.util.stream.Streams$RangeIntSpliterator.forEachRemaining(Streams.java:110)
	at java.util.stream.IntPipeline$Head.forEach(IntPipeline.java:557)
	at com.inspur.pmv6.Entrance.lambda$myTestCodes$1(Entrance.java:76)
	at java.util.stream.Streams$RangeIntSpliterator.forEachRemaining(Streams.java:110)
	at java.util.stream.IntPipeline$Head.forEach(IntPipeline.java:557)
	at com.inspur.pmv6.Entrance.myTestCodes(Entrance.java:74)
	at com.inspur.pmv6.Entrance.main(Entrance.java:43)
[0328 17:18:02 577 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29utxrumz1kq9f8v|80ec1f8]-HelperThread-#2] hive.jdbc.Utils - Resolved authority: 10.211.55.29:10000
[0328 17:18:02 577 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29utxrumz1kq9f8v|80ec1f8]-HelperThread-#2] hive.jdbc.HiveConnection - Will try to open client transport with JDBC Uri: jdbc:hive2://10.211.55.29:10000/default
[0328 17:18:02 577 INFO ] [main] pmv6.dao.HiveDao - start to execute the sql :insert into test_table_double values (20180402, 020000, 33.65326622325342)
[0328 17:18:02 841 ERROR] [main] pmv6.dao.HiveDao - ERROR SQL: insert into test_table_double values (20180402, 020000, 33.65326622325342)
[0328 17:18:02 841 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29utxrumz1kq9f8v|80ec1f8]-HelperThread-#0] hive.jdbc.Utils - Supplied authorities: 10.211.55.29:10000
[0328 17:18:02 841 ERROR] [main] pmv6.dao.HiveDao - java.lang.RuntimeException: Cannot create staging directory 'hdfs://localhost:9000/home/chen/hive/warehouse/test_table_double/.hive-staging_hive_2018-03-28_02-18-02_758_3551351952516986399-50': Permission denied: user=hive, access=WRITE, inode="/home/chen/hive/warehouse/test_table_double":chen:supergroup:drwxr-xr-x
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.check(FSPermissionChecker.java:308)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:214)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:190)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkPermission(FSDirectory.java:1752)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkPermission(FSDirectory.java:1736)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkAncestorAccess(FSDirectory.java:1719)
	at org.apache.hadoop.hdfs.server.namenode.FSDirMkdirOp.mkdirs(FSDirMkdirOp.java:69)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.mkdirs(FSNamesystem.java:3867)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.mkdirs(NameNodeRpcServer.java:984)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.mkdirs(ClientNamenodeProtocolServerSideTranslatorPB.java:634)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:616)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:982)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2217)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2213)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1754)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2213)

java.sql.SQLException: java.lang.RuntimeException: Cannot create staging directory 'hdfs://localhost:9000/home/chen/hive/warehouse/test_table_double/.hive-staging_hive_2018-03-28_02-18-02_758_3551351952516986399-50': Permission denied: user=hive, access=WRITE, inode="/home/chen/hive/warehouse/test_table_double":chen:supergroup:drwxr-xr-x
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.check(FSPermissionChecker.java:308)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:214)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:190)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkPermission(FSDirectory.java:1752)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkPermission(FSDirectory.java:1736)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkAncestorAccess(FSDirectory.java:1719)
	at org.apache.hadoop.hdfs.server.namenode.FSDirMkdirOp.mkdirs(FSDirMkdirOp.java:69)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.mkdirs(FSNamesystem.java:3867)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.mkdirs(NameNodeRpcServer.java:984)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.mkdirs(ClientNamenodeProtocolServerSideTranslatorPB.java:634)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:616)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:982)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2217)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2213)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1754)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2213)

	at org.apache.hive.jdbc.HiveStatement.execute(HiveStatement.java:296)
	at org.apache.hive.jdbc.HivePreparedStatement.execute(HivePreparedStatement.java:98)
	at com.mchange.v2.c3p0.impl.NewProxyPreparedStatement.execute(NewProxyPreparedStatement.java:67)
	at com.inspur.pmv6.dao.HiveDao.executesql(HiveDao.java:152)
	at com.inspur.pmv6.Entrance.lambda$null$0(Entrance.java:83)
	at java.util.stream.Streams$RangeIntSpliterator.forEachRemaining(Streams.java:110)
	at java.util.stream.IntPipeline$Head.forEach(IntPipeline.java:557)
	at com.inspur.pmv6.Entrance.lambda$myTestCodes$1(Entrance.java:76)
	at java.util.stream.Streams$RangeIntSpliterator.forEachRemaining(Streams.java:110)
	at java.util.stream.IntPipeline$Head.forEach(IntPipeline.java:557)
	at com.inspur.pmv6.Entrance.myTestCodes(Entrance.java:74)
	at com.inspur.pmv6.Entrance.main(Entrance.java:43)
[0328 17:18:02 842 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29utxrumz1kq9f8v|80ec1f8]-HelperThread-#0] hive.jdbc.Utils - Resolved authority: 10.211.55.29:10000
[0328 17:18:02 842 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29utxrumz1kq9f8v|80ec1f8]-HelperThread-#0] hive.jdbc.HiveConnection - Will try to open client transport with JDBC Uri: jdbc:hive2://10.211.55.29:10000/default
[0328 17:18:02 843 INFO ] [main] pmv6.dao.HiveDao - start to execute the sql :insert into test_table_double values (20180402, 030000, 52.926022764782786)
[0328 17:18:03 043 ERROR] [main] pmv6.dao.HiveDao - ERROR SQL: insert into test_table_double values (20180402, 030000, 52.926022764782786)
[0328 17:18:03 043 ERROR] [main] pmv6.dao.HiveDao - java.lang.RuntimeException: Cannot create staging directory 'hdfs://localhost:9000/home/chen/hive/warehouse/test_table_double/.hive-staging_hive_2018-03-28_02-18-02_970_6758903255532740734-51': Permission denied: user=hive, access=WRITE, inode="/home/chen/hive/warehouse/test_table_double":chen:supergroup:drwxr-xr-x
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.check(FSPermissionChecker.java:308)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:214)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:190)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkPermission(FSDirectory.java:1752)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkPermission(FSDirectory.java:1736)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkAncestorAccess(FSDirectory.java:1719)
	at org.apache.hadoop.hdfs.server.namenode.FSDirMkdirOp.mkdirs(FSDirMkdirOp.java:69)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.mkdirs(FSNamesystem.java:3867)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.mkdirs(NameNodeRpcServer.java:984)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.mkdirs(ClientNamenodeProtocolServerSideTranslatorPB.java:634)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:616)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:982)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2217)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2213)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1754)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2213)

java.sql.SQLException: java.lang.RuntimeException: Cannot create staging directory 'hdfs://localhost:9000/home/chen/hive/warehouse/test_table_double/.hive-staging_hive_2018-03-28_02-18-02_970_6758903255532740734-51': Permission denied: user=hive, access=WRITE, inode="/home/chen/hive/warehouse/test_table_double":chen:supergroup:drwxr-xr-x
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.check(FSPermissionChecker.java:308)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:214)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:190)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkPermission(FSDirectory.java:1752)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkPermission(FSDirectory.java:1736)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkAncestorAccess(FSDirectory.java:1719)
	at org.apache.hadoop.hdfs.server.namenode.FSDirMkdirOp.mkdirs(FSDirMkdirOp.java:69)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.mkdirs(FSNamesystem.java:3867)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.mkdirs(NameNodeRpcServer.java:984)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.mkdirs(ClientNamenodeProtocolServerSideTranslatorPB.java:634)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:616)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:982)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2217)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2213)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1754)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2213)

	at org.apache.hive.jdbc.HiveStatement.execute(HiveStatement.java:296)
	at org.apache.hive.jdbc.HivePreparedStatement.execute(HivePreparedStatement.java:98)
	at com.mchange.v2.c3p0.impl.NewProxyPreparedStatement.execute(NewProxyPreparedStatement.java:67)
	at com.inspur.pmv6.dao.HiveDao.executesql(HiveDao.java:152)
	at com.inspur.pmv6.Entrance.lambda$null$0(Entrance.java:83)
	at java.util.stream.Streams$RangeIntSpliterator.forEachRemaining(Streams.java:110)
	at java.util.stream.IntPipeline$Head.forEach(IntPipeline.java:557)
	at com.inspur.pmv6.Entrance.lambda$myTestCodes$1(Entrance.java:76)
	at java.util.stream.Streams$RangeIntSpliterator.forEachRemaining(Streams.java:110)
	at java.util.stream.IntPipeline$Head.forEach(IntPipeline.java:557)
	at com.inspur.pmv6.Entrance.myTestCodes(Entrance.java:74)
	at com.inspur.pmv6.Entrance.main(Entrance.java:43)
[0328 17:18:03 043 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29utxrumz1kq9f8v|80ec1f8]-HelperThread-#2] hive.jdbc.Utils - Supplied authorities: 10.211.55.29:10000
[0328 17:18:03 044 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29utxrumz1kq9f8v|80ec1f8]-HelperThread-#2] hive.jdbc.Utils - Resolved authority: 10.211.55.29:10000
[0328 17:18:03 044 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29utxrumz1kq9f8v|80ec1f8]-HelperThread-#2] hive.jdbc.HiveConnection - Will try to open client transport with JDBC Uri: jdbc:hive2://10.211.55.29:10000/default
[0328 17:18:03 045 INFO ] [main] pmv6.dao.HiveDao - start to execute the sql :insert into test_table_double values (20180402, 040000, 57.553511075175855)
[0328 17:18:03 234 ERROR] [main] pmv6.dao.HiveDao - ERROR SQL: insert into test_table_double values (20180402, 040000, 57.553511075175855)
[0328 17:18:03 234 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29utxrumz1kq9f8v|80ec1f8]-HelperThread-#0] hive.jdbc.Utils - Supplied authorities: 10.211.55.29:10000
[0328 17:18:03 234 ERROR] [main] pmv6.dao.HiveDao - java.lang.RuntimeException: Cannot create staging directory 'hdfs://localhost:9000/home/chen/hive/warehouse/test_table_double/.hive-staging_hive_2018-03-28_02-18-03_145_5060456508012150291-52': Permission denied: user=hive, access=WRITE, inode="/home/chen/hive/warehouse/test_table_double":chen:supergroup:drwxr-xr-x
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.check(FSPermissionChecker.java:308)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:214)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:190)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkPermission(FSDirectory.java:1752)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkPermission(FSDirectory.java:1736)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkAncestorAccess(FSDirectory.java:1719)
	at org.apache.hadoop.hdfs.server.namenode.FSDirMkdirOp.mkdirs(FSDirMkdirOp.java:69)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.mkdirs(FSNamesystem.java:3867)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.mkdirs(NameNodeRpcServer.java:984)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.mkdirs(ClientNamenodeProtocolServerSideTranslatorPB.java:634)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:616)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:982)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2217)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2213)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1754)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2213)

java.sql.SQLException: java.lang.RuntimeException: Cannot create staging directory 'hdfs://localhost:9000/home/chen/hive/warehouse/test_table_double/.hive-staging_hive_2018-03-28_02-18-03_145_5060456508012150291-52': Permission denied: user=hive, access=WRITE, inode="/home/chen/hive/warehouse/test_table_double":chen:supergroup:drwxr-xr-x
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.check(FSPermissionChecker.java:308)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:214)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:190)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkPermission(FSDirectory.java:1752)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkPermission(FSDirectory.java:1736)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkAncestorAccess(FSDirectory.java:1719)
	at org.apache.hadoop.hdfs.server.namenode.FSDirMkdirOp.mkdirs(FSDirMkdirOp.java:69)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.mkdirs(FSNamesystem.java:3867)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.mkdirs(NameNodeRpcServer.java:984)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.mkdirs(ClientNamenodeProtocolServerSideTranslatorPB.java:634)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:616)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:982)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2217)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2213)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1754)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2213)

	at org.apache.hive.jdbc.HiveStatement.execute(HiveStatement.java:296)
	at org.apache.hive.jdbc.HivePreparedStatement.execute(HivePreparedStatement.java:98)
	at com.mchange.v2.c3p0.impl.NewProxyPreparedStatement.execute(NewProxyPreparedStatement.java:67)
	at com.inspur.pmv6.dao.HiveDao.executesql(HiveDao.java:152)
	at com.inspur.pmv6.Entrance.lambda$null$0(Entrance.java:83)
	at java.util.stream.Streams$RangeIntSpliterator.forEachRemaining(Streams.java:110)
	at java.util.stream.IntPipeline$Head.forEach(IntPipeline.java:557)
	at com.inspur.pmv6.Entrance.lambda$myTestCodes$1(Entrance.java:76)
	at java.util.stream.Streams$RangeIntSpliterator.forEachRemaining(Streams.java:110)
	at java.util.stream.IntPipeline$Head.forEach(IntPipeline.java:557)
	at com.inspur.pmv6.Entrance.myTestCodes(Entrance.java:74)
	at com.inspur.pmv6.Entrance.main(Entrance.java:43)
[0328 17:18:03 234 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29utxrumz1kq9f8v|80ec1f8]-HelperThread-#0] hive.jdbc.Utils - Resolved authority: 10.211.55.29:10000
[0328 17:18:03 234 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29utxrumz1kq9f8v|80ec1f8]-HelperThread-#0] hive.jdbc.HiveConnection - Will try to open client transport with JDBC Uri: jdbc:hive2://10.211.55.29:10000/default
[0328 17:18:03 235 INFO ] [main] pmv6.dao.HiveDao - start to execute the sql :insert into test_table_double values (20180402, 050000, 56.130024666674096)
[0328 17:18:03 428 ERROR] [main] pmv6.dao.HiveDao - ERROR SQL: insert into test_table_double values (20180402, 050000, 56.130024666674096)
[0328 17:18:03 428 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29utxrumz1kq9f8v|80ec1f8]-HelperThread-#2] hive.jdbc.Utils - Supplied authorities: 10.211.55.29:10000
[0328 17:18:03 428 ERROR] [main] pmv6.dao.HiveDao - java.lang.RuntimeException: Cannot create staging directory 'hdfs://localhost:9000/home/chen/hive/warehouse/test_table_double/.hive-staging_hive_2018-03-28_02-18-03_336_5484319401602642847-53': Permission denied: user=hive, access=WRITE, inode="/home/chen/hive/warehouse/test_table_double":chen:supergroup:drwxr-xr-x
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.check(FSPermissionChecker.java:308)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:214)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:190)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkPermission(FSDirectory.java:1752)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkPermission(FSDirectory.java:1736)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkAncestorAccess(FSDirectory.java:1719)
	at org.apache.hadoop.hdfs.server.namenode.FSDirMkdirOp.mkdirs(FSDirMkdirOp.java:69)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.mkdirs(FSNamesystem.java:3867)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.mkdirs(NameNodeRpcServer.java:984)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.mkdirs(ClientNamenodeProtocolServerSideTranslatorPB.java:634)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:616)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:982)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2217)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2213)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1754)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2213)

java.sql.SQLException: java.lang.RuntimeException: Cannot create staging directory 'hdfs://localhost:9000/home/chen/hive/warehouse/test_table_double/.hive-staging_hive_2018-03-28_02-18-03_336_5484319401602642847-53': Permission denied: user=hive, access=WRITE, inode="/home/chen/hive/warehouse/test_table_double":chen:supergroup:drwxr-xr-x
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.check(FSPermissionChecker.java:308)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:214)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:190)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkPermission(FSDirectory.java:1752)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkPermission(FSDirectory.java:1736)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkAncestorAccess(FSDirectory.java:1719)
	at org.apache.hadoop.hdfs.server.namenode.FSDirMkdirOp.mkdirs(FSDirMkdirOp.java:69)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.mkdirs(FSNamesystem.java:3867)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.mkdirs(NameNodeRpcServer.java:984)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.mkdirs(ClientNamenodeProtocolServerSideTranslatorPB.java:634)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:616)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:982)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2217)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2213)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1754)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2213)

	at org.apache.hive.jdbc.HiveStatement.execute(HiveStatement.java:296)
	at org.apache.hive.jdbc.HivePreparedStatement.execute(HivePreparedStatement.java:98)
	at com.mchange.v2.c3p0.impl.NewProxyPreparedStatement.execute(NewProxyPreparedStatement.java:67)
	at com.inspur.pmv6.dao.HiveDao.executesql(HiveDao.java:152)
	at com.inspur.pmv6.Entrance.lambda$null$0(Entrance.java:83)
	at java.util.stream.Streams$RangeIntSpliterator.forEachRemaining(Streams.java:110)
	at java.util.stream.IntPipeline$Head.forEach(IntPipeline.java:557)
	at com.inspur.pmv6.Entrance.lambda$myTestCodes$1(Entrance.java:76)
	at java.util.stream.Streams$RangeIntSpliterator.forEachRemaining(Streams.java:110)
	at java.util.stream.IntPipeline$Head.forEach(IntPipeline.java:557)
	at com.inspur.pmv6.Entrance.myTestCodes(Entrance.java:74)
	at com.inspur.pmv6.Entrance.main(Entrance.java:43)
[0328 17:18:03 428 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29utxrumz1kq9f8v|80ec1f8]-HelperThread-#2] hive.jdbc.Utils - Resolved authority: 10.211.55.29:10000
[0328 17:18:03 428 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29utxrumz1kq9f8v|80ec1f8]-HelperThread-#2] hive.jdbc.HiveConnection - Will try to open client transport with JDBC Uri: jdbc:hive2://10.211.55.29:10000/default
[0328 17:18:03 429 INFO ] [main] pmv6.dao.HiveDao - start to execute the sql :insert into test_table_double values (20180402, 060000, 17.975922476251505)
[0328 17:18:03 633 ERROR] [main] pmv6.dao.HiveDao - ERROR SQL: insert into test_table_double values (20180402, 060000, 17.975922476251505)
[0328 17:18:03 633 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29utxrumz1kq9f8v|80ec1f8]-HelperThread-#0] hive.jdbc.Utils - Supplied authorities: 10.211.55.29:10000
[0328 17:18:03 633 ERROR] [main] pmv6.dao.HiveDao - java.lang.RuntimeException: Cannot create staging directory 'hdfs://localhost:9000/home/chen/hive/warehouse/test_table_double/.hive-staging_hive_2018-03-28_02-18-03_558_1651538259080582688-54': Permission denied: user=hive, access=WRITE, inode="/home/chen/hive/warehouse/test_table_double":chen:supergroup:drwxr-xr-x
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.check(FSPermissionChecker.java:308)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:214)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:190)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkPermission(FSDirectory.java:1752)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkPermission(FSDirectory.java:1736)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkAncestorAccess(FSDirectory.java:1719)
	at org.apache.hadoop.hdfs.server.namenode.FSDirMkdirOp.mkdirs(FSDirMkdirOp.java:69)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.mkdirs(FSNamesystem.java:3867)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.mkdirs(NameNodeRpcServer.java:984)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.mkdirs(ClientNamenodeProtocolServerSideTranslatorPB.java:634)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:616)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:982)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2217)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2213)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1754)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2213)

java.sql.SQLException: java.lang.RuntimeException: Cannot create staging directory 'hdfs://localhost:9000/home/chen/hive/warehouse/test_table_double/.hive-staging_hive_2018-03-28_02-18-03_558_1651538259080582688-54': Permission denied: user=hive, access=WRITE, inode="/home/chen/hive/warehouse/test_table_double":chen:supergroup:drwxr-xr-x
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.check(FSPermissionChecker.java:308)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:214)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:190)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkPermission(FSDirectory.java:1752)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkPermission(FSDirectory.java:1736)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkAncestorAccess(FSDirectory.java:1719)
	at org.apache.hadoop.hdfs.server.namenode.FSDirMkdirOp.mkdirs(FSDirMkdirOp.java:69)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.mkdirs(FSNamesystem.java:3867)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.mkdirs(NameNodeRpcServer.java:984)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.mkdirs(ClientNamenodeProtocolServerSideTranslatorPB.java:634)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:616)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:982)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2217)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2213)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1754)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2213)

	at org.apache.hive.jdbc.HiveStatement.execute(HiveStatement.java:296)
	at org.apache.hive.jdbc.HivePreparedStatement.execute(HivePreparedStatement.java:98)
	at com.mchange.v2.c3p0.impl.NewProxyPreparedStatement.execute(NewProxyPreparedStatement.java:67)
	at com.inspur.pmv6.dao.HiveDao.executesql(HiveDao.java:152)
	at com.inspur.pmv6.Entrance.lambda$null$0(Entrance.java:83)
	at java.util.stream.Streams$RangeIntSpliterator.forEachRemaining(Streams.java:110)
	at java.util.stream.IntPipeline$Head.forEach(IntPipeline.java:557)
	at com.inspur.pmv6.Entrance.lambda$myTestCodes$1(Entrance.java:76)
	at java.util.stream.Streams$RangeIntSpliterator.forEachRemaining(Streams.java:110)
	at java.util.stream.IntPipeline$Head.forEach(IntPipeline.java:557)
	at com.inspur.pmv6.Entrance.myTestCodes(Entrance.java:74)
	at com.inspur.pmv6.Entrance.main(Entrance.java:43)
[0328 17:18:03 634 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29utxrumz1kq9f8v|80ec1f8]-HelperThread-#0] hive.jdbc.Utils - Resolved authority: 10.211.55.29:10000
[0328 17:18:03 634 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29utxrumz1kq9f8v|80ec1f8]-HelperThread-#0] hive.jdbc.HiveConnection - Will try to open client transport with JDBC Uri: jdbc:hive2://10.211.55.29:10000/default
[0328 17:18:03 635 INFO ] [main] pmv6.dao.HiveDao - start to execute the sql :insert into test_table_double values (20180402, 070000, 26.20841161960574)
[0328 17:18:03 835 ERROR] [main] pmv6.dao.HiveDao - ERROR SQL: insert into test_table_double values (20180402, 070000, 26.20841161960574)
[0328 17:18:03 835 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29utxrumz1kq9f8v|80ec1f8]-HelperThread-#2] hive.jdbc.Utils - Supplied authorities: 10.211.55.29:10000
[0328 17:18:03 835 ERROR] [main] pmv6.dao.HiveDao - java.lang.RuntimeException: Cannot create staging directory 'hdfs://localhost:9000/home/chen/hive/warehouse/test_table_double/.hive-staging_hive_2018-03-28_02-18-03_764_8970479559830279859-55': Permission denied: user=hive, access=WRITE, inode="/home/chen/hive/warehouse/test_table_double":chen:supergroup:drwxr-xr-x
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.check(FSPermissionChecker.java:308)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:214)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:190)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkPermission(FSDirectory.java:1752)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkPermission(FSDirectory.java:1736)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkAncestorAccess(FSDirectory.java:1719)
	at org.apache.hadoop.hdfs.server.namenode.FSDirMkdirOp.mkdirs(FSDirMkdirOp.java:69)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.mkdirs(FSNamesystem.java:3867)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.mkdirs(NameNodeRpcServer.java:984)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.mkdirs(ClientNamenodeProtocolServerSideTranslatorPB.java:634)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:616)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:982)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2217)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2213)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1754)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2213)

java.sql.SQLException: java.lang.RuntimeException: Cannot create staging directory 'hdfs://localhost:9000/home/chen/hive/warehouse/test_table_double/.hive-staging_hive_2018-03-28_02-18-03_764_8970479559830279859-55': Permission denied: user=hive, access=WRITE, inode="/home/chen/hive/warehouse/test_table_double":chen:supergroup:drwxr-xr-x
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.check(FSPermissionChecker.java:308)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:214)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:190)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkPermission(FSDirectory.java:1752)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkPermission(FSDirectory.java:1736)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkAncestorAccess(FSDirectory.java:1719)
	at org.apache.hadoop.hdfs.server.namenode.FSDirMkdirOp.mkdirs(FSDirMkdirOp.java:69)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.mkdirs(FSNamesystem.java:3867)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.mkdirs(NameNodeRpcServer.java:984)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.mkdirs(ClientNamenodeProtocolServerSideTranslatorPB.java:634)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:616)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:982)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2217)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2213)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1754)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2213)

	at org.apache.hive.jdbc.HiveStatement.execute(HiveStatement.java:296)
	at org.apache.hive.jdbc.HivePreparedStatement.execute(HivePreparedStatement.java:98)
	at com.mchange.v2.c3p0.impl.NewProxyPreparedStatement.execute(NewProxyPreparedStatement.java:67)
	at com.inspur.pmv6.dao.HiveDao.executesql(HiveDao.java:152)
	at com.inspur.pmv6.Entrance.lambda$null$0(Entrance.java:83)
	at java.util.stream.Streams$RangeIntSpliterator.forEachRemaining(Streams.java:110)
	at java.util.stream.IntPipeline$Head.forEach(IntPipeline.java:557)
	at com.inspur.pmv6.Entrance.lambda$myTestCodes$1(Entrance.java:76)
	at java.util.stream.Streams$RangeIntSpliterator.forEachRemaining(Streams.java:110)
	at java.util.stream.IntPipeline$Head.forEach(IntPipeline.java:557)
	at com.inspur.pmv6.Entrance.myTestCodes(Entrance.java:74)
	at com.inspur.pmv6.Entrance.main(Entrance.java:43)
[0328 17:18:03 836 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29utxrumz1kq9f8v|80ec1f8]-HelperThread-#2] hive.jdbc.Utils - Resolved authority: 10.211.55.29:10000
[0328 17:18:03 836 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29utxrumz1kq9f8v|80ec1f8]-HelperThread-#2] hive.jdbc.HiveConnection - Will try to open client transport with JDBC Uri: jdbc:hive2://10.211.55.29:10000/default
[0328 17:18:03 837 INFO ] [main] pmv6.dao.HiveDao - start to execute the sql :insert into test_table_double values (20180402, 080000, 79.7908749503182)
[0328 17:18:04 040 ERROR] [main] pmv6.dao.HiveDao - ERROR SQL: insert into test_table_double values (20180402, 080000, 79.7908749503182)
[0328 17:18:04 040 ERROR] [main] pmv6.dao.HiveDao - java.lang.RuntimeException: Cannot create staging directory 'hdfs://localhost:9000/home/chen/hive/warehouse/test_table_double/.hive-staging_hive_2018-03-28_02-18-03_972_6899352396054183789-56': Permission denied: user=hive, access=WRITE, inode="/home/chen/hive/warehouse/test_table_double":chen:supergroup:drwxr-xr-x
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.check(FSPermissionChecker.java:308)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:214)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:190)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkPermission(FSDirectory.java:1752)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkPermission(FSDirectory.java:1736)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkAncestorAccess(FSDirectory.java:1719)
	at org.apache.hadoop.hdfs.server.namenode.FSDirMkdirOp.mkdirs(FSDirMkdirOp.java:69)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.mkdirs(FSNamesystem.java:3867)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.mkdirs(NameNodeRpcServer.java:984)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.mkdirs(ClientNamenodeProtocolServerSideTranslatorPB.java:634)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:616)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:982)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2217)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2213)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1754)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2213)

java.sql.SQLException: java.lang.RuntimeException: Cannot create staging directory 'hdfs://localhost:9000/home/chen/hive/warehouse/test_table_double/.hive-staging_hive_2018-03-28_02-18-03_972_6899352396054183789-56': Permission denied: user=hive, access=WRITE, inode="/home/chen/hive/warehouse/test_table_double":chen:supergroup:drwxr-xr-x
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.check(FSPermissionChecker.java:308)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:214)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:190)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkPermission(FSDirectory.java:1752)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkPermission(FSDirectory.java:1736)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkAncestorAccess(FSDirectory.java:1719)
	at org.apache.hadoop.hdfs.server.namenode.FSDirMkdirOp.mkdirs(FSDirMkdirOp.java:69)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.mkdirs(FSNamesystem.java:3867)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.mkdirs(NameNodeRpcServer.java:984)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.mkdirs(ClientNamenodeProtocolServerSideTranslatorPB.java:634)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:616)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:982)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2217)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2213)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1754)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2213)

	at org.apache.hive.jdbc.HiveStatement.execute(HiveStatement.java:296)
	at org.apache.hive.jdbc.HivePreparedStatement.execute(HivePreparedStatement.java:98)
	at com.mchange.v2.c3p0.impl.NewProxyPreparedStatement.execute(NewProxyPreparedStatement.java:67)
	at com.inspur.pmv6.dao.HiveDao.executesql(HiveDao.java:152)
	at com.inspur.pmv6.Entrance.lambda$null$0(Entrance.java:83)
	at java.util.stream.Streams$RangeIntSpliterator.forEachRemaining(Streams.java:110)
	at java.util.stream.IntPipeline$Head.forEach(IntPipeline.java:557)
	at com.inspur.pmv6.Entrance.lambda$myTestCodes$1(Entrance.java:76)
	at java.util.stream.Streams$RangeIntSpliterator.forEachRemaining(Streams.java:110)
	at java.util.stream.IntPipeline$Head.forEach(IntPipeline.java:557)
	at com.inspur.pmv6.Entrance.myTestCodes(Entrance.java:74)
	at com.inspur.pmv6.Entrance.main(Entrance.java:43)
[0328 17:18:04 040 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29utxrumz1kq9f8v|80ec1f8]-HelperThread-#2] hive.jdbc.Utils - Supplied authorities: 10.211.55.29:10000
[0328 17:18:04 041 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29utxrumz1kq9f8v|80ec1f8]-HelperThread-#2] hive.jdbc.Utils - Resolved authority: 10.211.55.29:10000
[0328 17:18:04 041 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29utxrumz1kq9f8v|80ec1f8]-HelperThread-#2] hive.jdbc.HiveConnection - Will try to open client transport with JDBC Uri: jdbc:hive2://10.211.55.29:10000/default
[0328 17:18:04 041 INFO ] [main] pmv6.dao.HiveDao - start to execute the sql :insert into test_table_double values (20180402, 090000, 76.74904600417905)
[0328 17:18:04 160 ERROR] [main] pmv6.dao.HiveDao - ERROR SQL: insert into test_table_double values (20180402, 090000, 76.74904600417905)
[0328 17:18:04 160 ERROR] [main] pmv6.dao.HiveDao - java.lang.RuntimeException: Cannot create staging directory 'hdfs://localhost:9000/home/chen/hive/warehouse/test_table_double/.hive-staging_hive_2018-03-28_02-18-04_087_9114437507037986802-57': Permission denied: user=hive, access=WRITE, inode="/home/chen/hive/warehouse/test_table_double":chen:supergroup:drwxr-xr-x
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.check(FSPermissionChecker.java:308)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:214)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:190)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkPermission(FSDirectory.java:1752)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkPermission(FSDirectory.java:1736)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkAncestorAccess(FSDirectory.java:1719)
	at org.apache.hadoop.hdfs.server.namenode.FSDirMkdirOp.mkdirs(FSDirMkdirOp.java:69)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.mkdirs(FSNamesystem.java:3867)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.mkdirs(NameNodeRpcServer.java:984)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.mkdirs(ClientNamenodeProtocolServerSideTranslatorPB.java:634)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:616)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:982)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2217)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2213)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1754)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2213)

java.sql.SQLException: java.lang.RuntimeException: Cannot create staging directory 'hdfs://localhost:9000/home/chen/hive/warehouse/test_table_double/.hive-staging_hive_2018-03-28_02-18-04_087_9114437507037986802-57': Permission denied: user=hive, access=WRITE, inode="/home/chen/hive/warehouse/test_table_double":chen:supergroup:drwxr-xr-x
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.check(FSPermissionChecker.java:308)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:214)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:190)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkPermission(FSDirectory.java:1752)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkPermission(FSDirectory.java:1736)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkAncestorAccess(FSDirectory.java:1719)
	at org.apache.hadoop.hdfs.server.namenode.FSDirMkdirOp.mkdirs(FSDirMkdirOp.java:69)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.mkdirs(FSNamesystem.java:3867)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.mkdirs(NameNodeRpcServer.java:984)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.mkdirs(ClientNamenodeProtocolServerSideTranslatorPB.java:634)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:616)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:982)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2217)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2213)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1754)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2213)

	at org.apache.hive.jdbc.HiveStatement.execute(HiveStatement.java:296)
	at org.apache.hive.jdbc.HivePreparedStatement.execute(HivePreparedStatement.java:98)
	at com.mchange.v2.c3p0.impl.NewProxyPreparedStatement.execute(NewProxyPreparedStatement.java:67)
	at com.inspur.pmv6.dao.HiveDao.executesql(HiveDao.java:152)
	at com.inspur.pmv6.Entrance.lambda$null$0(Entrance.java:83)
	at java.util.stream.Streams$RangeIntSpliterator.forEachRemaining(Streams.java:110)
	at java.util.stream.IntPipeline$Head.forEach(IntPipeline.java:557)
	at com.inspur.pmv6.Entrance.lambda$myTestCodes$1(Entrance.java:76)
	at java.util.stream.Streams$RangeIntSpliterator.forEachRemaining(Streams.java:110)
	at java.util.stream.IntPipeline$Head.forEach(IntPipeline.java:557)
	at com.inspur.pmv6.Entrance.myTestCodes(Entrance.java:74)
	at com.inspur.pmv6.Entrance.main(Entrance.java:43)
[0328 17:18:04 160 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29utxrumz1kq9f8v|80ec1f8]-HelperThread-#1] hive.jdbc.Utils - Supplied authorities: 10.211.55.29:10000
[0328 17:18:04 161 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29utxrumz1kq9f8v|80ec1f8]-HelperThread-#1] hive.jdbc.Utils - Resolved authority: 10.211.55.29:10000
[0328 17:18:04 161 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29utxrumz1kq9f8v|80ec1f8]-HelperThread-#1] hive.jdbc.HiveConnection - Will try to open client transport with JDBC Uri: jdbc:hive2://10.211.55.29:10000/default
[0328 17:18:04 161 INFO ] [main] pmv6.dao.HiveDao - start to execute the sql :insert into test_table_double values (20180402, 100000, 75.49333547636381)
[0328 17:18:04 355 ERROR] [main] pmv6.dao.HiveDao - ERROR SQL: insert into test_table_double values (20180402, 100000, 75.49333547636381)
[0328 17:18:04 355 ERROR] [main] pmv6.dao.HiveDao - java.lang.RuntimeException: Cannot create staging directory 'hdfs://localhost:9000/home/chen/hive/warehouse/test_table_double/.hive-staging_hive_2018-03-28_02-18-04_282_7304229905169487909-58': Permission denied: user=hive, access=WRITE, inode="/home/chen/hive/warehouse/test_table_double":chen:supergroup:drwxr-xr-x
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.check(FSPermissionChecker.java:308)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:214)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:190)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkPermission(FSDirectory.java:1752)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkPermission(FSDirectory.java:1736)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkAncestorAccess(FSDirectory.java:1719)
	at org.apache.hadoop.hdfs.server.namenode.FSDirMkdirOp.mkdirs(FSDirMkdirOp.java:69)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.mkdirs(FSNamesystem.java:3867)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.mkdirs(NameNodeRpcServer.java:984)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.mkdirs(ClientNamenodeProtocolServerSideTranslatorPB.java:634)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:616)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:982)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2217)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2213)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1754)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2213)

java.sql.SQLException: java.lang.RuntimeException: Cannot create staging directory 'hdfs://localhost:9000/home/chen/hive/warehouse/test_table_double/.hive-staging_hive_2018-03-28_02-18-04_282_7304229905169487909-58': Permission denied: user=hive, access=WRITE, inode="/home/chen/hive/warehouse/test_table_double":chen:supergroup:drwxr-xr-x
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.check(FSPermissionChecker.java:308)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:214)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:190)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkPermission(FSDirectory.java:1752)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkPermission(FSDirectory.java:1736)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkAncestorAccess(FSDirectory.java:1719)
	at org.apache.hadoop.hdfs.server.namenode.FSDirMkdirOp.mkdirs(FSDirMkdirOp.java:69)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.mkdirs(FSNamesystem.java:3867)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.mkdirs(NameNodeRpcServer.java:984)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.mkdirs(ClientNamenodeProtocolServerSideTranslatorPB.java:634)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:616)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:982)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2217)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2213)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1754)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2213)

	at org.apache.hive.jdbc.HiveStatement.execute(HiveStatement.java:296)
	at org.apache.hive.jdbc.HivePreparedStatement.execute(HivePreparedStatement.java:98)
	at com.mchange.v2.c3p0.impl.NewProxyPreparedStatement.execute(NewProxyPreparedStatement.java:67)
	at com.inspur.pmv6.dao.HiveDao.executesql(HiveDao.java:152)
	at com.inspur.pmv6.Entrance.lambda$null$0(Entrance.java:83)
	at java.util.stream.Streams$RangeIntSpliterator.forEachRemaining(Streams.java:110)
	at java.util.stream.IntPipeline$Head.forEach(IntPipeline.java:557)
	at com.inspur.pmv6.Entrance.lambda$myTestCodes$1(Entrance.java:76)
	at java.util.stream.Streams$RangeIntSpliterator.forEachRemaining(Streams.java:110)
	at java.util.stream.IntPipeline$Head.forEach(IntPipeline.java:557)
	at com.inspur.pmv6.Entrance.myTestCodes(Entrance.java:74)
	at com.inspur.pmv6.Entrance.main(Entrance.java:43)
[0328 17:18:04 355 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29utxrumz1kq9f8v|80ec1f8]-HelperThread-#1] hive.jdbc.Utils - Supplied authorities: 10.211.55.29:10000
[0328 17:18:04 356 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29utxrumz1kq9f8v|80ec1f8]-HelperThread-#1] hive.jdbc.Utils - Resolved authority: 10.211.55.29:10000
[0328 17:18:04 356 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29utxrumz1kq9f8v|80ec1f8]-HelperThread-#1] hive.jdbc.HiveConnection - Will try to open client transport with JDBC Uri: jdbc:hive2://10.211.55.29:10000/default
[0328 17:18:04 356 INFO ] [main] pmv6.dao.HiveDao - start to execute the sql :insert into test_table_double values (20180402, 110000, 77.15322746507684)
[0328 17:18:04 470 ERROR] [main] pmv6.dao.HiveDao - ERROR SQL: insert into test_table_double values (20180402, 110000, 77.15322746507684)
[0328 17:18:04 470 ERROR] [main] pmv6.dao.HiveDao - java.lang.RuntimeException: Cannot create staging directory 'hdfs://localhost:9000/home/chen/hive/warehouse/test_table_double/.hive-staging_hive_2018-03-28_02-18-04_397_2589412574958023642-59': Permission denied: user=hive, access=WRITE, inode="/home/chen/hive/warehouse/test_table_double":chen:supergroup:drwxr-xr-x
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.check(FSPermissionChecker.java:308)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:214)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:190)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkPermission(FSDirectory.java:1752)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkPermission(FSDirectory.java:1736)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkAncestorAccess(FSDirectory.java:1719)
	at org.apache.hadoop.hdfs.server.namenode.FSDirMkdirOp.mkdirs(FSDirMkdirOp.java:69)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.mkdirs(FSNamesystem.java:3867)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.mkdirs(NameNodeRpcServer.java:984)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.mkdirs(ClientNamenodeProtocolServerSideTranslatorPB.java:634)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:616)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:982)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2217)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2213)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1754)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2213)

java.sql.SQLException: java.lang.RuntimeException: Cannot create staging directory 'hdfs://localhost:9000/home/chen/hive/warehouse/test_table_double/.hive-staging_hive_2018-03-28_02-18-04_397_2589412574958023642-59': Permission denied: user=hive, access=WRITE, inode="/home/chen/hive/warehouse/test_table_double":chen:supergroup:drwxr-xr-x
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.check(FSPermissionChecker.java:308)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:214)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:190)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkPermission(FSDirectory.java:1752)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkPermission(FSDirectory.java:1736)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkAncestorAccess(FSDirectory.java:1719)
	at org.apache.hadoop.hdfs.server.namenode.FSDirMkdirOp.mkdirs(FSDirMkdirOp.java:69)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.mkdirs(FSNamesystem.java:3867)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.mkdirs(NameNodeRpcServer.java:984)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.mkdirs(ClientNamenodeProtocolServerSideTranslatorPB.java:634)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:616)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:982)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2217)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2213)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1754)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2213)

	at org.apache.hive.jdbc.HiveStatement.execute(HiveStatement.java:296)
	at org.apache.hive.jdbc.HivePreparedStatement.execute(HivePreparedStatement.java:98)
	at com.mchange.v2.c3p0.impl.NewProxyPreparedStatement.execute(NewProxyPreparedStatement.java:67)
	at com.inspur.pmv6.dao.HiveDao.executesql(HiveDao.java:152)
	at com.inspur.pmv6.Entrance.lambda$null$0(Entrance.java:83)
	at java.util.stream.Streams$RangeIntSpliterator.forEachRemaining(Streams.java:110)
	at java.util.stream.IntPipeline$Head.forEach(IntPipeline.java:557)
	at com.inspur.pmv6.Entrance.lambda$myTestCodes$1(Entrance.java:76)
	at java.util.stream.Streams$RangeIntSpliterator.forEachRemaining(Streams.java:110)
	at java.util.stream.IntPipeline$Head.forEach(IntPipeline.java:557)
	at com.inspur.pmv6.Entrance.myTestCodes(Entrance.java:74)
	at com.inspur.pmv6.Entrance.main(Entrance.java:43)
[0328 17:18:04 470 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29utxrumz1kq9f8v|80ec1f8]-HelperThread-#0] hive.jdbc.Utils - Supplied authorities: 10.211.55.29:10000
[0328 17:18:04 470 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29utxrumz1kq9f8v|80ec1f8]-HelperThread-#0] hive.jdbc.Utils - Resolved authority: 10.211.55.29:10000
[0328 17:18:04 470 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29utxrumz1kq9f8v|80ec1f8]-HelperThread-#0] hive.jdbc.HiveConnection - Will try to open client transport with JDBC Uri: jdbc:hive2://10.211.55.29:10000/default
[0328 17:18:04 471 INFO ] [main] pmv6.dao.HiveDao - start to execute the sql :insert into test_table_double values (20180402, 120000, 32.20131801823038)
[0328 17:18:04 760 ERROR] [main] pmv6.dao.HiveDao - ERROR SQL: insert into test_table_double values (20180402, 120000, 32.20131801823038)
[0328 17:18:04 760 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29utxrumz1kq9f8v|80ec1f8]-HelperThread-#0] hive.jdbc.Utils - Supplied authorities: 10.211.55.29:10000
[0328 17:18:04 760 ERROR] [main] pmv6.dao.HiveDao - java.lang.RuntimeException: Cannot create staging directory 'hdfs://localhost:9000/home/chen/hive/warehouse/test_table_double/.hive-staging_hive_2018-03-28_02-18-04_690_8570113527983170483-60': Permission denied: user=hive, access=WRITE, inode="/home/chen/hive/warehouse/test_table_double":chen:supergroup:drwxr-xr-x
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.check(FSPermissionChecker.java:308)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:214)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:190)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkPermission(FSDirectory.java:1752)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkPermission(FSDirectory.java:1736)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkAncestorAccess(FSDirectory.java:1719)
	at org.apache.hadoop.hdfs.server.namenode.FSDirMkdirOp.mkdirs(FSDirMkdirOp.java:69)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.mkdirs(FSNamesystem.java:3867)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.mkdirs(NameNodeRpcServer.java:984)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.mkdirs(ClientNamenodeProtocolServerSideTranslatorPB.java:634)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:616)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:982)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2217)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2213)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1754)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2213)

java.sql.SQLException: java.lang.RuntimeException: Cannot create staging directory 'hdfs://localhost:9000/home/chen/hive/warehouse/test_table_double/.hive-staging_hive_2018-03-28_02-18-04_690_8570113527983170483-60': Permission denied: user=hive, access=WRITE, inode="/home/chen/hive/warehouse/test_table_double":chen:supergroup:drwxr-xr-x
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.check(FSPermissionChecker.java:308)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:214)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:190)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkPermission(FSDirectory.java:1752)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkPermission(FSDirectory.java:1736)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkAncestorAccess(FSDirectory.java:1719)
	at org.apache.hadoop.hdfs.server.namenode.FSDirMkdirOp.mkdirs(FSDirMkdirOp.java:69)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.mkdirs(FSNamesystem.java:3867)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.mkdirs(NameNodeRpcServer.java:984)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.mkdirs(ClientNamenodeProtocolServerSideTranslatorPB.java:634)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:616)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:982)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2217)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2213)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1754)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2213)

	at org.apache.hive.jdbc.HiveStatement.execute(HiveStatement.java:296)
	at org.apache.hive.jdbc.HivePreparedStatement.execute(HivePreparedStatement.java:98)
	at com.mchange.v2.c3p0.impl.NewProxyPreparedStatement.execute(NewProxyPreparedStatement.java:67)
	at com.inspur.pmv6.dao.HiveDao.executesql(HiveDao.java:152)
	at com.inspur.pmv6.Entrance.lambda$null$0(Entrance.java:83)
	at java.util.stream.Streams$RangeIntSpliterator.forEachRemaining(Streams.java:110)
	at java.util.stream.IntPipeline$Head.forEach(IntPipeline.java:557)
	at com.inspur.pmv6.Entrance.lambda$myTestCodes$1(Entrance.java:76)
	at java.util.stream.Streams$RangeIntSpliterator.forEachRemaining(Streams.java:110)
	at java.util.stream.IntPipeline$Head.forEach(IntPipeline.java:557)
	at com.inspur.pmv6.Entrance.myTestCodes(Entrance.java:74)
	at com.inspur.pmv6.Entrance.main(Entrance.java:43)
[0328 17:18:04 760 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29utxrumz1kq9f8v|80ec1f8]-HelperThread-#0] hive.jdbc.Utils - Resolved authority: 10.211.55.29:10000
[0328 17:18:04 761 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29utxrumz1kq9f8v|80ec1f8]-HelperThread-#0] hive.jdbc.HiveConnection - Will try to open client transport with JDBC Uri: jdbc:hive2://10.211.55.29:10000/default
[0328 17:18:04 761 INFO ] [main] pmv6.dao.HiveDao - start to execute the sql :insert into test_table_double values (20180402, 010000, 99.40525599657907)
[0328 17:18:04 875 ERROR] [main] pmv6.dao.HiveDao - ERROR SQL: insert into test_table_double values (20180402, 010000, 99.40525599657907)
[0328 17:18:04 876 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29utxrumz1kq9f8v|80ec1f8]-HelperThread-#2] hive.jdbc.Utils - Supplied authorities: 10.211.55.29:10000
[0328 17:18:04 876 ERROR] [main] pmv6.dao.HiveDao - java.lang.RuntimeException: Cannot create staging directory 'hdfs://localhost:9000/home/chen/hive/warehouse/test_table_double/.hive-staging_hive_2018-03-28_02-18-04_801_3791193216189902673-61': Permission denied: user=hive, access=WRITE, inode="/home/chen/hive/warehouse/test_table_double":chen:supergroup:drwxr-xr-x
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.check(FSPermissionChecker.java:308)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:214)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:190)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkPermission(FSDirectory.java:1752)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkPermission(FSDirectory.java:1736)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkAncestorAccess(FSDirectory.java:1719)
	at org.apache.hadoop.hdfs.server.namenode.FSDirMkdirOp.mkdirs(FSDirMkdirOp.java:69)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.mkdirs(FSNamesystem.java:3867)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.mkdirs(NameNodeRpcServer.java:984)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.mkdirs(ClientNamenodeProtocolServerSideTranslatorPB.java:634)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:616)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:982)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2217)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2213)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1754)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2213)

java.sql.SQLException: java.lang.RuntimeException: Cannot create staging directory 'hdfs://localhost:9000/home/chen/hive/warehouse/test_table_double/.hive-staging_hive_2018-03-28_02-18-04_801_3791193216189902673-61': Permission denied: user=hive, access=WRITE, inode="/home/chen/hive/warehouse/test_table_double":chen:supergroup:drwxr-xr-x
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.check(FSPermissionChecker.java:308)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:214)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:190)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkPermission(FSDirectory.java:1752)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkPermission(FSDirectory.java:1736)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkAncestorAccess(FSDirectory.java:1719)
	at org.apache.hadoop.hdfs.server.namenode.FSDirMkdirOp.mkdirs(FSDirMkdirOp.java:69)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.mkdirs(FSNamesystem.java:3867)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.mkdirs(NameNodeRpcServer.java:984)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.mkdirs(ClientNamenodeProtocolServerSideTranslatorPB.java:634)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:616)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:982)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2217)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2213)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1754)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2213)

	at org.apache.hive.jdbc.HiveStatement.execute(HiveStatement.java:296)
	at org.apache.hive.jdbc.HivePreparedStatement.execute(HivePreparedStatement.java:98)
	at com.mchange.v2.c3p0.impl.NewProxyPreparedStatement.execute(NewProxyPreparedStatement.java:67)
	at com.inspur.pmv6.dao.HiveDao.executesql(HiveDao.java:152)
	at com.inspur.pmv6.Entrance.lambda$null$0(Entrance.java:83)
	at java.util.stream.Streams$RangeIntSpliterator.forEachRemaining(Streams.java:110)
	at java.util.stream.IntPipeline$Head.forEach(IntPipeline.java:557)
	at com.inspur.pmv6.Entrance.lambda$myTestCodes$1(Entrance.java:76)
	at java.util.stream.Streams$RangeIntSpliterator.forEachRemaining(Streams.java:110)
	at java.util.stream.IntPipeline$Head.forEach(IntPipeline.java:557)
	at com.inspur.pmv6.Entrance.myTestCodes(Entrance.java:74)
	at com.inspur.pmv6.Entrance.main(Entrance.java:43)
[0328 17:18:04 876 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29utxrumz1kq9f8v|80ec1f8]-HelperThread-#2] hive.jdbc.Utils - Resolved authority: 10.211.55.29:10000
[0328 17:18:04 877 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29utxrumz1kq9f8v|80ec1f8]-HelperThread-#2] hive.jdbc.HiveConnection - Will try to open client transport with JDBC Uri: jdbc:hive2://10.211.55.29:10000/default
[0328 17:18:04 877 INFO ] [main] pmv6.dao.HiveDao - start to execute the sql :insert into test_table_double values (20180402, 020000, 81.85194442517107)
[0328 17:18:05 109 ERROR] [main] pmv6.dao.HiveDao - ERROR SQL: insert into test_table_double values (20180402, 020000, 81.85194442517107)
[0328 17:18:05 109 ERROR] [main] pmv6.dao.HiveDao - java.lang.RuntimeException: Cannot create staging directory 'hdfs://localhost:9000/home/chen/hive/warehouse/test_table_double/.hive-staging_hive_2018-03-28_02-18-05_037_6390714040604365851-62': Permission denied: user=hive, access=WRITE, inode="/home/chen/hive/warehouse/test_table_double":chen:supergroup:drwxr-xr-x
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.check(FSPermissionChecker.java:308)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:214)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:190)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkPermission(FSDirectory.java:1752)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkPermission(FSDirectory.java:1736)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkAncestorAccess(FSDirectory.java:1719)
	at org.apache.hadoop.hdfs.server.namenode.FSDirMkdirOp.mkdirs(FSDirMkdirOp.java:69)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.mkdirs(FSNamesystem.java:3867)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.mkdirs(NameNodeRpcServer.java:984)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.mkdirs(ClientNamenodeProtocolServerSideTranslatorPB.java:634)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:616)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:982)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2217)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2213)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1754)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2213)

java.sql.SQLException: java.lang.RuntimeException: Cannot create staging directory 'hdfs://localhost:9000/home/chen/hive/warehouse/test_table_double/.hive-staging_hive_2018-03-28_02-18-05_037_6390714040604365851-62': Permission denied: user=hive, access=WRITE, inode="/home/chen/hive/warehouse/test_table_double":chen:supergroup:drwxr-xr-x
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.check(FSPermissionChecker.java:308)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:214)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:190)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkPermission(FSDirectory.java:1752)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkPermission(FSDirectory.java:1736)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkAncestorAccess(FSDirectory.java:1719)
	at org.apache.hadoop.hdfs.server.namenode.FSDirMkdirOp.mkdirs(FSDirMkdirOp.java:69)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.mkdirs(FSNamesystem.java:3867)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.mkdirs(NameNodeRpcServer.java:984)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.mkdirs(ClientNamenodeProtocolServerSideTranslatorPB.java:634)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:616)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:982)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2217)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2213)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1754)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2213)

	at org.apache.hive.jdbc.HiveStatement.execute(HiveStatement.java:296)
	at org.apache.hive.jdbc.HivePreparedStatement.execute(HivePreparedStatement.java:98)
	at com.mchange.v2.c3p0.impl.NewProxyPreparedStatement.execute(NewProxyPreparedStatement.java:67)
	at com.inspur.pmv6.dao.HiveDao.executesql(HiveDao.java:152)
	at com.inspur.pmv6.Entrance.lambda$null$0(Entrance.java:83)
	at java.util.stream.Streams$RangeIntSpliterator.forEachRemaining(Streams.java:110)
	at java.util.stream.IntPipeline$Head.forEach(IntPipeline.java:557)
	at com.inspur.pmv6.Entrance.lambda$myTestCodes$1(Entrance.java:76)
	at java.util.stream.Streams$RangeIntSpliterator.forEachRemaining(Streams.java:110)
	at java.util.stream.IntPipeline$Head.forEach(IntPipeline.java:557)
	at com.inspur.pmv6.Entrance.myTestCodes(Entrance.java:74)
	at com.inspur.pmv6.Entrance.main(Entrance.java:43)
[0328 17:18:05 109 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29utxrumz1kq9f8v|80ec1f8]-HelperThread-#0] hive.jdbc.Utils - Supplied authorities: 10.211.55.29:10000
[0328 17:18:05 110 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29utxrumz1kq9f8v|80ec1f8]-HelperThread-#0] hive.jdbc.Utils - Resolved authority: 10.211.55.29:10000
[0328 17:18:05 110 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29utxrumz1kq9f8v|80ec1f8]-HelperThread-#0] hive.jdbc.HiveConnection - Will try to open client transport with JDBC Uri: jdbc:hive2://10.211.55.29:10000/default
[0328 17:18:05 110 INFO ] [main] pmv6.dao.HiveDao - start to execute the sql :insert into test_table_double values (20180402, 030000, 70.83990747508096)
[0328 17:18:05 227 ERROR] [main] pmv6.dao.HiveDao - ERROR SQL: insert into test_table_double values (20180402, 030000, 70.83990747508096)
[0328 17:18:05 227 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29utxrumz1kq9f8v|80ec1f8]-HelperThread-#1] hive.jdbc.Utils - Supplied authorities: 10.211.55.29:10000
[0328 17:18:05 227 ERROR] [main] pmv6.dao.HiveDao - java.lang.RuntimeException: Cannot create staging directory 'hdfs://localhost:9000/home/chen/hive/warehouse/test_table_double/.hive-staging_hive_2018-03-28_02-18-05_154_1313216323732854340-63': Permission denied: user=hive, access=WRITE, inode="/home/chen/hive/warehouse/test_table_double":chen:supergroup:drwxr-xr-x
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.check(FSPermissionChecker.java:308)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:214)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:190)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkPermission(FSDirectory.java:1752)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkPermission(FSDirectory.java:1736)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkAncestorAccess(FSDirectory.java:1719)
	at org.apache.hadoop.hdfs.server.namenode.FSDirMkdirOp.mkdirs(FSDirMkdirOp.java:69)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.mkdirs(FSNamesystem.java:3867)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.mkdirs(NameNodeRpcServer.java:984)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.mkdirs(ClientNamenodeProtocolServerSideTranslatorPB.java:634)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:616)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:982)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2217)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2213)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1754)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2213)

java.sql.SQLException: java.lang.RuntimeException: Cannot create staging directory 'hdfs://localhost:9000/home/chen/hive/warehouse/test_table_double/.hive-staging_hive_2018-03-28_02-18-05_154_1313216323732854340-63': Permission denied: user=hive, access=WRITE, inode="/home/chen/hive/warehouse/test_table_double":chen:supergroup:drwxr-xr-x
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.check(FSPermissionChecker.java:308)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:214)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:190)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkPermission(FSDirectory.java:1752)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkPermission(FSDirectory.java:1736)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkAncestorAccess(FSDirectory.java:1719)
	at org.apache.hadoop.hdfs.server.namenode.FSDirMkdirOp.mkdirs(FSDirMkdirOp.java:69)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.mkdirs(FSNamesystem.java:3867)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.mkdirs(NameNodeRpcServer.java:984)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.mkdirs(ClientNamenodeProtocolServerSideTranslatorPB.java:634)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:616)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:982)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2217)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2213)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1754)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2213)

	at org.apache.hive.jdbc.HiveStatement.execute(HiveStatement.java:296)
	at org.apache.hive.jdbc.HivePreparedStatement.execute(HivePreparedStatement.java:98)
	at com.mchange.v2.c3p0.impl.NewProxyPreparedStatement.execute(NewProxyPreparedStatement.java:67)
	at com.inspur.pmv6.dao.HiveDao.executesql(HiveDao.java:152)
	at com.inspur.pmv6.Entrance.lambda$null$0(Entrance.java:83)
	at java.util.stream.Streams$RangeIntSpliterator.forEachRemaining(Streams.java:110)
	at java.util.stream.IntPipeline$Head.forEach(IntPipeline.java:557)
	at com.inspur.pmv6.Entrance.lambda$myTestCodes$1(Entrance.java:76)
	at java.util.stream.Streams$RangeIntSpliterator.forEachRemaining(Streams.java:110)
	at java.util.stream.IntPipeline$Head.forEach(IntPipeline.java:557)
	at com.inspur.pmv6.Entrance.myTestCodes(Entrance.java:74)
	at com.inspur.pmv6.Entrance.main(Entrance.java:43)
[0328 17:18:05 227 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29utxrumz1kq9f8v|80ec1f8]-HelperThread-#1] hive.jdbc.Utils - Resolved authority: 10.211.55.29:10000
[0328 17:18:05 228 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29utxrumz1kq9f8v|80ec1f8]-HelperThread-#1] hive.jdbc.HiveConnection - Will try to open client transport with JDBC Uri: jdbc:hive2://10.211.55.29:10000/default
[0328 17:18:05 228 INFO ] [main] pmv6.dao.HiveDao - start to execute the sql :insert into test_table_double values (20180402, 040000, 15.23336075958085)
[0328 17:18:05 473 ERROR] [main] pmv6.dao.HiveDao - ERROR SQL: insert into test_table_double values (20180402, 040000, 15.23336075958085)
[0328 17:18:05 473 ERROR] [main] pmv6.dao.HiveDao - java.lang.RuntimeException: Cannot create staging directory 'hdfs://localhost:9000/home/chen/hive/warehouse/test_table_double/.hive-staging_hive_2018-03-28_02-18-05_396_8377305578734428188-64': Permission denied: user=hive, access=WRITE, inode="/home/chen/hive/warehouse/test_table_double":chen:supergroup:drwxr-xr-x
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.check(FSPermissionChecker.java:308)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:214)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:190)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkPermission(FSDirectory.java:1752)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkPermission(FSDirectory.java:1736)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkAncestorAccess(FSDirectory.java:1719)
	at org.apache.hadoop.hdfs.server.namenode.FSDirMkdirOp.mkdirs(FSDirMkdirOp.java:69)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.mkdirs(FSNamesystem.java:3867)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.mkdirs(NameNodeRpcServer.java:984)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.mkdirs(ClientNamenodeProtocolServerSideTranslatorPB.java:634)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:616)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:982)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2217)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2213)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1754)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2213)

java.sql.SQLException: java.lang.RuntimeException: Cannot create staging directory 'hdfs://localhost:9000/home/chen/hive/warehouse/test_table_double/.hive-staging_hive_2018-03-28_02-18-05_396_8377305578734428188-64': Permission denied: user=hive, access=WRITE, inode="/home/chen/hive/warehouse/test_table_double":chen:supergroup:drwxr-xr-x
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.check(FSPermissionChecker.java:308)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:214)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:190)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkPermission(FSDirectory.java:1752)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkPermission(FSDirectory.java:1736)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkAncestorAccess(FSDirectory.java:1719)
	at org.apache.hadoop.hdfs.server.namenode.FSDirMkdirOp.mkdirs(FSDirMkdirOp.java:69)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.mkdirs(FSNamesystem.java:3867)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.mkdirs(NameNodeRpcServer.java:984)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.mkdirs(ClientNamenodeProtocolServerSideTranslatorPB.java:634)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:616)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:982)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2217)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2213)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1754)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2213)

	at org.apache.hive.jdbc.HiveStatement.execute(HiveStatement.java:296)
	at org.apache.hive.jdbc.HivePreparedStatement.execute(HivePreparedStatement.java:98)
	at com.mchange.v2.c3p0.impl.NewProxyPreparedStatement.execute(NewProxyPreparedStatement.java:67)
	at com.inspur.pmv6.dao.HiveDao.executesql(HiveDao.java:152)
	at com.inspur.pmv6.Entrance.lambda$null$0(Entrance.java:83)
	at java.util.stream.Streams$RangeIntSpliterator.forEachRemaining(Streams.java:110)
	at java.util.stream.IntPipeline$Head.forEach(IntPipeline.java:557)
	at com.inspur.pmv6.Entrance.lambda$myTestCodes$1(Entrance.java:76)
	at java.util.stream.Streams$RangeIntSpliterator.forEachRemaining(Streams.java:110)
	at java.util.stream.IntPipeline$Head.forEach(IntPipeline.java:557)
	at com.inspur.pmv6.Entrance.myTestCodes(Entrance.java:74)
	at com.inspur.pmv6.Entrance.main(Entrance.java:43)
[0328 17:18:05 473 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29utxrumz1kq9f8v|80ec1f8]-HelperThread-#0] hive.jdbc.Utils - Supplied authorities: 10.211.55.29:10000
[0328 17:18:05 474 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29utxrumz1kq9f8v|80ec1f8]-HelperThread-#0] hive.jdbc.Utils - Resolved authority: 10.211.55.29:10000
[0328 17:18:05 474 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29utxrumz1kq9f8v|80ec1f8]-HelperThread-#0] hive.jdbc.HiveConnection - Will try to open client transport with JDBC Uri: jdbc:hive2://10.211.55.29:10000/default
[0328 17:18:05 475 INFO ] [main] pmv6.dao.HiveDao - start to execute the sql :insert into test_table_double values (20180402, 050000, 83.87296614659083)
[0328 17:18:05 597 ERROR] [main] pmv6.dao.HiveDao - ERROR SQL: insert into test_table_double values (20180402, 050000, 83.87296614659083)
[0328 17:18:05 597 ERROR] [main] pmv6.dao.HiveDao - java.lang.RuntimeException: Cannot create staging directory 'hdfs://localhost:9000/home/chen/hive/warehouse/test_table_double/.hive-staging_hive_2018-03-28_02-18-05_522_4532979385722223137-65': Permission denied: user=hive, access=WRITE, inode="/home/chen/hive/warehouse/test_table_double":chen:supergroup:drwxr-xr-x
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.check(FSPermissionChecker.java:308)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:214)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:190)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkPermission(FSDirectory.java:1752)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkPermission(FSDirectory.java:1736)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkAncestorAccess(FSDirectory.java:1719)
	at org.apache.hadoop.hdfs.server.namenode.FSDirMkdirOp.mkdirs(FSDirMkdirOp.java:69)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.mkdirs(FSNamesystem.java:3867)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.mkdirs(NameNodeRpcServer.java:984)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.mkdirs(ClientNamenodeProtocolServerSideTranslatorPB.java:634)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:616)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:982)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2217)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2213)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1754)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2213)

java.sql.SQLException: java.lang.RuntimeException: Cannot create staging directory 'hdfs://localhost:9000/home/chen/hive/warehouse/test_table_double/.hive-staging_hive_2018-03-28_02-18-05_522_4532979385722223137-65': Permission denied: user=hive, access=WRITE, inode="/home/chen/hive/warehouse/test_table_double":chen:supergroup:drwxr-xr-x
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.check(FSPermissionChecker.java:308)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:214)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:190)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkPermission(FSDirectory.java:1752)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkPermission(FSDirectory.java:1736)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkAncestorAccess(FSDirectory.java:1719)
	at org.apache.hadoop.hdfs.server.namenode.FSDirMkdirOp.mkdirs(FSDirMkdirOp.java:69)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.mkdirs(FSNamesystem.java:3867)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.mkdirs(NameNodeRpcServer.java:984)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.mkdirs(ClientNamenodeProtocolServerSideTranslatorPB.java:634)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:616)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:982)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2217)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2213)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1754)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2213)

	at org.apache.hive.jdbc.HiveStatement.execute(HiveStatement.java:296)
	at org.apache.hive.jdbc.HivePreparedStatement.execute(HivePreparedStatement.java:98)
	at com.mchange.v2.c3p0.impl.NewProxyPreparedStatement.execute(NewProxyPreparedStatement.java:67)
	at com.inspur.pmv6.dao.HiveDao.executesql(HiveDao.java:152)
	at com.inspur.pmv6.Entrance.lambda$null$0(Entrance.java:83)
	at java.util.stream.Streams$RangeIntSpliterator.forEachRemaining(Streams.java:110)
	at java.util.stream.IntPipeline$Head.forEach(IntPipeline.java:557)
	at com.inspur.pmv6.Entrance.lambda$myTestCodes$1(Entrance.java:76)
	at java.util.stream.Streams$RangeIntSpliterator.forEachRemaining(Streams.java:110)
	at java.util.stream.IntPipeline$Head.forEach(IntPipeline.java:557)
	at com.inspur.pmv6.Entrance.myTestCodes(Entrance.java:74)
	at com.inspur.pmv6.Entrance.main(Entrance.java:43)
[0328 17:18:05 597 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29utxrumz1kq9f8v|80ec1f8]-HelperThread-#2] hive.jdbc.Utils - Supplied authorities: 10.211.55.29:10000
[0328 17:18:05 597 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29utxrumz1kq9f8v|80ec1f8]-HelperThread-#2] hive.jdbc.Utils - Resolved authority: 10.211.55.29:10000
[0328 17:18:05 598 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29utxrumz1kq9f8v|80ec1f8]-HelperThread-#2] hive.jdbc.HiveConnection - Will try to open client transport with JDBC Uri: jdbc:hive2://10.211.55.29:10000/default
[0328 17:18:05 598 INFO ] [main] pmv6.dao.HiveDao - start to execute the sql :insert into test_table_double values (20180402, 060000, 51.95663775974646)
[0328 17:18:05 796 ERROR] [main] pmv6.dao.HiveDao - ERROR SQL: insert into test_table_double values (20180402, 060000, 51.95663775974646)
[0328 17:18:05 796 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29utxrumz1kq9f8v|80ec1f8]-HelperThread-#0] hive.jdbc.Utils - Supplied authorities: 10.211.55.29:10000
[0328 17:18:05 796 ERROR] [main] pmv6.dao.HiveDao - java.lang.RuntimeException: Cannot create staging directory 'hdfs://localhost:9000/home/chen/hive/warehouse/test_table_double/.hive-staging_hive_2018-03-28_02-18-05_722_6641599667308166173-66': Permission denied: user=hive, access=WRITE, inode="/home/chen/hive/warehouse/test_table_double":chen:supergroup:drwxr-xr-x
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.check(FSPermissionChecker.java:308)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:214)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:190)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkPermission(FSDirectory.java:1752)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkPermission(FSDirectory.java:1736)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkAncestorAccess(FSDirectory.java:1719)
	at org.apache.hadoop.hdfs.server.namenode.FSDirMkdirOp.mkdirs(FSDirMkdirOp.java:69)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.mkdirs(FSNamesystem.java:3867)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.mkdirs(NameNodeRpcServer.java:984)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.mkdirs(ClientNamenodeProtocolServerSideTranslatorPB.java:634)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:616)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:982)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2217)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2213)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1754)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2213)

java.sql.SQLException: java.lang.RuntimeException: Cannot create staging directory 'hdfs://localhost:9000/home/chen/hive/warehouse/test_table_double/.hive-staging_hive_2018-03-28_02-18-05_722_6641599667308166173-66': Permission denied: user=hive, access=WRITE, inode="/home/chen/hive/warehouse/test_table_double":chen:supergroup:drwxr-xr-x
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.check(FSPermissionChecker.java:308)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:214)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:190)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkPermission(FSDirectory.java:1752)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkPermission(FSDirectory.java:1736)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkAncestorAccess(FSDirectory.java:1719)
	at org.apache.hadoop.hdfs.server.namenode.FSDirMkdirOp.mkdirs(FSDirMkdirOp.java:69)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.mkdirs(FSNamesystem.java:3867)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.mkdirs(NameNodeRpcServer.java:984)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.mkdirs(ClientNamenodeProtocolServerSideTranslatorPB.java:634)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:616)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:982)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2217)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2213)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1754)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2213)

	at org.apache.hive.jdbc.HiveStatement.execute(HiveStatement.java:296)
	at org.apache.hive.jdbc.HivePreparedStatement.execute(HivePreparedStatement.java:98)
	at com.mchange.v2.c3p0.impl.NewProxyPreparedStatement.execute(NewProxyPreparedStatement.java:67)
	at com.inspur.pmv6.dao.HiveDao.executesql(HiveDao.java:152)
	at com.inspur.pmv6.Entrance.lambda$null$0(Entrance.java:83)
	at java.util.stream.Streams$RangeIntSpliterator.forEachRemaining(Streams.java:110)
	at java.util.stream.IntPipeline$Head.forEach(IntPipeline.java:557)
	at com.inspur.pmv6.Entrance.lambda$myTestCodes$1(Entrance.java:76)
	at java.util.stream.Streams$RangeIntSpliterator.forEachRemaining(Streams.java:110)
	at java.util.stream.IntPipeline$Head.forEach(IntPipeline.java:557)
	at com.inspur.pmv6.Entrance.myTestCodes(Entrance.java:74)
	at com.inspur.pmv6.Entrance.main(Entrance.java:43)
[0328 17:18:05 796 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29utxrumz1kq9f8v|80ec1f8]-HelperThread-#0] hive.jdbc.Utils - Resolved authority: 10.211.55.29:10000
[0328 17:18:05 796 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29utxrumz1kq9f8v|80ec1f8]-HelperThread-#0] hive.jdbc.HiveConnection - Will try to open client transport with JDBC Uri: jdbc:hive2://10.211.55.29:10000/default
[0328 17:18:05 797 INFO ] [main] pmv6.dao.HiveDao - start to execute the sql :insert into test_table_double values (20180402, 070000, 70.11176701610961)
[0328 17:18:05 991 ERROR] [main] pmv6.dao.HiveDao - ERROR SQL: insert into test_table_double values (20180402, 070000, 70.11176701610961)
[0328 17:18:05 991 ERROR] [main] pmv6.dao.HiveDao - java.lang.RuntimeException: Cannot create staging directory 'hdfs://localhost:9000/home/chen/hive/warehouse/test_table_double/.hive-staging_hive_2018-03-28_02-18-05_918_2258336889021275824-67': Permission denied: user=hive, access=WRITE, inode="/home/chen/hive/warehouse/test_table_double":chen:supergroup:drwxr-xr-x
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.check(FSPermissionChecker.java:308)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:214)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:190)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkPermission(FSDirectory.java:1752)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkPermission(FSDirectory.java:1736)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkAncestorAccess(FSDirectory.java:1719)
	at org.apache.hadoop.hdfs.server.namenode.FSDirMkdirOp.mkdirs(FSDirMkdirOp.java:69)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.mkdirs(FSNamesystem.java:3867)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.mkdirs(NameNodeRpcServer.java:984)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.mkdirs(ClientNamenodeProtocolServerSideTranslatorPB.java:634)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:616)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:982)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2217)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2213)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1754)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2213)

java.sql.SQLException: java.lang.RuntimeException: Cannot create staging directory 'hdfs://localhost:9000/home/chen/hive/warehouse/test_table_double/.hive-staging_hive_2018-03-28_02-18-05_918_2258336889021275824-67': Permission denied: user=hive, access=WRITE, inode="/home/chen/hive/warehouse/test_table_double":chen:supergroup:drwxr-xr-x
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.check(FSPermissionChecker.java:308)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:214)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:190)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkPermission(FSDirectory.java:1752)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkPermission(FSDirectory.java:1736)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkAncestorAccess(FSDirectory.java:1719)
	at org.apache.hadoop.hdfs.server.namenode.FSDirMkdirOp.mkdirs(FSDirMkdirOp.java:69)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.mkdirs(FSNamesystem.java:3867)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.mkdirs(NameNodeRpcServer.java:984)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.mkdirs(ClientNamenodeProtocolServerSideTranslatorPB.java:634)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:616)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:982)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2217)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2213)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1754)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2213)

	at org.apache.hive.jdbc.HiveStatement.execute(HiveStatement.java:296)
	at org.apache.hive.jdbc.HivePreparedStatement.execute(HivePreparedStatement.java:98)
	at com.mchange.v2.c3p0.impl.NewProxyPreparedStatement.execute(NewProxyPreparedStatement.java:67)
	at com.inspur.pmv6.dao.HiveDao.executesql(HiveDao.java:152)
	at com.inspur.pmv6.Entrance.lambda$null$0(Entrance.java:83)
	at java.util.stream.Streams$RangeIntSpliterator.forEachRemaining(Streams.java:110)
	at java.util.stream.IntPipeline$Head.forEach(IntPipeline.java:557)
	at com.inspur.pmv6.Entrance.lambda$myTestCodes$1(Entrance.java:76)
	at java.util.stream.Streams$RangeIntSpliterator.forEachRemaining(Streams.java:110)
	at java.util.stream.IntPipeline$Head.forEach(IntPipeline.java:557)
	at com.inspur.pmv6.Entrance.myTestCodes(Entrance.java:74)
	at com.inspur.pmv6.Entrance.main(Entrance.java:43)
[0328 17:18:05 991 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29utxrumz1kq9f8v|80ec1f8]-HelperThread-#2] hive.jdbc.Utils - Supplied authorities: 10.211.55.29:10000
[0328 17:18:05 992 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29utxrumz1kq9f8v|80ec1f8]-HelperThread-#2] hive.jdbc.Utils - Resolved authority: 10.211.55.29:10000
[0328 17:18:05 992 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29utxrumz1kq9f8v|80ec1f8]-HelperThread-#2] hive.jdbc.HiveConnection - Will try to open client transport with JDBC Uri: jdbc:hive2://10.211.55.29:10000/default
[0328 17:18:05 992 INFO ] [main] pmv6.dao.HiveDao - start to execute the sql :insert into test_table_double values (20180402, 080000, 42.512009489849845)
[0328 17:18:06 106 ERROR] [main] pmv6.dao.HiveDao - ERROR SQL: insert into test_table_double values (20180402, 080000, 42.512009489849845)
[0328 17:18:06 106 ERROR] [main] pmv6.dao.HiveDao - java.lang.RuntimeException: Cannot create staging directory 'hdfs://localhost:9000/home/chen/hive/warehouse/test_table_double/.hive-staging_hive_2018-03-28_02-18-06_034_7828554137401639935-68': Permission denied: user=hive, access=WRITE, inode="/home/chen/hive/warehouse/test_table_double":chen:supergroup:drwxr-xr-x
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.check(FSPermissionChecker.java:308)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:214)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:190)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkPermission(FSDirectory.java:1752)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkPermission(FSDirectory.java:1736)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkAncestorAccess(FSDirectory.java:1719)
	at org.apache.hadoop.hdfs.server.namenode.FSDirMkdirOp.mkdirs(FSDirMkdirOp.java:69)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.mkdirs(FSNamesystem.java:3867)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.mkdirs(NameNodeRpcServer.java:984)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.mkdirs(ClientNamenodeProtocolServerSideTranslatorPB.java:634)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:616)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:982)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2217)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2213)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1754)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2213)

java.sql.SQLException: java.lang.RuntimeException: Cannot create staging directory 'hdfs://localhost:9000/home/chen/hive/warehouse/test_table_double/.hive-staging_hive_2018-03-28_02-18-06_034_7828554137401639935-68': Permission denied: user=hive, access=WRITE, inode="/home/chen/hive/warehouse/test_table_double":chen:supergroup:drwxr-xr-x
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.check(FSPermissionChecker.java:308)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:214)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:190)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkPermission(FSDirectory.java:1752)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkPermission(FSDirectory.java:1736)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkAncestorAccess(FSDirectory.java:1719)
	at org.apache.hadoop.hdfs.server.namenode.FSDirMkdirOp.mkdirs(FSDirMkdirOp.java:69)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.mkdirs(FSNamesystem.java:3867)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.mkdirs(NameNodeRpcServer.java:984)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.mkdirs(ClientNamenodeProtocolServerSideTranslatorPB.java:634)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:616)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:982)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2217)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2213)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1754)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2213)

	at org.apache.hive.jdbc.HiveStatement.execute(HiveStatement.java:296)
	at org.apache.hive.jdbc.HivePreparedStatement.execute(HivePreparedStatement.java:98)
	at com.mchange.v2.c3p0.impl.NewProxyPreparedStatement.execute(NewProxyPreparedStatement.java:67)
	at com.inspur.pmv6.dao.HiveDao.executesql(HiveDao.java:152)
	at com.inspur.pmv6.Entrance.lambda$null$0(Entrance.java:83)
	at java.util.stream.Streams$RangeIntSpliterator.forEachRemaining(Streams.java:110)
	at java.util.stream.IntPipeline$Head.forEach(IntPipeline.java:557)
	at com.inspur.pmv6.Entrance.lambda$myTestCodes$1(Entrance.java:76)
	at java.util.stream.Streams$RangeIntSpliterator.forEachRemaining(Streams.java:110)
	at java.util.stream.IntPipeline$Head.forEach(IntPipeline.java:557)
	at com.inspur.pmv6.Entrance.myTestCodes(Entrance.java:74)
	at com.inspur.pmv6.Entrance.main(Entrance.java:43)
[0328 17:18:06 106 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29utxrumz1kq9f8v|80ec1f8]-HelperThread-#1] hive.jdbc.Utils - Supplied authorities: 10.211.55.29:10000
[0328 17:18:06 107 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29utxrumz1kq9f8v|80ec1f8]-HelperThread-#1] hive.jdbc.Utils - Resolved authority: 10.211.55.29:10000
[0328 17:18:06 107 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29utxrumz1kq9f8v|80ec1f8]-HelperThread-#1] hive.jdbc.HiveConnection - Will try to open client transport with JDBC Uri: jdbc:hive2://10.211.55.29:10000/default
[0328 17:18:06 107 INFO ] [main] pmv6.dao.HiveDao - start to execute the sql :insert into test_table_double values (20180402, 090000, 13.658091466857304)
[0328 17:18:06 343 ERROR] [main] pmv6.dao.HiveDao - ERROR SQL: insert into test_table_double values (20180402, 090000, 13.658091466857304)
[0328 17:18:06 343 ERROR] [main] pmv6.dao.HiveDao - java.lang.RuntimeException: Cannot create staging directory 'hdfs://localhost:9000/home/chen/hive/warehouse/test_table_double/.hive-staging_hive_2018-03-28_02-18-06_269_6944416956218390495-69': Permission denied: user=hive, access=WRITE, inode="/home/chen/hive/warehouse/test_table_double":chen:supergroup:drwxr-xr-x
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.check(FSPermissionChecker.java:308)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:214)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:190)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkPermission(FSDirectory.java:1752)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkPermission(FSDirectory.java:1736)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkAncestorAccess(FSDirectory.java:1719)
	at org.apache.hadoop.hdfs.server.namenode.FSDirMkdirOp.mkdirs(FSDirMkdirOp.java:69)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.mkdirs(FSNamesystem.java:3867)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.mkdirs(NameNodeRpcServer.java:984)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.mkdirs(ClientNamenodeProtocolServerSideTranslatorPB.java:634)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:616)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:982)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2217)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2213)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1754)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2213)

java.sql.SQLException: java.lang.RuntimeException: Cannot create staging directory 'hdfs://localhost:9000/home/chen/hive/warehouse/test_table_double/.hive-staging_hive_2018-03-28_02-18-06_269_6944416956218390495-69': Permission denied: user=hive, access=WRITE, inode="/home/chen/hive/warehouse/test_table_double":chen:supergroup:drwxr-xr-x
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.check(FSPermissionChecker.java:308)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:214)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:190)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkPermission(FSDirectory.java:1752)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkPermission(FSDirectory.java:1736)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkAncestorAccess(FSDirectory.java:1719)
	at org.apache.hadoop.hdfs.server.namenode.FSDirMkdirOp.mkdirs(FSDirMkdirOp.java:69)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.mkdirs(FSNamesystem.java:3867)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.mkdirs(NameNodeRpcServer.java:984)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.mkdirs(ClientNamenodeProtocolServerSideTranslatorPB.java:634)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:616)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:982)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2217)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2213)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1754)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2213)

	at org.apache.hive.jdbc.HiveStatement.execute(HiveStatement.java:296)
	at org.apache.hive.jdbc.HivePreparedStatement.execute(HivePreparedStatement.java:98)
	at com.mchange.v2.c3p0.impl.NewProxyPreparedStatement.execute(NewProxyPreparedStatement.java:67)
	at com.inspur.pmv6.dao.HiveDao.executesql(HiveDao.java:152)
	at com.inspur.pmv6.Entrance.lambda$null$0(Entrance.java:83)
	at java.util.stream.Streams$RangeIntSpliterator.forEachRemaining(Streams.java:110)
	at java.util.stream.IntPipeline$Head.forEach(IntPipeline.java:557)
	at com.inspur.pmv6.Entrance.lambda$myTestCodes$1(Entrance.java:76)
	at java.util.stream.Streams$RangeIntSpliterator.forEachRemaining(Streams.java:110)
	at java.util.stream.IntPipeline$Head.forEach(IntPipeline.java:557)
	at com.inspur.pmv6.Entrance.myTestCodes(Entrance.java:74)
	at com.inspur.pmv6.Entrance.main(Entrance.java:43)
[0328 17:18:06 343 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29utxrumz1kq9f8v|80ec1f8]-HelperThread-#2] hive.jdbc.Utils - Supplied authorities: 10.211.55.29:10000
[0328 17:18:06 343 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29utxrumz1kq9f8v|80ec1f8]-HelperThread-#2] hive.jdbc.Utils - Resolved authority: 10.211.55.29:10000
[0328 17:18:06 344 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29utxrumz1kq9f8v|80ec1f8]-HelperThread-#2] hive.jdbc.HiveConnection - Will try to open client transport with JDBC Uri: jdbc:hive2://10.211.55.29:10000/default
[0328 17:18:06 344 INFO ] [main] pmv6.dao.HiveDao - start to execute the sql :insert into test_table_double values (20180403, 100000, 27.29755200334868)
[0328 17:18:06 464 ERROR] [main] pmv6.dao.HiveDao - ERROR SQL: insert into test_table_double values (20180403, 100000, 27.29755200334868)
[0328 17:18:06 464 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29utxrumz1kq9f8v|80ec1f8]-HelperThread-#0] hive.jdbc.Utils - Supplied authorities: 10.211.55.29:10000
[0328 17:18:06 464 ERROR] [main] pmv6.dao.HiveDao - java.lang.RuntimeException: Cannot create staging directory 'hdfs://localhost:9000/home/chen/hive/warehouse/test_table_double/.hive-staging_hive_2018-03-28_02-18-06_385_1516269350814149657-70': Permission denied: user=hive, access=WRITE, inode="/home/chen/hive/warehouse/test_table_double":chen:supergroup:drwxr-xr-x
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.check(FSPermissionChecker.java:308)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:214)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:190)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkPermission(FSDirectory.java:1752)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkPermission(FSDirectory.java:1736)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkAncestorAccess(FSDirectory.java:1719)
	at org.apache.hadoop.hdfs.server.namenode.FSDirMkdirOp.mkdirs(FSDirMkdirOp.java:69)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.mkdirs(FSNamesystem.java:3867)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.mkdirs(NameNodeRpcServer.java:984)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.mkdirs(ClientNamenodeProtocolServerSideTranslatorPB.java:634)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:616)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:982)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2217)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2213)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1754)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2213)

java.sql.SQLException: java.lang.RuntimeException: Cannot create staging directory 'hdfs://localhost:9000/home/chen/hive/warehouse/test_table_double/.hive-staging_hive_2018-03-28_02-18-06_385_1516269350814149657-70': Permission denied: user=hive, access=WRITE, inode="/home/chen/hive/warehouse/test_table_double":chen:supergroup:drwxr-xr-x
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.check(FSPermissionChecker.java:308)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:214)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:190)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkPermission(FSDirectory.java:1752)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkPermission(FSDirectory.java:1736)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkAncestorAccess(FSDirectory.java:1719)
	at org.apache.hadoop.hdfs.server.namenode.FSDirMkdirOp.mkdirs(FSDirMkdirOp.java:69)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.mkdirs(FSNamesystem.java:3867)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.mkdirs(NameNodeRpcServer.java:984)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.mkdirs(ClientNamenodeProtocolServerSideTranslatorPB.java:634)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:616)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:982)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2217)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2213)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1754)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2213)

	at org.apache.hive.jdbc.HiveStatement.execute(HiveStatement.java:296)
	at org.apache.hive.jdbc.HivePreparedStatement.execute(HivePreparedStatement.java:98)
	at com.mchange.v2.c3p0.impl.NewProxyPreparedStatement.execute(NewProxyPreparedStatement.java:67)
	at com.inspur.pmv6.dao.HiveDao.executesql(HiveDao.java:152)
	at com.inspur.pmv6.Entrance.lambda$null$0(Entrance.java:83)
	at java.util.stream.Streams$RangeIntSpliterator.forEachRemaining(Streams.java:110)
	at java.util.stream.IntPipeline$Head.forEach(IntPipeline.java:557)
	at com.inspur.pmv6.Entrance.lambda$myTestCodes$1(Entrance.java:76)
	at java.util.stream.Streams$RangeIntSpliterator.forEachRemaining(Streams.java:110)
	at java.util.stream.IntPipeline$Head.forEach(IntPipeline.java:557)
	at com.inspur.pmv6.Entrance.myTestCodes(Entrance.java:74)
	at com.inspur.pmv6.Entrance.main(Entrance.java:43)
[0328 17:18:06 464 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29utxrumz1kq9f8v|80ec1f8]-HelperThread-#0] hive.jdbc.Utils - Resolved authority: 10.211.55.29:10000
[0328 17:18:06 465 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29utxrumz1kq9f8v|80ec1f8]-HelperThread-#0] hive.jdbc.HiveConnection - Will try to open client transport with JDBC Uri: jdbc:hive2://10.211.55.29:10000/default
[0328 17:18:06 465 INFO ] [main] pmv6.dao.HiveDao - start to execute the sql :insert into test_table_double values (20180403, 110000, 80.28989121920824)
[0328 17:18:06 660 ERROR] [main] pmv6.dao.HiveDao - ERROR SQL: insert into test_table_double values (20180403, 110000, 80.28989121920824)
[0328 17:18:06 660 ERROR] [main] pmv6.dao.HiveDao - java.lang.RuntimeException: Cannot create staging directory 'hdfs://localhost:9000/home/chen/hive/warehouse/test_table_double/.hive-staging_hive_2018-03-28_02-18-06_586_6487607131840205645-71': Permission denied: user=hive, access=WRITE, inode="/home/chen/hive/warehouse/test_table_double":chen:supergroup:drwxr-xr-x
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.check(FSPermissionChecker.java:308)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:214)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:190)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkPermission(FSDirectory.java:1752)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkPermission(FSDirectory.java:1736)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkAncestorAccess(FSDirectory.java:1719)
	at org.apache.hadoop.hdfs.server.namenode.FSDirMkdirOp.mkdirs(FSDirMkdirOp.java:69)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.mkdirs(FSNamesystem.java:3867)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.mkdirs(NameNodeRpcServer.java:984)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.mkdirs(ClientNamenodeProtocolServerSideTranslatorPB.java:634)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:616)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:982)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2217)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2213)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1754)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2213)

java.sql.SQLException: java.lang.RuntimeException: Cannot create staging directory 'hdfs://localhost:9000/home/chen/hive/warehouse/test_table_double/.hive-staging_hive_2018-03-28_02-18-06_586_6487607131840205645-71': Permission denied: user=hive, access=WRITE, inode="/home/chen/hive/warehouse/test_table_double":chen:supergroup:drwxr-xr-x
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.check(FSPermissionChecker.java:308)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:214)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:190)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkPermission(FSDirectory.java:1752)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkPermission(FSDirectory.java:1736)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkAncestorAccess(FSDirectory.java:1719)
	at org.apache.hadoop.hdfs.server.namenode.FSDirMkdirOp.mkdirs(FSDirMkdirOp.java:69)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.mkdirs(FSNamesystem.java:3867)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.mkdirs(NameNodeRpcServer.java:984)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.mkdirs(ClientNamenodeProtocolServerSideTranslatorPB.java:634)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:616)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:982)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2217)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2213)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1754)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2213)

	at org.apache.hive.jdbc.HiveStatement.execute(HiveStatement.java:296)
	at org.apache.hive.jdbc.HivePreparedStatement.execute(HivePreparedStatement.java:98)
	at com.mchange.v2.c3p0.impl.NewProxyPreparedStatement.execute(NewProxyPreparedStatement.java:67)
	at com.inspur.pmv6.dao.HiveDao.executesql(HiveDao.java:152)
	at com.inspur.pmv6.Entrance.lambda$null$0(Entrance.java:83)
	at java.util.stream.Streams$RangeIntSpliterator.forEachRemaining(Streams.java:110)
	at java.util.stream.IntPipeline$Head.forEach(IntPipeline.java:557)
	at com.inspur.pmv6.Entrance.lambda$myTestCodes$1(Entrance.java:76)
	at java.util.stream.Streams$RangeIntSpliterator.forEachRemaining(Streams.java:110)
	at java.util.stream.IntPipeline$Head.forEach(IntPipeline.java:557)
	at com.inspur.pmv6.Entrance.myTestCodes(Entrance.java:74)
	at com.inspur.pmv6.Entrance.main(Entrance.java:43)
[0328 17:18:06 660 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29utxrumz1kq9f8v|80ec1f8]-HelperThread-#0] hive.jdbc.Utils - Supplied authorities: 10.211.55.29:10000
[0328 17:18:06 661 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29utxrumz1kq9f8v|80ec1f8]-HelperThread-#0] hive.jdbc.Utils - Resolved authority: 10.211.55.29:10000
[0328 17:18:06 661 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29utxrumz1kq9f8v|80ec1f8]-HelperThread-#0] hive.jdbc.HiveConnection - Will try to open client transport with JDBC Uri: jdbc:hive2://10.211.55.29:10000/default
[0328 17:18:06 661 INFO ] [main] pmv6.dao.HiveDao - start to execute the sql :insert into test_table_double values (20180404, 120000, 72.14678465817018)
[0328 17:18:06 771 ERROR] [main] pmv6.dao.HiveDao - ERROR SQL: insert into test_table_double values (20180404, 120000, 72.14678465817018)
[0328 17:18:06 771 ERROR] [main] pmv6.dao.HiveDao - java.lang.RuntimeException: Cannot create staging directory 'hdfs://localhost:9000/home/chen/hive/warehouse/test_table_double/.hive-staging_hive_2018-03-28_02-18-06_700_5235240757601597836-72': Permission denied: user=hive, access=WRITE, inode="/home/chen/hive/warehouse/test_table_double":chen:supergroup:drwxr-xr-x
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.check(FSPermissionChecker.java:308)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:214)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:190)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkPermission(FSDirectory.java:1752)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkPermission(FSDirectory.java:1736)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkAncestorAccess(FSDirectory.java:1719)
	at org.apache.hadoop.hdfs.server.namenode.FSDirMkdirOp.mkdirs(FSDirMkdirOp.java:69)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.mkdirs(FSNamesystem.java:3867)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.mkdirs(NameNodeRpcServer.java:984)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.mkdirs(ClientNamenodeProtocolServerSideTranslatorPB.java:634)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:616)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:982)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2217)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2213)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1754)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2213)

java.sql.SQLException: java.lang.RuntimeException: Cannot create staging directory 'hdfs://localhost:9000/home/chen/hive/warehouse/test_table_double/.hive-staging_hive_2018-03-28_02-18-06_700_5235240757601597836-72': Permission denied: user=hive, access=WRITE, inode="/home/chen/hive/warehouse/test_table_double":chen:supergroup:drwxr-xr-x
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.check(FSPermissionChecker.java:308)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:214)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:190)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkPermission(FSDirectory.java:1752)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkPermission(FSDirectory.java:1736)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkAncestorAccess(FSDirectory.java:1719)
	at org.apache.hadoop.hdfs.server.namenode.FSDirMkdirOp.mkdirs(FSDirMkdirOp.java:69)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.mkdirs(FSNamesystem.java:3867)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.mkdirs(NameNodeRpcServer.java:984)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.mkdirs(ClientNamenodeProtocolServerSideTranslatorPB.java:634)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:616)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:982)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2217)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2213)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1754)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2213)

	at org.apache.hive.jdbc.HiveStatement.execute(HiveStatement.java:296)
	at org.apache.hive.jdbc.HivePreparedStatement.execute(HivePreparedStatement.java:98)
	at com.mchange.v2.c3p0.impl.NewProxyPreparedStatement.execute(NewProxyPreparedStatement.java:67)
	at com.inspur.pmv6.dao.HiveDao.executesql(HiveDao.java:152)
	at com.inspur.pmv6.Entrance.lambda$null$0(Entrance.java:83)
	at java.util.stream.Streams$RangeIntSpliterator.forEachRemaining(Streams.java:110)
	at java.util.stream.IntPipeline$Head.forEach(IntPipeline.java:557)
	at com.inspur.pmv6.Entrance.lambda$myTestCodes$1(Entrance.java:76)
	at java.util.stream.Streams$RangeIntSpliterator.forEachRemaining(Streams.java:110)
	at java.util.stream.IntPipeline$Head.forEach(IntPipeline.java:557)
	at com.inspur.pmv6.Entrance.myTestCodes(Entrance.java:74)
	at com.inspur.pmv6.Entrance.main(Entrance.java:43)
[0328 17:18:06 771 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29utxrumz1kq9f8v|80ec1f8]-HelperThread-#1] hive.jdbc.Utils - Supplied authorities: 10.211.55.29:10000
[0328 17:18:06 772 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29utxrumz1kq9f8v|80ec1f8]-HelperThread-#1] hive.jdbc.Utils - Resolved authority: 10.211.55.29:10000
[0328 17:18:06 772 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29utxrumz1kq9f8v|80ec1f8]-HelperThread-#1] hive.jdbc.HiveConnection - Will try to open client transport with JDBC Uri: jdbc:hive2://10.211.55.29:10000/default
[0328 17:18:06 773 INFO ] [main] pmv6.dao.HiveDao - start to execute the sql :insert into test_table_double values (20180404, 010000, 50.65894703097287)
[0328 17:18:07 059 ERROR] [main] pmv6.dao.HiveDao - ERROR SQL: insert into test_table_double values (20180404, 010000, 50.65894703097287)
[0328 17:18:07 059 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29utxrumz1kq9f8v|80ec1f8]-HelperThread-#1] hive.jdbc.Utils - Supplied authorities: 10.211.55.29:10000
[0328 17:18:07 059 ERROR] [main] pmv6.dao.HiveDao - java.lang.RuntimeException: Cannot create staging directory 'hdfs://localhost:9000/home/chen/hive/warehouse/test_table_double/.hive-staging_hive_2018-03-28_02-18-06_983_7879010100385508589-73': Permission denied: user=hive, access=WRITE, inode="/home/chen/hive/warehouse/test_table_double":chen:supergroup:drwxr-xr-x
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.check(FSPermissionChecker.java:308)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:214)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:190)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkPermission(FSDirectory.java:1752)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkPermission(FSDirectory.java:1736)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkAncestorAccess(FSDirectory.java:1719)
	at org.apache.hadoop.hdfs.server.namenode.FSDirMkdirOp.mkdirs(FSDirMkdirOp.java:69)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.mkdirs(FSNamesystem.java:3867)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.mkdirs(NameNodeRpcServer.java:984)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.mkdirs(ClientNamenodeProtocolServerSideTranslatorPB.java:634)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:616)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:982)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2217)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2213)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1754)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2213)

java.sql.SQLException: java.lang.RuntimeException: Cannot create staging directory 'hdfs://localhost:9000/home/chen/hive/warehouse/test_table_double/.hive-staging_hive_2018-03-28_02-18-06_983_7879010100385508589-73': Permission denied: user=hive, access=WRITE, inode="/home/chen/hive/warehouse/test_table_double":chen:supergroup:drwxr-xr-x
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.check(FSPermissionChecker.java:308)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:214)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:190)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkPermission(FSDirectory.java:1752)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkPermission(FSDirectory.java:1736)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkAncestorAccess(FSDirectory.java:1719)
	at org.apache.hadoop.hdfs.server.namenode.FSDirMkdirOp.mkdirs(FSDirMkdirOp.java:69)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.mkdirs(FSNamesystem.java:3867)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.mkdirs(NameNodeRpcServer.java:984)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.mkdirs(ClientNamenodeProtocolServerSideTranslatorPB.java:634)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:616)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:982)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2217)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2213)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1754)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2213)

	at org.apache.hive.jdbc.HiveStatement.execute(HiveStatement.java:296)
	at org.apache.hive.jdbc.HivePreparedStatement.execute(HivePreparedStatement.java:98)
	at com.mchange.v2.c3p0.impl.NewProxyPreparedStatement.execute(NewProxyPreparedStatement.java:67)
	at com.inspur.pmv6.dao.HiveDao.executesql(HiveDao.java:152)
	at com.inspur.pmv6.Entrance.lambda$null$0(Entrance.java:83)
	at java.util.stream.Streams$RangeIntSpliterator.forEachRemaining(Streams.java:110)
	at java.util.stream.IntPipeline$Head.forEach(IntPipeline.java:557)
	at com.inspur.pmv6.Entrance.lambda$myTestCodes$1(Entrance.java:76)
	at java.util.stream.Streams$RangeIntSpliterator.forEachRemaining(Streams.java:110)
	at java.util.stream.IntPipeline$Head.forEach(IntPipeline.java:557)
	at com.inspur.pmv6.Entrance.myTestCodes(Entrance.java:74)
	at com.inspur.pmv6.Entrance.main(Entrance.java:43)
[0328 17:18:07 059 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29utxrumz1kq9f8v|80ec1f8]-HelperThread-#1] hive.jdbc.Utils - Resolved authority: 10.211.55.29:10000
[0328 17:18:07 060 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29utxrumz1kq9f8v|80ec1f8]-HelperThread-#1] hive.jdbc.HiveConnection - Will try to open client transport with JDBC Uri: jdbc:hive2://10.211.55.29:10000/default
[0328 17:18:07 060 INFO ] [main] pmv6.dao.HiveDao - start to execute the sql :insert into test_table_double values (20180404, 020000, 15.668809800357518)
[0328 17:18:07 216 ERROR] [main] pmv6.dao.HiveDao - ERROR SQL: insert into test_table_double values (20180404, 020000, 15.668809800357518)
[0328 17:18:07 216 ERROR] [main] pmv6.dao.HiveDao - java.lang.RuntimeException: Cannot create staging directory 'hdfs://localhost:9000/home/chen/hive/warehouse/test_table_double/.hive-staging_hive_2018-03-28_02-18-07_146_4272282547492175978-74': Permission denied: user=hive, access=WRITE, inode="/home/chen/hive/warehouse/test_table_double":chen:supergroup:drwxr-xr-x
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.check(FSPermissionChecker.java:308)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:214)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:190)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkPermission(FSDirectory.java:1752)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkPermission(FSDirectory.java:1736)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkAncestorAccess(FSDirectory.java:1719)
	at org.apache.hadoop.hdfs.server.namenode.FSDirMkdirOp.mkdirs(FSDirMkdirOp.java:69)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.mkdirs(FSNamesystem.java:3867)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.mkdirs(NameNodeRpcServer.java:984)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.mkdirs(ClientNamenodeProtocolServerSideTranslatorPB.java:634)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:616)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:982)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2217)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2213)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1754)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2213)

java.sql.SQLException: java.lang.RuntimeException: Cannot create staging directory 'hdfs://localhost:9000/home/chen/hive/warehouse/test_table_double/.hive-staging_hive_2018-03-28_02-18-07_146_4272282547492175978-74': Permission denied: user=hive, access=WRITE, inode="/home/chen/hive/warehouse/test_table_double":chen:supergroup:drwxr-xr-x
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.check(FSPermissionChecker.java:308)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:214)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:190)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkPermission(FSDirectory.java:1752)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkPermission(FSDirectory.java:1736)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkAncestorAccess(FSDirectory.java:1719)
	at org.apache.hadoop.hdfs.server.namenode.FSDirMkdirOp.mkdirs(FSDirMkdirOp.java:69)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.mkdirs(FSNamesystem.java:3867)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.mkdirs(NameNodeRpcServer.java:984)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.mkdirs(ClientNamenodeProtocolServerSideTranslatorPB.java:634)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:616)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:982)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2217)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2213)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1754)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2213)

	at org.apache.hive.jdbc.HiveStatement.execute(HiveStatement.java:296)
	at org.apache.hive.jdbc.HivePreparedStatement.execute(HivePreparedStatement.java:98)
	at com.mchange.v2.c3p0.impl.NewProxyPreparedStatement.execute(NewProxyPreparedStatement.java:67)
	at com.inspur.pmv6.dao.HiveDao.executesql(HiveDao.java:152)
	at com.inspur.pmv6.Entrance.lambda$null$0(Entrance.java:83)
	at java.util.stream.Streams$RangeIntSpliterator.forEachRemaining(Streams.java:110)
	at java.util.stream.IntPipeline$Head.forEach(IntPipeline.java:557)
	at com.inspur.pmv6.Entrance.lambda$myTestCodes$1(Entrance.java:76)
	at java.util.stream.Streams$RangeIntSpliterator.forEachRemaining(Streams.java:110)
	at java.util.stream.IntPipeline$Head.forEach(IntPipeline.java:557)
	at com.inspur.pmv6.Entrance.myTestCodes(Entrance.java:74)
	at com.inspur.pmv6.Entrance.main(Entrance.java:43)
[0328 17:18:07 216 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29utxrumz1kq9f8v|80ec1f8]-HelperThread-#0] hive.jdbc.Utils - Supplied authorities: 10.211.55.29:10000
[0328 17:18:07 217 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29utxrumz1kq9f8v|80ec1f8]-HelperThread-#0] hive.jdbc.Utils - Resolved authority: 10.211.55.29:10000
[0328 17:18:07 217 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29utxrumz1kq9f8v|80ec1f8]-HelperThread-#0] hive.jdbc.HiveConnection - Will try to open client transport with JDBC Uri: jdbc:hive2://10.211.55.29:10000/default
[0328 17:18:07 217 INFO ] [main] pmv6.dao.HiveDao - start to execute the sql :insert into test_table_double values (20180404, 030000, 18.32867351438312)
[0328 17:18:07 400 ERROR] [main] pmv6.dao.HiveDao - ERROR SQL: insert into test_table_double values (20180404, 030000, 18.32867351438312)
[0328 17:18:07 400 ERROR] [main] pmv6.dao.HiveDao - java.lang.RuntimeException: Cannot create staging directory 'hdfs://localhost:9000/home/chen/hive/warehouse/test_table_double/.hive-staging_hive_2018-03-28_02-18-07_327_5237394874055463182-75': Permission denied: user=hive, access=WRITE, inode="/home/chen/hive/warehouse/test_table_double":chen:supergroup:drwxr-xr-x
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.check(FSPermissionChecker.java:308)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:214)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:190)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkPermission(FSDirectory.java:1752)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkPermission(FSDirectory.java:1736)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkAncestorAccess(FSDirectory.java:1719)
	at org.apache.hadoop.hdfs.server.namenode.FSDirMkdirOp.mkdirs(FSDirMkdirOp.java:69)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.mkdirs(FSNamesystem.java:3867)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.mkdirs(NameNodeRpcServer.java:984)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.mkdirs(ClientNamenodeProtocolServerSideTranslatorPB.java:634)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:616)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:982)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2217)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2213)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1754)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2213)

java.sql.SQLException: java.lang.RuntimeException: Cannot create staging directory 'hdfs://localhost:9000/home/chen/hive/warehouse/test_table_double/.hive-staging_hive_2018-03-28_02-18-07_327_5237394874055463182-75': Permission denied: user=hive, access=WRITE, inode="/home/chen/hive/warehouse/test_table_double":chen:supergroup:drwxr-xr-x
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.check(FSPermissionChecker.java:308)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:214)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:190)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkPermission(FSDirectory.java:1752)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkPermission(FSDirectory.java:1736)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkAncestorAccess(FSDirectory.java:1719)
	at org.apache.hadoop.hdfs.server.namenode.FSDirMkdirOp.mkdirs(FSDirMkdirOp.java:69)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.mkdirs(FSNamesystem.java:3867)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.mkdirs(NameNodeRpcServer.java:984)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.mkdirs(ClientNamenodeProtocolServerSideTranslatorPB.java:634)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:616)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:982)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2217)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2213)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1754)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2213)

	at org.apache.hive.jdbc.HiveStatement.execute(HiveStatement.java:296)
	at org.apache.hive.jdbc.HivePreparedStatement.execute(HivePreparedStatement.java:98)
	at com.mchange.v2.c3p0.impl.NewProxyPreparedStatement.execute(NewProxyPreparedStatement.java:67)
	at com.inspur.pmv6.dao.HiveDao.executesql(HiveDao.java:152)
	at com.inspur.pmv6.Entrance.lambda$null$0(Entrance.java:83)
	at java.util.stream.Streams$RangeIntSpliterator.forEachRemaining(Streams.java:110)
	at java.util.stream.IntPipeline$Head.forEach(IntPipeline.java:557)
	at com.inspur.pmv6.Entrance.lambda$myTestCodes$1(Entrance.java:76)
	at java.util.stream.Streams$RangeIntSpliterator.forEachRemaining(Streams.java:110)
	at java.util.stream.IntPipeline$Head.forEach(IntPipeline.java:557)
	at com.inspur.pmv6.Entrance.myTestCodes(Entrance.java:74)
	at com.inspur.pmv6.Entrance.main(Entrance.java:43)
[0328 17:18:07 400 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29utxrumz1kq9f8v|80ec1f8]-HelperThread-#1] hive.jdbc.Utils - Supplied authorities: 10.211.55.29:10000
[0328 17:18:07 400 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29utxrumz1kq9f8v|80ec1f8]-HelperThread-#1] hive.jdbc.Utils - Resolved authority: 10.211.55.29:10000
[0328 17:18:07 401 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29utxrumz1kq9f8v|80ec1f8]-HelperThread-#1] hive.jdbc.HiveConnection - Will try to open client transport with JDBC Uri: jdbc:hive2://10.211.55.29:10000/default
[0328 17:18:07 401 INFO ] [main] pmv6.dao.HiveDao - start to execute the sql :insert into test_table_double values (20180404, 040000, 74.96688993853843)
[0328 17:18:07 578 ERROR] [main] pmv6.dao.HiveDao - ERROR SQL: insert into test_table_double values (20180404, 040000, 74.96688993853843)
[0328 17:18:07 578 ERROR] [main] pmv6.dao.HiveDao - java.lang.RuntimeException: Cannot create staging directory 'hdfs://localhost:9000/home/chen/hive/warehouse/test_table_double/.hive-staging_hive_2018-03-28_02-18-07_497_8371812391153510645-76': Permission denied: user=hive, access=WRITE, inode="/home/chen/hive/warehouse/test_table_double":chen:supergroup:drwxr-xr-x
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.check(FSPermissionChecker.java:308)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:214)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:190)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkPermission(FSDirectory.java:1752)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkPermission(FSDirectory.java:1736)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkAncestorAccess(FSDirectory.java:1719)
	at org.apache.hadoop.hdfs.server.namenode.FSDirMkdirOp.mkdirs(FSDirMkdirOp.java:69)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.mkdirs(FSNamesystem.java:3867)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.mkdirs(NameNodeRpcServer.java:984)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.mkdirs(ClientNamenodeProtocolServerSideTranslatorPB.java:634)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:616)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:982)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2217)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2213)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1754)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2213)

java.sql.SQLException: java.lang.RuntimeException: Cannot create staging directory 'hdfs://localhost:9000/home/chen/hive/warehouse/test_table_double/.hive-staging_hive_2018-03-28_02-18-07_497_8371812391153510645-76': Permission denied: user=hive, access=WRITE, inode="/home/chen/hive/warehouse/test_table_double":chen:supergroup:drwxr-xr-x
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.check(FSPermissionChecker.java:308)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:214)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:190)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkPermission(FSDirectory.java:1752)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkPermission(FSDirectory.java:1736)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkAncestorAccess(FSDirectory.java:1719)
	at org.apache.hadoop.hdfs.server.namenode.FSDirMkdirOp.mkdirs(FSDirMkdirOp.java:69)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.mkdirs(FSNamesystem.java:3867)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.mkdirs(NameNodeRpcServer.java:984)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.mkdirs(ClientNamenodeProtocolServerSideTranslatorPB.java:634)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:616)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:982)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2217)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2213)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1754)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2213)

	at org.apache.hive.jdbc.HiveStatement.execute(HiveStatement.java:296)
	at org.apache.hive.jdbc.HivePreparedStatement.execute(HivePreparedStatement.java:98)
	at com.mchange.v2.c3p0.impl.NewProxyPreparedStatement.execute(NewProxyPreparedStatement.java:67)
	at com.inspur.pmv6.dao.HiveDao.executesql(HiveDao.java:152)
	at com.inspur.pmv6.Entrance.lambda$null$0(Entrance.java:83)
	at java.util.stream.Streams$RangeIntSpliterator.forEachRemaining(Streams.java:110)
	at java.util.stream.IntPipeline$Head.forEach(IntPipeline.java:557)
	at com.inspur.pmv6.Entrance.lambda$myTestCodes$1(Entrance.java:76)
	at java.util.stream.Streams$RangeIntSpliterator.forEachRemaining(Streams.java:110)
	at java.util.stream.IntPipeline$Head.forEach(IntPipeline.java:557)
	at com.inspur.pmv6.Entrance.myTestCodes(Entrance.java:74)
	at com.inspur.pmv6.Entrance.main(Entrance.java:43)
[0328 17:18:07 578 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29utxrumz1kq9f8v|80ec1f8]-HelperThread-#0] hive.jdbc.Utils - Supplied authorities: 10.211.55.29:10000
[0328 17:18:07 579 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29utxrumz1kq9f8v|80ec1f8]-HelperThread-#0] hive.jdbc.Utils - Resolved authority: 10.211.55.29:10000
[0328 17:18:07 579 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29utxrumz1kq9f8v|80ec1f8]-HelperThread-#0] hive.jdbc.HiveConnection - Will try to open client transport with JDBC Uri: jdbc:hive2://10.211.55.29:10000/default
[0328 17:18:07 579 INFO ] [main] pmv6.dao.HiveDao - start to execute the sql :insert into test_table_double values (20180404, 050000, 0.6226929484860588)
[0328 17:18:07 793 ERROR] [main] pmv6.dao.HiveDao - ERROR SQL: insert into test_table_double values (20180404, 050000, 0.6226929484860588)
[0328 17:18:07 793 ERROR] [main] pmv6.dao.HiveDao - java.lang.RuntimeException: Cannot create staging directory 'hdfs://localhost:9000/home/chen/hive/warehouse/test_table_double/.hive-staging_hive_2018-03-28_02-18-07_709_1670232418557428663-77': Permission denied: user=hive, access=WRITE, inode="/home/chen/hive/warehouse/test_table_double":chen:supergroup:drwxr-xr-x
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.check(FSPermissionChecker.java:308)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:214)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:190)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkPermission(FSDirectory.java:1752)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkPermission(FSDirectory.java:1736)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkAncestorAccess(FSDirectory.java:1719)
	at org.apache.hadoop.hdfs.server.namenode.FSDirMkdirOp.mkdirs(FSDirMkdirOp.java:69)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.mkdirs(FSNamesystem.java:3867)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.mkdirs(NameNodeRpcServer.java:984)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.mkdirs(ClientNamenodeProtocolServerSideTranslatorPB.java:634)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:616)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:982)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2217)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2213)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1754)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2213)

java.sql.SQLException: java.lang.RuntimeException: Cannot create staging directory 'hdfs://localhost:9000/home/chen/hive/warehouse/test_table_double/.hive-staging_hive_2018-03-28_02-18-07_709_1670232418557428663-77': Permission denied: user=hive, access=WRITE, inode="/home/chen/hive/warehouse/test_table_double":chen:supergroup:drwxr-xr-x
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.check(FSPermissionChecker.java:308)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:214)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:190)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkPermission(FSDirectory.java:1752)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkPermission(FSDirectory.java:1736)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkAncestorAccess(FSDirectory.java:1719)
	at org.apache.hadoop.hdfs.server.namenode.FSDirMkdirOp.mkdirs(FSDirMkdirOp.java:69)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.mkdirs(FSNamesystem.java:3867)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.mkdirs(NameNodeRpcServer.java:984)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.mkdirs(ClientNamenodeProtocolServerSideTranslatorPB.java:634)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:616)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:982)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2217)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2213)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1754)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2213)

	at org.apache.hive.jdbc.HiveStatement.execute(HiveStatement.java:296)
	at org.apache.hive.jdbc.HivePreparedStatement.execute(HivePreparedStatement.java:98)
	at com.mchange.v2.c3p0.impl.NewProxyPreparedStatement.execute(NewProxyPreparedStatement.java:67)
	at com.inspur.pmv6.dao.HiveDao.executesql(HiveDao.java:152)
	at com.inspur.pmv6.Entrance.lambda$null$0(Entrance.java:83)
	at java.util.stream.Streams$RangeIntSpliterator.forEachRemaining(Streams.java:110)
	at java.util.stream.IntPipeline$Head.forEach(IntPipeline.java:557)
	at com.inspur.pmv6.Entrance.lambda$myTestCodes$1(Entrance.java:76)
	at java.util.stream.Streams$RangeIntSpliterator.forEachRemaining(Streams.java:110)
	at java.util.stream.IntPipeline$Head.forEach(IntPipeline.java:557)
	at com.inspur.pmv6.Entrance.myTestCodes(Entrance.java:74)
	at com.inspur.pmv6.Entrance.main(Entrance.java:43)
[0328 17:18:07 793 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29utxrumz1kq9f8v|80ec1f8]-HelperThread-#1] hive.jdbc.Utils - Supplied authorities: 10.211.55.29:10000
[0328 17:18:07 794 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29utxrumz1kq9f8v|80ec1f8]-HelperThread-#1] hive.jdbc.Utils - Resolved authority: 10.211.55.29:10000
[0328 17:18:07 794 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29utxrumz1kq9f8v|80ec1f8]-HelperThread-#1] hive.jdbc.HiveConnection - Will try to open client transport with JDBC Uri: jdbc:hive2://10.211.55.29:10000/default
[0328 17:18:07 795 INFO ] [main] pmv6.dao.HiveDao - start to execute the sql :insert into test_table_double values (20180404, 060000, 1.3974367703936008)
[0328 17:18:07 986 ERROR] [main] pmv6.dao.HiveDao - ERROR SQL: insert into test_table_double values (20180404, 060000, 1.3974367703936008)
[0328 17:18:07 986 ERROR] [main] pmv6.dao.HiveDao - java.lang.RuntimeException: Cannot create staging directory 'hdfs://localhost:9000/home/chen/hive/warehouse/test_table_double/.hive-staging_hive_2018-03-28_02-18-07_916_8135943171597363393-78': Permission denied: user=hive, access=WRITE, inode="/home/chen/hive/warehouse/test_table_double":chen:supergroup:drwxr-xr-x
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.check(FSPermissionChecker.java:308)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:214)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:190)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkPermission(FSDirectory.java:1752)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkPermission(FSDirectory.java:1736)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkAncestorAccess(FSDirectory.java:1719)
	at org.apache.hadoop.hdfs.server.namenode.FSDirMkdirOp.mkdirs(FSDirMkdirOp.java:69)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.mkdirs(FSNamesystem.java:3867)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.mkdirs(NameNodeRpcServer.java:984)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.mkdirs(ClientNamenodeProtocolServerSideTranslatorPB.java:634)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:616)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:982)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2217)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2213)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1754)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2213)

java.sql.SQLException: java.lang.RuntimeException: Cannot create staging directory 'hdfs://localhost:9000/home/chen/hive/warehouse/test_table_double/.hive-staging_hive_2018-03-28_02-18-07_916_8135943171597363393-78': Permission denied: user=hive, access=WRITE, inode="/home/chen/hive/warehouse/test_table_double":chen:supergroup:drwxr-xr-x
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.check(FSPermissionChecker.java:308)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:214)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:190)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkPermission(FSDirectory.java:1752)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkPermission(FSDirectory.java:1736)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkAncestorAccess(FSDirectory.java:1719)
	at org.apache.hadoop.hdfs.server.namenode.FSDirMkdirOp.mkdirs(FSDirMkdirOp.java:69)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.mkdirs(FSNamesystem.java:3867)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.mkdirs(NameNodeRpcServer.java:984)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.mkdirs(ClientNamenodeProtocolServerSideTranslatorPB.java:634)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:616)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:982)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2217)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2213)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1754)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2213)

	at org.apache.hive.jdbc.HiveStatement.execute(HiveStatement.java:296)
	at org.apache.hive.jdbc.HivePreparedStatement.execute(HivePreparedStatement.java:98)
	at com.mchange.v2.c3p0.impl.NewProxyPreparedStatement.execute(NewProxyPreparedStatement.java:67)
	at com.inspur.pmv6.dao.HiveDao.executesql(HiveDao.java:152)
	at com.inspur.pmv6.Entrance.lambda$null$0(Entrance.java:83)
	at java.util.stream.Streams$RangeIntSpliterator.forEachRemaining(Streams.java:110)
	at java.util.stream.IntPipeline$Head.forEach(IntPipeline.java:557)
	at com.inspur.pmv6.Entrance.lambda$myTestCodes$1(Entrance.java:76)
	at java.util.stream.Streams$RangeIntSpliterator.forEachRemaining(Streams.java:110)
	at java.util.stream.IntPipeline$Head.forEach(IntPipeline.java:557)
	at com.inspur.pmv6.Entrance.myTestCodes(Entrance.java:74)
	at com.inspur.pmv6.Entrance.main(Entrance.java:43)
[0328 17:18:07 986 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29utxrumz1kq9f8v|80ec1f8]-HelperThread-#0] hive.jdbc.Utils - Supplied authorities: 10.211.55.29:10000
[0328 17:18:07 986 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29utxrumz1kq9f8v|80ec1f8]-HelperThread-#0] hive.jdbc.Utils - Resolved authority: 10.211.55.29:10000
[0328 17:18:07 987 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29utxrumz1kq9f8v|80ec1f8]-HelperThread-#0] hive.jdbc.HiveConnection - Will try to open client transport with JDBC Uri: jdbc:hive2://10.211.55.29:10000/default
[0328 17:18:07 987 INFO ] [main] pmv6.dao.HiveDao - start to execute the sql :insert into test_table_double values (20180404, 070000, 91.64550904974165)
[0328 17:18:08 207 ERROR] [main] pmv6.dao.HiveDao - ERROR SQL: insert into test_table_double values (20180404, 070000, 91.64550904974165)
[0328 17:18:08 207 ERROR] [main] pmv6.dao.HiveDao - java.lang.RuntimeException: Cannot create staging directory 'hdfs://localhost:9000/home/chen/hive/warehouse/test_table_double/.hive-staging_hive_2018-03-28_02-18-08_110_7205645983183843599-79': Permission denied: user=hive, access=WRITE, inode="/home/chen/hive/warehouse/test_table_double":chen:supergroup:drwxr-xr-x
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.check(FSPermissionChecker.java:308)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:214)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:190)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkPermission(FSDirectory.java:1752)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkPermission(FSDirectory.java:1736)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkAncestorAccess(FSDirectory.java:1719)
	at org.apache.hadoop.hdfs.server.namenode.FSDirMkdirOp.mkdirs(FSDirMkdirOp.java:69)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.mkdirs(FSNamesystem.java:3867)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.mkdirs(NameNodeRpcServer.java:984)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.mkdirs(ClientNamenodeProtocolServerSideTranslatorPB.java:634)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:616)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:982)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2217)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2213)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1754)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2213)

java.sql.SQLException: java.lang.RuntimeException: Cannot create staging directory 'hdfs://localhost:9000/home/chen/hive/warehouse/test_table_double/.hive-staging_hive_2018-03-28_02-18-08_110_7205645983183843599-79': Permission denied: user=hive, access=WRITE, inode="/home/chen/hive/warehouse/test_table_double":chen:supergroup:drwxr-xr-x
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.check(FSPermissionChecker.java:308)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:214)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:190)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkPermission(FSDirectory.java:1752)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkPermission(FSDirectory.java:1736)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkAncestorAccess(FSDirectory.java:1719)
	at org.apache.hadoop.hdfs.server.namenode.FSDirMkdirOp.mkdirs(FSDirMkdirOp.java:69)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.mkdirs(FSNamesystem.java:3867)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.mkdirs(NameNodeRpcServer.java:984)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.mkdirs(ClientNamenodeProtocolServerSideTranslatorPB.java:634)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:616)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:982)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2217)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2213)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1754)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2213)

	at org.apache.hive.jdbc.HiveStatement.execute(HiveStatement.java:296)
	at org.apache.hive.jdbc.HivePreparedStatement.execute(HivePreparedStatement.java:98)
	at com.mchange.v2.c3p0.impl.NewProxyPreparedStatement.execute(NewProxyPreparedStatement.java:67)
	at com.inspur.pmv6.dao.HiveDao.executesql(HiveDao.java:152)
	at com.inspur.pmv6.Entrance.lambda$null$0(Entrance.java:83)
	at java.util.stream.Streams$RangeIntSpliterator.forEachRemaining(Streams.java:110)
	at java.util.stream.IntPipeline$Head.forEach(IntPipeline.java:557)
	at com.inspur.pmv6.Entrance.lambda$myTestCodes$1(Entrance.java:76)
	at java.util.stream.Streams$RangeIntSpliterator.forEachRemaining(Streams.java:110)
	at java.util.stream.IntPipeline$Head.forEach(IntPipeline.java:557)
	at com.inspur.pmv6.Entrance.myTestCodes(Entrance.java:74)
	at com.inspur.pmv6.Entrance.main(Entrance.java:43)
[0328 17:18:08 207 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29utxrumz1kq9f8v|80ec1f8]-HelperThread-#1] hive.jdbc.Utils - Supplied authorities: 10.211.55.29:10000
[0328 17:18:08 208 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29utxrumz1kq9f8v|80ec1f8]-HelperThread-#1] hive.jdbc.Utils - Resolved authority: 10.211.55.29:10000
[0328 17:18:08 209 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29utxrumz1kq9f8v|80ec1f8]-HelperThread-#1] hive.jdbc.HiveConnection - Will try to open client transport with JDBC Uri: jdbc:hive2://10.211.55.29:10000/default
[0328 17:18:08 209 INFO ] [main] pmv6.dao.HiveDao - start to execute the sql :insert into test_table_double values (20180404, 080000, 84.41311931259028)
[0328 17:18:08 455 ERROR] [main] pmv6.dao.HiveDao - ERROR SQL: insert into test_table_double values (20180404, 080000, 84.41311931259028)
[0328 17:18:08 455 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29utxrumz1kq9f8v|80ec1f8]-HelperThread-#0] hive.jdbc.Utils - Supplied authorities: 10.211.55.29:10000
[0328 17:18:08 455 ERROR] [main] pmv6.dao.HiveDao - java.lang.RuntimeException: Cannot create staging directory 'hdfs://localhost:9000/home/chen/hive/warehouse/test_table_double/.hive-staging_hive_2018-03-28_02-18-08_359_7949170671883504229-80': Permission denied: user=hive, access=WRITE, inode="/home/chen/hive/warehouse/test_table_double":chen:supergroup:drwxr-xr-x
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.check(FSPermissionChecker.java:308)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:214)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:190)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkPermission(FSDirectory.java:1752)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkPermission(FSDirectory.java:1736)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkAncestorAccess(FSDirectory.java:1719)
	at org.apache.hadoop.hdfs.server.namenode.FSDirMkdirOp.mkdirs(FSDirMkdirOp.java:69)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.mkdirs(FSNamesystem.java:3867)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.mkdirs(NameNodeRpcServer.java:984)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.mkdirs(ClientNamenodeProtocolServerSideTranslatorPB.java:634)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:616)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:982)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2217)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2213)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1754)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2213)

java.sql.SQLException: java.lang.RuntimeException: Cannot create staging directory 'hdfs://localhost:9000/home/chen/hive/warehouse/test_table_double/.hive-staging_hive_2018-03-28_02-18-08_359_7949170671883504229-80': Permission denied: user=hive, access=WRITE, inode="/home/chen/hive/warehouse/test_table_double":chen:supergroup:drwxr-xr-x
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.check(FSPermissionChecker.java:308)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:214)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:190)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkPermission(FSDirectory.java:1752)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkPermission(FSDirectory.java:1736)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkAncestorAccess(FSDirectory.java:1719)
	at org.apache.hadoop.hdfs.server.namenode.FSDirMkdirOp.mkdirs(FSDirMkdirOp.java:69)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.mkdirs(FSNamesystem.java:3867)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.mkdirs(NameNodeRpcServer.java:984)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.mkdirs(ClientNamenodeProtocolServerSideTranslatorPB.java:634)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:616)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:982)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2217)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2213)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1754)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2213)

	at org.apache.hive.jdbc.HiveStatement.execute(HiveStatement.java:296)
	at org.apache.hive.jdbc.HivePreparedStatement.execute(HivePreparedStatement.java:98)
	at com.mchange.v2.c3p0.impl.NewProxyPreparedStatement.execute(NewProxyPreparedStatement.java:67)
	at com.inspur.pmv6.dao.HiveDao.executesql(HiveDao.java:152)
	at com.inspur.pmv6.Entrance.lambda$null$0(Entrance.java:83)
	at java.util.stream.Streams$RangeIntSpliterator.forEachRemaining(Streams.java:110)
	at java.util.stream.IntPipeline$Head.forEach(IntPipeline.java:557)
	at com.inspur.pmv6.Entrance.lambda$myTestCodes$1(Entrance.java:76)
	at java.util.stream.Streams$RangeIntSpliterator.forEachRemaining(Streams.java:110)
	at java.util.stream.IntPipeline$Head.forEach(IntPipeline.java:557)
	at com.inspur.pmv6.Entrance.myTestCodes(Entrance.java:74)
	at com.inspur.pmv6.Entrance.main(Entrance.java:43)
[0328 17:18:08 456 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29utxrumz1kq9f8v|80ec1f8]-HelperThread-#0] hive.jdbc.Utils - Resolved authority: 10.211.55.29:10000
[0328 17:18:08 456 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29utxrumz1kq9f8v|80ec1f8]-HelperThread-#0] hive.jdbc.HiveConnection - Will try to open client transport with JDBC Uri: jdbc:hive2://10.211.55.29:10000/default
[0328 17:18:08 456 INFO ] [main] pmv6.dao.HiveDao - start to execute the sql :insert into test_table_double values (20180404, 090000, 93.81950156303118)
[0328 17:18:08 609 ERROR] [main] pmv6.dao.HiveDao - ERROR SQL: insert into test_table_double values (20180404, 090000, 93.81950156303118)
[0328 17:18:08 609 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29utxrumz1kq9f8v|80ec1f8]-HelperThread-#1] hive.jdbc.Utils - Supplied authorities: 10.211.55.29:10000
[0328 17:18:08 609 ERROR] [main] pmv6.dao.HiveDao - java.lang.RuntimeException: Cannot create staging directory 'hdfs://localhost:9000/home/chen/hive/warehouse/test_table_double/.hive-staging_hive_2018-03-28_02-18-08_540_7241362551765130674-81': Permission denied: user=hive, access=WRITE, inode="/home/chen/hive/warehouse/test_table_double":chen:supergroup:drwxr-xr-x
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.check(FSPermissionChecker.java:308)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:214)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:190)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkPermission(FSDirectory.java:1752)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkPermission(FSDirectory.java:1736)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkAncestorAccess(FSDirectory.java:1719)
	at org.apache.hadoop.hdfs.server.namenode.FSDirMkdirOp.mkdirs(FSDirMkdirOp.java:69)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.mkdirs(FSNamesystem.java:3867)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.mkdirs(NameNodeRpcServer.java:984)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.mkdirs(ClientNamenodeProtocolServerSideTranslatorPB.java:634)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:616)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:982)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2217)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2213)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1754)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2213)

java.sql.SQLException: java.lang.RuntimeException: Cannot create staging directory 'hdfs://localhost:9000/home/chen/hive/warehouse/test_table_double/.hive-staging_hive_2018-03-28_02-18-08_540_7241362551765130674-81': Permission denied: user=hive, access=WRITE, inode="/home/chen/hive/warehouse/test_table_double":chen:supergroup:drwxr-xr-x
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.check(FSPermissionChecker.java:308)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:214)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:190)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkPermission(FSDirectory.java:1752)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkPermission(FSDirectory.java:1736)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkAncestorAccess(FSDirectory.java:1719)
	at org.apache.hadoop.hdfs.server.namenode.FSDirMkdirOp.mkdirs(FSDirMkdirOp.java:69)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.mkdirs(FSNamesystem.java:3867)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.mkdirs(NameNodeRpcServer.java:984)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.mkdirs(ClientNamenodeProtocolServerSideTranslatorPB.java:634)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:616)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:982)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2217)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2213)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1754)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2213)

	at org.apache.hive.jdbc.HiveStatement.execute(HiveStatement.java:296)
	at org.apache.hive.jdbc.HivePreparedStatement.execute(HivePreparedStatement.java:98)
	at com.mchange.v2.c3p0.impl.NewProxyPreparedStatement.execute(NewProxyPreparedStatement.java:67)
	at com.inspur.pmv6.dao.HiveDao.executesql(HiveDao.java:152)
	at com.inspur.pmv6.Entrance.lambda$null$0(Entrance.java:83)
	at java.util.stream.Streams$RangeIntSpliterator.forEachRemaining(Streams.java:110)
	at java.util.stream.IntPipeline$Head.forEach(IntPipeline.java:557)
	at com.inspur.pmv6.Entrance.lambda$myTestCodes$1(Entrance.java:76)
	at java.util.stream.Streams$RangeIntSpliterator.forEachRemaining(Streams.java:110)
	at java.util.stream.IntPipeline$Head.forEach(IntPipeline.java:557)
	at com.inspur.pmv6.Entrance.myTestCodes(Entrance.java:74)
	at com.inspur.pmv6.Entrance.main(Entrance.java:43)
[0328 17:18:08 609 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29utxrumz1kq9f8v|80ec1f8]-HelperThread-#1] hive.jdbc.Utils - Resolved authority: 10.211.55.29:10000
[0328 17:18:08 610 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29utxrumz1kq9f8v|80ec1f8]-HelperThread-#1] hive.jdbc.HiveConnection - Will try to open client transport with JDBC Uri: jdbc:hive2://10.211.55.29:10000/default
[0328 17:18:08 611 INFO ] [main] pmv6.dao.HiveDao - start to execute the sql :insert into test_table_double values (20180404, 100000, 10.704667125549305)
[0328 17:18:08 898 ERROR] [main] pmv6.dao.HiveDao - ERROR SQL: insert into test_table_double values (20180404, 100000, 10.704667125549305)
[0328 17:18:08 899 ERROR] [main] pmv6.dao.HiveDao - java.lang.RuntimeException: Cannot create staging directory 'hdfs://localhost:9000/home/chen/hive/warehouse/test_table_double/.hive-staging_hive_2018-03-28_02-18-08_805_8216378043533775491-82': Permission denied: user=hive, access=WRITE, inode="/home/chen/hive/warehouse/test_table_double":chen:supergroup:drwxr-xr-x
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.check(FSPermissionChecker.java:308)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:214)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:190)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkPermission(FSDirectory.java:1752)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkPermission(FSDirectory.java:1736)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkAncestorAccess(FSDirectory.java:1719)
	at org.apache.hadoop.hdfs.server.namenode.FSDirMkdirOp.mkdirs(FSDirMkdirOp.java:69)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.mkdirs(FSNamesystem.java:3867)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.mkdirs(NameNodeRpcServer.java:984)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.mkdirs(ClientNamenodeProtocolServerSideTranslatorPB.java:634)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:616)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:982)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2217)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2213)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1754)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2213)

java.sql.SQLException: java.lang.RuntimeException: Cannot create staging directory 'hdfs://localhost:9000/home/chen/hive/warehouse/test_table_double/.hive-staging_hive_2018-03-28_02-18-08_805_8216378043533775491-82': Permission denied: user=hive, access=WRITE, inode="/home/chen/hive/warehouse/test_table_double":chen:supergroup:drwxr-xr-x
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.check(FSPermissionChecker.java:308)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:214)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:190)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkPermission(FSDirectory.java:1752)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkPermission(FSDirectory.java:1736)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkAncestorAccess(FSDirectory.java:1719)
	at org.apache.hadoop.hdfs.server.namenode.FSDirMkdirOp.mkdirs(FSDirMkdirOp.java:69)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.mkdirs(FSNamesystem.java:3867)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.mkdirs(NameNodeRpcServer.java:984)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.mkdirs(ClientNamenodeProtocolServerSideTranslatorPB.java:634)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:616)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:982)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2217)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2213)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1754)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2213)

	at org.apache.hive.jdbc.HiveStatement.execute(HiveStatement.java:296)
	at org.apache.hive.jdbc.HivePreparedStatement.execute(HivePreparedStatement.java:98)
	at com.mchange.v2.c3p0.impl.NewProxyPreparedStatement.execute(NewProxyPreparedStatement.java:67)
	at com.inspur.pmv6.dao.HiveDao.executesql(HiveDao.java:152)
	at com.inspur.pmv6.Entrance.lambda$null$0(Entrance.java:83)
	at java.util.stream.Streams$RangeIntSpliterator.forEachRemaining(Streams.java:110)
	at java.util.stream.IntPipeline$Head.forEach(IntPipeline.java:557)
	at com.inspur.pmv6.Entrance.lambda$myTestCodes$1(Entrance.java:76)
	at java.util.stream.Streams$RangeIntSpliterator.forEachRemaining(Streams.java:110)
	at java.util.stream.IntPipeline$Head.forEach(IntPipeline.java:557)
	at com.inspur.pmv6.Entrance.myTestCodes(Entrance.java:74)
	at com.inspur.pmv6.Entrance.main(Entrance.java:43)
[0328 17:18:08 899 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29utxrumz1kq9f8v|80ec1f8]-HelperThread-#1] hive.jdbc.Utils - Supplied authorities: 10.211.55.29:10000
[0328 17:18:08 899 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29utxrumz1kq9f8v|80ec1f8]-HelperThread-#1] hive.jdbc.Utils - Resolved authority: 10.211.55.29:10000
[0328 17:18:08 900 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29utxrumz1kq9f8v|80ec1f8]-HelperThread-#1] hive.jdbc.HiveConnection - Will try to open client transport with JDBC Uri: jdbc:hive2://10.211.55.29:10000/default
[0328 17:18:08 900 INFO ] [main] pmv6.dao.HiveDao - start to execute the sql :insert into test_table_double values (20180404, 110000, 4.7673613662480125)
[0328 17:18:09 009 ERROR] [main] pmv6.dao.HiveDao - ERROR SQL: insert into test_table_double values (20180404, 110000, 4.7673613662480125)
[0328 17:18:09 009 ERROR] [main] pmv6.dao.HiveDao - java.lang.RuntimeException: Cannot create staging directory 'hdfs://localhost:9000/home/chen/hive/warehouse/test_table_double/.hive-staging_hive_2018-03-28_02-18-08_940_7793925655593269098-83': Permission denied: user=hive, access=WRITE, inode="/home/chen/hive/warehouse/test_table_double":chen:supergroup:drwxr-xr-x
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.check(FSPermissionChecker.java:308)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:214)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:190)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkPermission(FSDirectory.java:1752)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkPermission(FSDirectory.java:1736)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkAncestorAccess(FSDirectory.java:1719)
	at org.apache.hadoop.hdfs.server.namenode.FSDirMkdirOp.mkdirs(FSDirMkdirOp.java:69)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.mkdirs(FSNamesystem.java:3867)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.mkdirs(NameNodeRpcServer.java:984)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.mkdirs(ClientNamenodeProtocolServerSideTranslatorPB.java:634)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:616)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:982)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2217)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2213)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1754)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2213)

java.sql.SQLException: java.lang.RuntimeException: Cannot create staging directory 'hdfs://localhost:9000/home/chen/hive/warehouse/test_table_double/.hive-staging_hive_2018-03-28_02-18-08_940_7793925655593269098-83': Permission denied: user=hive, access=WRITE, inode="/home/chen/hive/warehouse/test_table_double":chen:supergroup:drwxr-xr-x
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.check(FSPermissionChecker.java:308)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:214)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:190)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkPermission(FSDirectory.java:1752)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkPermission(FSDirectory.java:1736)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkAncestorAccess(FSDirectory.java:1719)
	at org.apache.hadoop.hdfs.server.namenode.FSDirMkdirOp.mkdirs(FSDirMkdirOp.java:69)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.mkdirs(FSNamesystem.java:3867)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.mkdirs(NameNodeRpcServer.java:984)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.mkdirs(ClientNamenodeProtocolServerSideTranslatorPB.java:634)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:616)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:982)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2217)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2213)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1754)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2213)

	at org.apache.hive.jdbc.HiveStatement.execute(HiveStatement.java:296)
	at org.apache.hive.jdbc.HivePreparedStatement.execute(HivePreparedStatement.java:98)
	at com.mchange.v2.c3p0.impl.NewProxyPreparedStatement.execute(NewProxyPreparedStatement.java:67)
	at com.inspur.pmv6.dao.HiveDao.executesql(HiveDao.java:152)
	at com.inspur.pmv6.Entrance.lambda$null$0(Entrance.java:83)
	at java.util.stream.Streams$RangeIntSpliterator.forEachRemaining(Streams.java:110)
	at java.util.stream.IntPipeline$Head.forEach(IntPipeline.java:557)
	at com.inspur.pmv6.Entrance.lambda$myTestCodes$1(Entrance.java:76)
	at java.util.stream.Streams$RangeIntSpliterator.forEachRemaining(Streams.java:110)
	at java.util.stream.IntPipeline$Head.forEach(IntPipeline.java:557)
	at com.inspur.pmv6.Entrance.myTestCodes(Entrance.java:74)
	at com.inspur.pmv6.Entrance.main(Entrance.java:43)
[0328 17:18:09 009 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29utxrumz1kq9f8v|80ec1f8]-HelperThread-#2] hive.jdbc.Utils - Supplied authorities: 10.211.55.29:10000
[0328 17:18:09 010 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29utxrumz1kq9f8v|80ec1f8]-HelperThread-#2] hive.jdbc.Utils - Resolved authority: 10.211.55.29:10000
[0328 17:18:09 010 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29utxrumz1kq9f8v|80ec1f8]-HelperThread-#2] hive.jdbc.HiveConnection - Will try to open client transport with JDBC Uri: jdbc:hive2://10.211.55.29:10000/default
[0328 17:18:09 010 INFO ] [main] pmv6.dao.HiveDao - start to execute the sql :insert into test_table_double values (20180404, 120000, 78.3825123990637)
[0328 17:18:09 305 ERROR] [main] pmv6.dao.HiveDao - ERROR SQL: insert into test_table_double values (20180404, 120000, 78.3825123990637)
[0328 17:18:09 305 ERROR] [main] pmv6.dao.HiveDao - java.lang.RuntimeException: Cannot create staging directory 'hdfs://localhost:9000/home/chen/hive/warehouse/test_table_double/.hive-staging_hive_2018-03-28_02-18-09_206_6521491466424678644-84': Permission denied: user=hive, access=WRITE, inode="/home/chen/hive/warehouse/test_table_double":chen:supergroup:drwxr-xr-x
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.check(FSPermissionChecker.java:308)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:214)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:190)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkPermission(FSDirectory.java:1752)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkPermission(FSDirectory.java:1736)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkAncestorAccess(FSDirectory.java:1719)
	at org.apache.hadoop.hdfs.server.namenode.FSDirMkdirOp.mkdirs(FSDirMkdirOp.java:69)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.mkdirs(FSNamesystem.java:3867)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.mkdirs(NameNodeRpcServer.java:984)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.mkdirs(ClientNamenodeProtocolServerSideTranslatorPB.java:634)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:616)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:982)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2217)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2213)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1754)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2213)

java.sql.SQLException: java.lang.RuntimeException: Cannot create staging directory 'hdfs://localhost:9000/home/chen/hive/warehouse/test_table_double/.hive-staging_hive_2018-03-28_02-18-09_206_6521491466424678644-84': Permission denied: user=hive, access=WRITE, inode="/home/chen/hive/warehouse/test_table_double":chen:supergroup:drwxr-xr-x
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.check(FSPermissionChecker.java:308)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:214)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:190)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkPermission(FSDirectory.java:1752)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkPermission(FSDirectory.java:1736)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkAncestorAccess(FSDirectory.java:1719)
	at org.apache.hadoop.hdfs.server.namenode.FSDirMkdirOp.mkdirs(FSDirMkdirOp.java:69)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.mkdirs(FSNamesystem.java:3867)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.mkdirs(NameNodeRpcServer.java:984)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.mkdirs(ClientNamenodeProtocolServerSideTranslatorPB.java:634)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:616)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:982)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2217)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2213)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1754)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2213)

	at org.apache.hive.jdbc.HiveStatement.execute(HiveStatement.java:296)
	at org.apache.hive.jdbc.HivePreparedStatement.execute(HivePreparedStatement.java:98)
	at com.mchange.v2.c3p0.impl.NewProxyPreparedStatement.execute(NewProxyPreparedStatement.java:67)
	at com.inspur.pmv6.dao.HiveDao.executesql(HiveDao.java:152)
	at com.inspur.pmv6.Entrance.lambda$null$0(Entrance.java:83)
	at java.util.stream.Streams$RangeIntSpliterator.forEachRemaining(Streams.java:110)
	at java.util.stream.IntPipeline$Head.forEach(IntPipeline.java:557)
	at com.inspur.pmv6.Entrance.lambda$myTestCodes$1(Entrance.java:76)
	at java.util.stream.Streams$RangeIntSpliterator.forEachRemaining(Streams.java:110)
	at java.util.stream.IntPipeline$Head.forEach(IntPipeline.java:557)
	at com.inspur.pmv6.Entrance.myTestCodes(Entrance.java:74)
	at com.inspur.pmv6.Entrance.main(Entrance.java:43)
[0328 17:18:09 305 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29utxrumz1kq9f8v|80ec1f8]-HelperThread-#2] hive.jdbc.Utils - Supplied authorities: 10.211.55.29:10000
[0328 17:18:09 306 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29utxrumz1kq9f8v|80ec1f8]-HelperThread-#2] hive.jdbc.Utils - Resolved authority: 10.211.55.29:10000
[0328 17:18:09 306 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29utxrumz1kq9f8v|80ec1f8]-HelperThread-#2] hive.jdbc.HiveConnection - Will try to open client transport with JDBC Uri: jdbc:hive2://10.211.55.29:10000/default
[0328 17:18:09 306 INFO ] [main] pmv6.dao.HiveDao - start to execute the sql :insert into test_table_double values (20180404, 010000, 19.829036963874145)
[0328 17:18:09 423 ERROR] [main] pmv6.dao.HiveDao - ERROR SQL: insert into test_table_double values (20180404, 010000, 19.829036963874145)
[0328 17:18:09 423 ERROR] [main] pmv6.dao.HiveDao - java.lang.RuntimeException: Cannot create staging directory 'hdfs://localhost:9000/home/chen/hive/warehouse/test_table_double/.hive-staging_hive_2018-03-28_02-18-09_349_5444794658968886673-85': Permission denied: user=hive, access=WRITE, inode="/home/chen/hive/warehouse/test_table_double":chen:supergroup:drwxr-xr-x
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.check(FSPermissionChecker.java:308)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:214)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:190)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkPermission(FSDirectory.java:1752)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkPermission(FSDirectory.java:1736)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkAncestorAccess(FSDirectory.java:1719)
	at org.apache.hadoop.hdfs.server.namenode.FSDirMkdirOp.mkdirs(FSDirMkdirOp.java:69)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.mkdirs(FSNamesystem.java:3867)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.mkdirs(NameNodeRpcServer.java:984)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.mkdirs(ClientNamenodeProtocolServerSideTranslatorPB.java:634)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:616)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:982)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2217)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2213)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1754)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2213)

java.sql.SQLException: java.lang.RuntimeException: Cannot create staging directory 'hdfs://localhost:9000/home/chen/hive/warehouse/test_table_double/.hive-staging_hive_2018-03-28_02-18-09_349_5444794658968886673-85': Permission denied: user=hive, access=WRITE, inode="/home/chen/hive/warehouse/test_table_double":chen:supergroup:drwxr-xr-x
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.check(FSPermissionChecker.java:308)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:214)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:190)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkPermission(FSDirectory.java:1752)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkPermission(FSDirectory.java:1736)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkAncestorAccess(FSDirectory.java:1719)
	at org.apache.hadoop.hdfs.server.namenode.FSDirMkdirOp.mkdirs(FSDirMkdirOp.java:69)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.mkdirs(FSNamesystem.java:3867)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.mkdirs(NameNodeRpcServer.java:984)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.mkdirs(ClientNamenodeProtocolServerSideTranslatorPB.java:634)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:616)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:982)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2217)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2213)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1754)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2213)

	at org.apache.hive.jdbc.HiveStatement.execute(HiveStatement.java:296)
	at org.apache.hive.jdbc.HivePreparedStatement.execute(HivePreparedStatement.java:98)
	at com.mchange.v2.c3p0.impl.NewProxyPreparedStatement.execute(NewProxyPreparedStatement.java:67)
	at com.inspur.pmv6.dao.HiveDao.executesql(HiveDao.java:152)
	at com.inspur.pmv6.Entrance.lambda$null$0(Entrance.java:83)
	at java.util.stream.Streams$RangeIntSpliterator.forEachRemaining(Streams.java:110)
	at java.util.stream.IntPipeline$Head.forEach(IntPipeline.java:557)
	at com.inspur.pmv6.Entrance.lambda$myTestCodes$1(Entrance.java:76)
	at java.util.stream.Streams$RangeIntSpliterator.forEachRemaining(Streams.java:110)
	at java.util.stream.IntPipeline$Head.forEach(IntPipeline.java:557)
	at com.inspur.pmv6.Entrance.myTestCodes(Entrance.java:74)
	at com.inspur.pmv6.Entrance.main(Entrance.java:43)
[0328 17:18:09 423 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29utxrumz1kq9f8v|80ec1f8]-HelperThread-#1] hive.jdbc.Utils - Supplied authorities: 10.211.55.29:10000
[0328 17:18:09 424 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29utxrumz1kq9f8v|80ec1f8]-HelperThread-#1] hive.jdbc.Utils - Resolved authority: 10.211.55.29:10000
[0328 17:18:09 424 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29utxrumz1kq9f8v|80ec1f8]-HelperThread-#1] hive.jdbc.HiveConnection - Will try to open client transport with JDBC Uri: jdbc:hive2://10.211.55.29:10000/default
[0328 17:18:09 425 INFO ] [main] pmv6.dao.HiveDao - start to execute the sql :insert into test_table_double values (20180404, 020000, 86.4507637747078)
[0328 17:18:09 689 ERROR] [main] pmv6.dao.HiveDao - ERROR SQL: insert into test_table_double values (20180404, 020000, 86.4507637747078)
[0328 17:18:09 689 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29utxrumz1kq9f8v|80ec1f8]-HelperThread-#1] hive.jdbc.Utils - Supplied authorities: 10.211.55.29:10000
[0328 17:18:09 689 ERROR] [main] pmv6.dao.HiveDao - java.lang.RuntimeException: Cannot create staging directory 'hdfs://localhost:9000/home/chen/hive/warehouse/test_table_double/.hive-staging_hive_2018-03-28_02-18-09_620_138679078111359310-86': Permission denied: user=hive, access=WRITE, inode="/home/chen/hive/warehouse/test_table_double":chen:supergroup:drwxr-xr-x
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.check(FSPermissionChecker.java:308)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:214)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:190)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkPermission(FSDirectory.java:1752)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkPermission(FSDirectory.java:1736)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkAncestorAccess(FSDirectory.java:1719)
	at org.apache.hadoop.hdfs.server.namenode.FSDirMkdirOp.mkdirs(FSDirMkdirOp.java:69)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.mkdirs(FSNamesystem.java:3867)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.mkdirs(NameNodeRpcServer.java:984)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.mkdirs(ClientNamenodeProtocolServerSideTranslatorPB.java:634)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:616)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:982)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2217)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2213)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1754)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2213)

java.sql.SQLException: java.lang.RuntimeException: Cannot create staging directory 'hdfs://localhost:9000/home/chen/hive/warehouse/test_table_double/.hive-staging_hive_2018-03-28_02-18-09_620_138679078111359310-86': Permission denied: user=hive, access=WRITE, inode="/home/chen/hive/warehouse/test_table_double":chen:supergroup:drwxr-xr-x
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.check(FSPermissionChecker.java:308)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:214)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:190)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkPermission(FSDirectory.java:1752)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkPermission(FSDirectory.java:1736)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkAncestorAccess(FSDirectory.java:1719)
	at org.apache.hadoop.hdfs.server.namenode.FSDirMkdirOp.mkdirs(FSDirMkdirOp.java:69)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.mkdirs(FSNamesystem.java:3867)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.mkdirs(NameNodeRpcServer.java:984)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.mkdirs(ClientNamenodeProtocolServerSideTranslatorPB.java:634)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:616)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:982)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2217)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2213)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1754)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2213)

	at org.apache.hive.jdbc.HiveStatement.execute(HiveStatement.java:296)
	at org.apache.hive.jdbc.HivePreparedStatement.execute(HivePreparedStatement.java:98)
	at com.mchange.v2.c3p0.impl.NewProxyPreparedStatement.execute(NewProxyPreparedStatement.java:67)
	at com.inspur.pmv6.dao.HiveDao.executesql(HiveDao.java:152)
	at com.inspur.pmv6.Entrance.lambda$null$0(Entrance.java:83)
	at java.util.stream.Streams$RangeIntSpliterator.forEachRemaining(Streams.java:110)
	at java.util.stream.IntPipeline$Head.forEach(IntPipeline.java:557)
	at com.inspur.pmv6.Entrance.lambda$myTestCodes$1(Entrance.java:76)
	at java.util.stream.Streams$RangeIntSpliterator.forEachRemaining(Streams.java:110)
	at java.util.stream.IntPipeline$Head.forEach(IntPipeline.java:557)
	at com.inspur.pmv6.Entrance.myTestCodes(Entrance.java:74)
	at com.inspur.pmv6.Entrance.main(Entrance.java:43)
[0328 17:18:09 689 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29utxrumz1kq9f8v|80ec1f8]-HelperThread-#1] hive.jdbc.Utils - Resolved authority: 10.211.55.29:10000
[0328 17:18:09 690 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29utxrumz1kq9f8v|80ec1f8]-HelperThread-#1] hive.jdbc.HiveConnection - Will try to open client transport with JDBC Uri: jdbc:hive2://10.211.55.29:10000/default
[0328 17:18:09 690 INFO ] [main] pmv6.dao.HiveDao - start to execute the sql :insert into test_table_double values (20180404, 030000, 72.97204718885426)
[0328 17:18:09 806 ERROR] [main] pmv6.dao.HiveDao - ERROR SQL: insert into test_table_double values (20180404, 030000, 72.97204718885426)
[0328 17:18:09 806 ERROR] [main] pmv6.dao.HiveDao - java.lang.RuntimeException: Cannot create staging directory 'hdfs://localhost:9000/home/chen/hive/warehouse/test_table_double/.hive-staging_hive_2018-03-28_02-18-09_734_1248988159085159621-87': Permission denied: user=hive, access=WRITE, inode="/home/chen/hive/warehouse/test_table_double":chen:supergroup:drwxr-xr-x
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.check(FSPermissionChecker.java:308)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:214)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:190)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkPermission(FSDirectory.java:1752)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkPermission(FSDirectory.java:1736)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkAncestorAccess(FSDirectory.java:1719)
	at org.apache.hadoop.hdfs.server.namenode.FSDirMkdirOp.mkdirs(FSDirMkdirOp.java:69)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.mkdirs(FSNamesystem.java:3867)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.mkdirs(NameNodeRpcServer.java:984)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.mkdirs(ClientNamenodeProtocolServerSideTranslatorPB.java:634)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:616)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:982)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2217)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2213)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1754)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2213)

java.sql.SQLException: java.lang.RuntimeException: Cannot create staging directory 'hdfs://localhost:9000/home/chen/hive/warehouse/test_table_double/.hive-staging_hive_2018-03-28_02-18-09_734_1248988159085159621-87': Permission denied: user=hive, access=WRITE, inode="/home/chen/hive/warehouse/test_table_double":chen:supergroup:drwxr-xr-x
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.check(FSPermissionChecker.java:308)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:214)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:190)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkPermission(FSDirectory.java:1752)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkPermission(FSDirectory.java:1736)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkAncestorAccess(FSDirectory.java:1719)
	at org.apache.hadoop.hdfs.server.namenode.FSDirMkdirOp.mkdirs(FSDirMkdirOp.java:69)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.mkdirs(FSNamesystem.java:3867)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.mkdirs(NameNodeRpcServer.java:984)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.mkdirs(ClientNamenodeProtocolServerSideTranslatorPB.java:634)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:616)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:982)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2217)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2213)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1754)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2213)

	at org.apache.hive.jdbc.HiveStatement.execute(HiveStatement.java:296)
	at org.apache.hive.jdbc.HivePreparedStatement.execute(HivePreparedStatement.java:98)
	at com.mchange.v2.c3p0.impl.NewProxyPreparedStatement.execute(NewProxyPreparedStatement.java:67)
	at com.inspur.pmv6.dao.HiveDao.executesql(HiveDao.java:152)
	at com.inspur.pmv6.Entrance.lambda$null$0(Entrance.java:83)
	at java.util.stream.Streams$RangeIntSpliterator.forEachRemaining(Streams.java:110)
	at java.util.stream.IntPipeline$Head.forEach(IntPipeline.java:557)
	at com.inspur.pmv6.Entrance.lambda$myTestCodes$1(Entrance.java:76)
	at java.util.stream.Streams$RangeIntSpliterator.forEachRemaining(Streams.java:110)
	at java.util.stream.IntPipeline$Head.forEach(IntPipeline.java:557)
	at com.inspur.pmv6.Entrance.myTestCodes(Entrance.java:74)
	at com.inspur.pmv6.Entrance.main(Entrance.java:43)
[0328 17:18:09 806 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29utxrumz1kq9f8v|80ec1f8]-HelperThread-#0] hive.jdbc.Utils - Supplied authorities: 10.211.55.29:10000
[0328 17:18:09 807 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29utxrumz1kq9f8v|80ec1f8]-HelperThread-#0] hive.jdbc.Utils - Resolved authority: 10.211.55.29:10000
[0328 17:18:09 807 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29utxrumz1kq9f8v|80ec1f8]-HelperThread-#0] hive.jdbc.HiveConnection - Will try to open client transport with JDBC Uri: jdbc:hive2://10.211.55.29:10000/default
[0328 17:18:09 808 INFO ] [main] pmv6.dao.HiveDao - start to execute the sql :insert into test_table_double values (20180404, 040000, 2.0132169640939668)
[0328 17:18:10 040 ERROR] [main] pmv6.dao.HiveDao - ERROR SQL: insert into test_table_double values (20180404, 040000, 2.0132169640939668)
[0328 17:18:10 040 ERROR] [main] pmv6.dao.HiveDao - java.lang.RuntimeException: Cannot create staging directory 'hdfs://localhost:9000/home/chen/hive/warehouse/test_table_double/.hive-staging_hive_2018-03-28_02-18-09_972_1136028640475218069-88': Permission denied: user=hive, access=WRITE, inode="/home/chen/hive/warehouse/test_table_double":chen:supergroup:drwxr-xr-x
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.check(FSPermissionChecker.java:308)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:214)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:190)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkPermission(FSDirectory.java:1752)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkPermission(FSDirectory.java:1736)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkAncestorAccess(FSDirectory.java:1719)
	at org.apache.hadoop.hdfs.server.namenode.FSDirMkdirOp.mkdirs(FSDirMkdirOp.java:69)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.mkdirs(FSNamesystem.java:3867)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.mkdirs(NameNodeRpcServer.java:984)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.mkdirs(ClientNamenodeProtocolServerSideTranslatorPB.java:634)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:616)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:982)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2217)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2213)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1754)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2213)

java.sql.SQLException: java.lang.RuntimeException: Cannot create staging directory 'hdfs://localhost:9000/home/chen/hive/warehouse/test_table_double/.hive-staging_hive_2018-03-28_02-18-09_972_1136028640475218069-88': Permission denied: user=hive, access=WRITE, inode="/home/chen/hive/warehouse/test_table_double":chen:supergroup:drwxr-xr-x
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.check(FSPermissionChecker.java:308)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:214)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:190)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkPermission(FSDirectory.java:1752)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkPermission(FSDirectory.java:1736)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkAncestorAccess(FSDirectory.java:1719)
	at org.apache.hadoop.hdfs.server.namenode.FSDirMkdirOp.mkdirs(FSDirMkdirOp.java:69)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.mkdirs(FSNamesystem.java:3867)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.mkdirs(NameNodeRpcServer.java:984)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.mkdirs(ClientNamenodeProtocolServerSideTranslatorPB.java:634)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:616)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:982)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2217)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2213)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1754)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2213)

	at org.apache.hive.jdbc.HiveStatement.execute(HiveStatement.java:296)
	at org.apache.hive.jdbc.HivePreparedStatement.execute(HivePreparedStatement.java:98)
	at com.mchange.v2.c3p0.impl.NewProxyPreparedStatement.execute(NewProxyPreparedStatement.java:67)
	at com.inspur.pmv6.dao.HiveDao.executesql(HiveDao.java:152)
	at com.inspur.pmv6.Entrance.lambda$null$0(Entrance.java:83)
	at java.util.stream.Streams$RangeIntSpliterator.forEachRemaining(Streams.java:110)
	at java.util.stream.IntPipeline$Head.forEach(IntPipeline.java:557)
	at com.inspur.pmv6.Entrance.lambda$myTestCodes$1(Entrance.java:76)
	at java.util.stream.Streams$RangeIntSpliterator.forEachRemaining(Streams.java:110)
	at java.util.stream.IntPipeline$Head.forEach(IntPipeline.java:557)
	at com.inspur.pmv6.Entrance.myTestCodes(Entrance.java:74)
	at com.inspur.pmv6.Entrance.main(Entrance.java:43)
[0328 17:18:10 040 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29utxrumz1kq9f8v|80ec1f8]-HelperThread-#0] hive.jdbc.Utils - Supplied authorities: 10.211.55.29:10000
[0328 17:18:10 041 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29utxrumz1kq9f8v|80ec1f8]-HelperThread-#0] hive.jdbc.Utils - Resolved authority: 10.211.55.29:10000
[0328 17:18:10 041 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29utxrumz1kq9f8v|80ec1f8]-HelperThread-#0] hive.jdbc.HiveConnection - Will try to open client transport with JDBC Uri: jdbc:hive2://10.211.55.29:10000/default
[0328 17:18:10 041 INFO ] [main] pmv6.dao.HiveDao - start to execute the sql :insert into test_table_double values (20180404, 050000, 67.93159482393433)
[0328 17:18:10 152 ERROR] [main] pmv6.dao.HiveDao - ERROR SQL: insert into test_table_double values (20180404, 050000, 67.93159482393433)
[0328 17:18:10 152 ERROR] [main] pmv6.dao.HiveDao - java.lang.RuntimeException: Cannot create staging directory 'hdfs://localhost:9000/home/chen/hive/warehouse/test_table_double/.hive-staging_hive_2018-03-28_02-18-10_081_9052591601918748932-89': Permission denied: user=hive, access=WRITE, inode="/home/chen/hive/warehouse/test_table_double":chen:supergroup:drwxr-xr-x
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.check(FSPermissionChecker.java:308)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:214)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:190)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkPermission(FSDirectory.java:1752)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkPermission(FSDirectory.java:1736)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkAncestorAccess(FSDirectory.java:1719)
	at org.apache.hadoop.hdfs.server.namenode.FSDirMkdirOp.mkdirs(FSDirMkdirOp.java:69)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.mkdirs(FSNamesystem.java:3867)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.mkdirs(NameNodeRpcServer.java:984)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.mkdirs(ClientNamenodeProtocolServerSideTranslatorPB.java:634)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:616)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:982)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2217)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2213)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1754)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2213)

java.sql.SQLException: java.lang.RuntimeException: Cannot create staging directory 'hdfs://localhost:9000/home/chen/hive/warehouse/test_table_double/.hive-staging_hive_2018-03-28_02-18-10_081_9052591601918748932-89': Permission denied: user=hive, access=WRITE, inode="/home/chen/hive/warehouse/test_table_double":chen:supergroup:drwxr-xr-x
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.check(FSPermissionChecker.java:308)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:214)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:190)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkPermission(FSDirectory.java:1752)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkPermission(FSDirectory.java:1736)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkAncestorAccess(FSDirectory.java:1719)
	at org.apache.hadoop.hdfs.server.namenode.FSDirMkdirOp.mkdirs(FSDirMkdirOp.java:69)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.mkdirs(FSNamesystem.java:3867)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.mkdirs(NameNodeRpcServer.java:984)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.mkdirs(ClientNamenodeProtocolServerSideTranslatorPB.java:634)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:616)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:982)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2217)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2213)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1754)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2213)

	at org.apache.hive.jdbc.HiveStatement.execute(HiveStatement.java:296)
	at org.apache.hive.jdbc.HivePreparedStatement.execute(HivePreparedStatement.java:98)
	at com.mchange.v2.c3p0.impl.NewProxyPreparedStatement.execute(NewProxyPreparedStatement.java:67)
	at com.inspur.pmv6.dao.HiveDao.executesql(HiveDao.java:152)
	at com.inspur.pmv6.Entrance.lambda$null$0(Entrance.java:83)
	at java.util.stream.Streams$RangeIntSpliterator.forEachRemaining(Streams.java:110)
	at java.util.stream.IntPipeline$Head.forEach(IntPipeline.java:557)
	at com.inspur.pmv6.Entrance.lambda$myTestCodes$1(Entrance.java:76)
	at java.util.stream.Streams$RangeIntSpliterator.forEachRemaining(Streams.java:110)
	at java.util.stream.IntPipeline$Head.forEach(IntPipeline.java:557)
	at com.inspur.pmv6.Entrance.myTestCodes(Entrance.java:74)
	at com.inspur.pmv6.Entrance.main(Entrance.java:43)
[0328 17:18:10 152 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29utxrumz1kq9f8v|80ec1f8]-HelperThread-#2] hive.jdbc.Utils - Supplied authorities: 10.211.55.29:10000
[0328 17:18:10 152 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29utxrumz1kq9f8v|80ec1f8]-HelperThread-#2] hive.jdbc.Utils - Resolved authority: 10.211.55.29:10000
[0328 17:18:10 153 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29utxrumz1kq9f8v|80ec1f8]-HelperThread-#2] hive.jdbc.HiveConnection - Will try to open client transport with JDBC Uri: jdbc:hive2://10.211.55.29:10000/default
[0328 17:18:10 153 INFO ] [main] pmv6.dao.HiveDao - start to execute the sql :insert into test_table_double values (20180404, 060000, 99.26828922609113)
[0328 17:24:47 064 INFO ] [MLog-Init-Reporter] v2.log.MLog - MLog clients using slf4j logging.
[0328 17:24:47 343 INFO ] [main] v2.c3p0.C3P0Registry - Initializing c3p0-0.9.5.2 [built 08-December-2015 22:06:04 -0800; debug? true; trace: 10]
[0328 17:24:47 546 INFO ] [main] pmv6.dao.HiveDao - start to execute the sql :insert into test_table_double values (20180329, 010000, 21.713011215943435)
[0328 17:24:47 584 INFO ] [main] c3p0.impl.AbstractPoolBackedDataSource - Initializing c3p0 pool... com.mchange.v2.c3p0.ComboPooledDataSource [ acquireIncrement -> 1, acquireRetryAttempts -> 30, acquireRetryDelay -> 1000, autoCommitOnClose -> false, automaticTestTable -> null, breakAfterAcquireFailure -> false, checkoutTimeout -> 0, connectionCustomizerClassName -> null, connectionTesterClassName -> com.mchange.v2.c3p0.impl.DefaultConnectionTester, contextClassLoaderSource -> caller, dataSourceName -> 1hge0w29uty0tmi85t0ga|2e55dd0c, debugUnreturnedConnectionStackTraces -> false, description -> null, driverClass -> org.apache.hive.jdbc.HiveDriver, extensions -> {}, factoryClassLocation -> null, forceIgnoreUnresolvedTransactions -> false, forceSynchronousCheckins -> false, forceUseNamedDriverClass -> false, identityToken -> 1hge0w29uty0tmi85t0ga|2e55dd0c, idleConnectionTestPeriod -> 0, initialPoolSize -> 3, jdbcUrl -> jdbc:hive2://10.211.55.29:10000/default, maxAdministrativeTaskTime -> 0, maxConnectionAge -> 0, maxIdleTime -> 0, maxIdleTimeExcessConnections -> 0, maxPoolSize -> 2, maxStatements -> 0, maxStatementsPerConnection -> 0, minPoolSize -> 1, numHelperThreads -> 3, preferredTestQuery -> null, privilegeSpawnedThreads -> false, properties -> {user=******, password=******}, propertyCycle -> 0, statementCacheNumDeferredCloseThreads -> 0, testConnectionOnCheckin -> false, testConnectionOnCheckout -> false, unreturnedConnectionTimeout -> 0, userOverrides -> {}, usesTraditionalReflectiveProxies -> false ]
[0328 17:24:47 627 WARN ] [main] v2.resourcepool.BasicResourcePool - Bad pool size config, start 3 > max 2. Using 2 as start.
[0328 17:24:47 653 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29uty0tmi85t0ga|2e55dd0c]-HelperThread-#2] hive.jdbc.Utils - Supplied authorities: 10.211.55.29:10000
[0328 17:24:47 653 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29uty0tmi85t0ga|2e55dd0c]-HelperThread-#1] hive.jdbc.Utils - Supplied authorities: 10.211.55.29:10000
[0328 17:24:47 653 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29uty0tmi85t0ga|2e55dd0c]-HelperThread-#1] hive.jdbc.Utils - Resolved authority: 10.211.55.29:10000
[0328 17:24:47 653 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29uty0tmi85t0ga|2e55dd0c]-HelperThread-#2] hive.jdbc.Utils - Resolved authority: 10.211.55.29:10000
[0328 17:24:47 746 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29uty0tmi85t0ga|2e55dd0c]-HelperThread-#2] hive.jdbc.HiveConnection - Will try to open client transport with JDBC Uri: jdbc:hive2://10.211.55.29:10000/default
[0328 17:24:47 746 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29uty0tmi85t0ga|2e55dd0c]-HelperThread-#1] hive.jdbc.HiveConnection - Will try to open client transport with JDBC Uri: jdbc:hive2://10.211.55.29:10000/default
[0328 17:24:47 860 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29uty0tmi85t0ga|2e55dd0c]-HelperThread-#2] hive.jdbc.HiveConnection - Could not open client transport with JDBC Uri: jdbc:hive2://10.211.55.29:10000/default
[0328 17:24:47 861 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29uty0tmi85t0ga|2e55dd0c]-HelperThread-#1] hive.jdbc.HiveConnection - Could not open client transport with JDBC Uri: jdbc:hive2://10.211.55.29:10000/default
[0328 17:24:47 861 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29uty0tmi85t0ga|2e55dd0c]-HelperThread-#2] hive.jdbc.HiveConnection - Transport Used for JDBC connection: null
[0328 17:24:47 861 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29uty0tmi85t0ga|2e55dd0c]-HelperThread-#1] hive.jdbc.HiveConnection - Transport Used for JDBC connection: null
[0328 17:24:48 864 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29uty0tmi85t0ga|2e55dd0c]-HelperThread-#1] hive.jdbc.Utils - Supplied authorities: 10.211.55.29:10000
[0328 17:24:48 864 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29uty0tmi85t0ga|2e55dd0c]-HelperThread-#2] hive.jdbc.Utils - Supplied authorities: 10.211.55.29:10000
[0328 17:24:48 865 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29uty0tmi85t0ga|2e55dd0c]-HelperThread-#1] hive.jdbc.Utils - Resolved authority: 10.211.55.29:10000
[0328 17:24:48 865 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29uty0tmi85t0ga|2e55dd0c]-HelperThread-#2] hive.jdbc.Utils - Resolved authority: 10.211.55.29:10000
[0328 17:24:48 866 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29uty0tmi85t0ga|2e55dd0c]-HelperThread-#1] hive.jdbc.HiveConnection - Will try to open client transport with JDBC Uri: jdbc:hive2://10.211.55.29:10000/default
[0328 17:24:48 866 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29uty0tmi85t0ga|2e55dd0c]-HelperThread-#2] hive.jdbc.HiveConnection - Will try to open client transport with JDBC Uri: jdbc:hive2://10.211.55.29:10000/default
[0328 17:24:48 967 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29uty0tmi85t0ga|2e55dd0c]-HelperThread-#2] hive.jdbc.HiveConnection - Could not open client transport with JDBC Uri: jdbc:hive2://10.211.55.29:10000/default
[0328 17:24:48 968 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29uty0tmi85t0ga|2e55dd0c]-HelperThread-#2] hive.jdbc.HiveConnection - Transport Used for JDBC connection: null
[0328 17:24:48 967 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29uty0tmi85t0ga|2e55dd0c]-HelperThread-#1] hive.jdbc.HiveConnection - Could not open client transport with JDBC Uri: jdbc:hive2://10.211.55.29:10000/default
[0328 17:24:48 969 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29uty0tmi85t0ga|2e55dd0c]-HelperThread-#1] hive.jdbc.HiveConnection - Transport Used for JDBC connection: null
[0328 17:24:49 972 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29uty0tmi85t0ga|2e55dd0c]-HelperThread-#1] hive.jdbc.Utils - Supplied authorities: 10.211.55.29:10000
[0328 17:24:49 972 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29uty0tmi85t0ga|2e55dd0c]-HelperThread-#2] hive.jdbc.Utils - Supplied authorities: 10.211.55.29:10000
[0328 17:24:49 973 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29uty0tmi85t0ga|2e55dd0c]-HelperThread-#1] hive.jdbc.Utils - Resolved authority: 10.211.55.29:10000
[0328 17:24:49 973 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29uty0tmi85t0ga|2e55dd0c]-HelperThread-#2] hive.jdbc.Utils - Resolved authority: 10.211.55.29:10000
[0328 17:24:49 975 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29uty0tmi85t0ga|2e55dd0c]-HelperThread-#1] hive.jdbc.HiveConnection - Will try to open client transport with JDBC Uri: jdbc:hive2://10.211.55.29:10000/default
[0328 17:24:49 975 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29uty0tmi85t0ga|2e55dd0c]-HelperThread-#2] hive.jdbc.HiveConnection - Will try to open client transport with JDBC Uri: jdbc:hive2://10.211.55.29:10000/default
[0328 17:24:50 077 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29uty0tmi85t0ga|2e55dd0c]-HelperThread-#2] hive.jdbc.HiveConnection - Could not open client transport with JDBC Uri: jdbc:hive2://10.211.55.29:10000/default
[0328 17:24:50 077 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29uty0tmi85t0ga|2e55dd0c]-HelperThread-#1] hive.jdbc.HiveConnection - Could not open client transport with JDBC Uri: jdbc:hive2://10.211.55.29:10000/default
[0328 17:24:50 077 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29uty0tmi85t0ga|2e55dd0c]-HelperThread-#2] hive.jdbc.HiveConnection - Transport Used for JDBC connection: null
[0328 17:24:50 078 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29uty0tmi85t0ga|2e55dd0c]-HelperThread-#1] hive.jdbc.HiveConnection - Transport Used for JDBC connection: null
[0328 17:24:51 079 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29uty0tmi85t0ga|2e55dd0c]-HelperThread-#1] hive.jdbc.Utils - Supplied authorities: 10.211.55.29:10000
[0328 17:24:51 079 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29uty0tmi85t0ga|2e55dd0c]-HelperThread-#2] hive.jdbc.Utils - Supplied authorities: 10.211.55.29:10000
[0328 17:24:51 079 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29uty0tmi85t0ga|2e55dd0c]-HelperThread-#1] hive.jdbc.Utils - Resolved authority: 10.211.55.29:10000
[0328 17:24:51 080 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29uty0tmi85t0ga|2e55dd0c]-HelperThread-#2] hive.jdbc.Utils - Resolved authority: 10.211.55.29:10000
[0328 17:24:51 080 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29uty0tmi85t0ga|2e55dd0c]-HelperThread-#1] hive.jdbc.HiveConnection - Will try to open client transport with JDBC Uri: jdbc:hive2://10.211.55.29:10000/default
[0328 17:24:51 080 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29uty0tmi85t0ga|2e55dd0c]-HelperThread-#2] hive.jdbc.HiveConnection - Will try to open client transport with JDBC Uri: jdbc:hive2://10.211.55.29:10000/default
[0328 17:24:51 181 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29uty0tmi85t0ga|2e55dd0c]-HelperThread-#1] hive.jdbc.HiveConnection - Could not open client transport with JDBC Uri: jdbc:hive2://10.211.55.29:10000/default
[0328 17:24:51 181 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29uty0tmi85t0ga|2e55dd0c]-HelperThread-#2] hive.jdbc.HiveConnection - Could not open client transport with JDBC Uri: jdbc:hive2://10.211.55.29:10000/default
[0328 17:24:51 181 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29uty0tmi85t0ga|2e55dd0c]-HelperThread-#2] hive.jdbc.HiveConnection - Transport Used for JDBC connection: null
[0328 17:24:51 181 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29uty0tmi85t0ga|2e55dd0c]-HelperThread-#1] hive.jdbc.HiveConnection - Transport Used for JDBC connection: null
[0328 17:24:52 185 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29uty0tmi85t0ga|2e55dd0c]-HelperThread-#1] hive.jdbc.Utils - Supplied authorities: 10.211.55.29:10000
[0328 17:24:52 186 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29uty0tmi85t0ga|2e55dd0c]-HelperThread-#0] hive.jdbc.Utils - Supplied authorities: 10.211.55.29:10000
[0328 17:24:52 186 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29uty0tmi85t0ga|2e55dd0c]-HelperThread-#1] hive.jdbc.Utils - Resolved authority: 10.211.55.29:10000
[0328 17:24:52 186 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29uty0tmi85t0ga|2e55dd0c]-HelperThread-#0] hive.jdbc.Utils - Resolved authority: 10.211.55.29:10000
[0328 17:24:52 187 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29uty0tmi85t0ga|2e55dd0c]-HelperThread-#1] hive.jdbc.HiveConnection - Will try to open client transport with JDBC Uri: jdbc:hive2://10.211.55.29:10000/default
[0328 17:24:52 187 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29uty0tmi85t0ga|2e55dd0c]-HelperThread-#0] hive.jdbc.HiveConnection - Will try to open client transport with JDBC Uri: jdbc:hive2://10.211.55.29:10000/default
[0328 17:24:52 290 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29uty0tmi85t0ga|2e55dd0c]-HelperThread-#1] hive.jdbc.HiveConnection - Could not open client transport with JDBC Uri: jdbc:hive2://10.211.55.29:10000/default
[0328 17:24:52 290 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29uty0tmi85t0ga|2e55dd0c]-HelperThread-#0] hive.jdbc.HiveConnection - Could not open client transport with JDBC Uri: jdbc:hive2://10.211.55.29:10000/default
[0328 17:24:52 290 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29uty0tmi85t0ga|2e55dd0c]-HelperThread-#0] hive.jdbc.HiveConnection - Transport Used for JDBC connection: null
[0328 17:24:52 290 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29uty0tmi85t0ga|2e55dd0c]-HelperThread-#1] hive.jdbc.HiveConnection - Transport Used for JDBC connection: null
[0328 17:24:53 296 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29uty0tmi85t0ga|2e55dd0c]-HelperThread-#0] hive.jdbc.Utils - Supplied authorities: 10.211.55.29:10000
[0328 17:24:53 296 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29uty0tmi85t0ga|2e55dd0c]-HelperThread-#1] hive.jdbc.Utils - Supplied authorities: 10.211.55.29:10000
[0328 17:24:53 296 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29uty0tmi85t0ga|2e55dd0c]-HelperThread-#0] hive.jdbc.Utils - Resolved authority: 10.211.55.29:10000
[0328 17:24:53 297 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29uty0tmi85t0ga|2e55dd0c]-HelperThread-#1] hive.jdbc.Utils - Resolved authority: 10.211.55.29:10000
[0328 17:24:53 297 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29uty0tmi85t0ga|2e55dd0c]-HelperThread-#0] hive.jdbc.HiveConnection - Will try to open client transport with JDBC Uri: jdbc:hive2://10.211.55.29:10000/default
[0328 17:24:53 297 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29uty0tmi85t0ga|2e55dd0c]-HelperThread-#1] hive.jdbc.HiveConnection - Will try to open client transport with JDBC Uri: jdbc:hive2://10.211.55.29:10000/default
[0328 17:24:53 398 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29uty0tmi85t0ga|2e55dd0c]-HelperThread-#1] hive.jdbc.HiveConnection - Could not open client transport with JDBC Uri: jdbc:hive2://10.211.55.29:10000/default
[0328 17:24:53 398 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29uty0tmi85t0ga|2e55dd0c]-HelperThread-#0] hive.jdbc.HiveConnection - Could not open client transport with JDBC Uri: jdbc:hive2://10.211.55.29:10000/default
[0328 17:24:53 399 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29uty0tmi85t0ga|2e55dd0c]-HelperThread-#1] hive.jdbc.HiveConnection - Transport Used for JDBC connection: null
[0328 17:24:53 399 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29uty0tmi85t0ga|2e55dd0c]-HelperThread-#0] hive.jdbc.HiveConnection - Transport Used for JDBC connection: null
[0328 17:24:54 403 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29uty0tmi85t0ga|2e55dd0c]-HelperThread-#0] hive.jdbc.Utils - Supplied authorities: 10.211.55.29:10000
[0328 17:24:54 403 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29uty0tmi85t0ga|2e55dd0c]-HelperThread-#1] hive.jdbc.Utils - Supplied authorities: 10.211.55.29:10000
[0328 17:24:54 403 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29uty0tmi85t0ga|2e55dd0c]-HelperThread-#0] hive.jdbc.Utils - Resolved authority: 10.211.55.29:10000
[0328 17:24:54 403 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29uty0tmi85t0ga|2e55dd0c]-HelperThread-#1] hive.jdbc.Utils - Resolved authority: 10.211.55.29:10000
[0328 17:24:54 404 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29uty0tmi85t0ga|2e55dd0c]-HelperThread-#0] hive.jdbc.HiveConnection - Will try to open client transport with JDBC Uri: jdbc:hive2://10.211.55.29:10000/default
[0328 17:24:54 404 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29uty0tmi85t0ga|2e55dd0c]-HelperThread-#1] hive.jdbc.HiveConnection - Will try to open client transport with JDBC Uri: jdbc:hive2://10.211.55.29:10000/default
[0328 17:24:54 505 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29uty0tmi85t0ga|2e55dd0c]-HelperThread-#0] hive.jdbc.HiveConnection - Could not open client transport with JDBC Uri: jdbc:hive2://10.211.55.29:10000/default
[0328 17:24:54 505 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29uty0tmi85t0ga|2e55dd0c]-HelperThread-#0] hive.jdbc.HiveConnection - Transport Used for JDBC connection: null
[0328 17:24:54 505 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29uty0tmi85t0ga|2e55dd0c]-HelperThread-#1] hive.jdbc.HiveConnection - Could not open client transport with JDBC Uri: jdbc:hive2://10.211.55.29:10000/default
[0328 17:24:54 506 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29uty0tmi85t0ga|2e55dd0c]-HelperThread-#1] hive.jdbc.HiveConnection - Transport Used for JDBC connection: null
[0328 17:24:55 510 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29uty0tmi85t0ga|2e55dd0c]-HelperThread-#1] hive.jdbc.Utils - Supplied authorities: 10.211.55.29:10000
[0328 17:24:55 510 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29uty0tmi85t0ga|2e55dd0c]-HelperThread-#2] hive.jdbc.Utils - Supplied authorities: 10.211.55.29:10000
[0328 17:24:55 510 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29uty0tmi85t0ga|2e55dd0c]-HelperThread-#1] hive.jdbc.Utils - Resolved authority: 10.211.55.29:10000
[0328 17:24:55 510 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29uty0tmi85t0ga|2e55dd0c]-HelperThread-#2] hive.jdbc.Utils - Resolved authority: 10.211.55.29:10000
[0328 17:24:55 510 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29uty0tmi85t0ga|2e55dd0c]-HelperThread-#1] hive.jdbc.HiveConnection - Will try to open client transport with JDBC Uri: jdbc:hive2://10.211.55.29:10000/default
[0328 17:24:55 511 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29uty0tmi85t0ga|2e55dd0c]-HelperThread-#2] hive.jdbc.HiveConnection - Will try to open client transport with JDBC Uri: jdbc:hive2://10.211.55.29:10000/default
[0328 17:24:55 612 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29uty0tmi85t0ga|2e55dd0c]-HelperThread-#2] hive.jdbc.HiveConnection - Could not open client transport with JDBC Uri: jdbc:hive2://10.211.55.29:10000/default
[0328 17:24:55 612 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29uty0tmi85t0ga|2e55dd0c]-HelperThread-#1] hive.jdbc.HiveConnection - Could not open client transport with JDBC Uri: jdbc:hive2://10.211.55.29:10000/default
[0328 17:24:55 612 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29uty0tmi85t0ga|2e55dd0c]-HelperThread-#2] hive.jdbc.HiveConnection - Transport Used for JDBC connection: null
[0328 17:24:55 612 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29uty0tmi85t0ga|2e55dd0c]-HelperThread-#1] hive.jdbc.HiveConnection - Transport Used for JDBC connection: null
[0328 17:24:56 618 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29uty0tmi85t0ga|2e55dd0c]-HelperThread-#1] hive.jdbc.Utils - Supplied authorities: 10.211.55.29:10000
[0328 17:24:56 618 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29uty0tmi85t0ga|2e55dd0c]-HelperThread-#0] hive.jdbc.Utils - Supplied authorities: 10.211.55.29:10000
[0328 17:24:56 618 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29uty0tmi85t0ga|2e55dd0c]-HelperThread-#1] hive.jdbc.Utils - Resolved authority: 10.211.55.29:10000
[0328 17:24:56 618 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29uty0tmi85t0ga|2e55dd0c]-HelperThread-#0] hive.jdbc.Utils - Resolved authority: 10.211.55.29:10000
[0328 17:24:56 620 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29uty0tmi85t0ga|2e55dd0c]-HelperThread-#0] hive.jdbc.HiveConnection - Will try to open client transport with JDBC Uri: jdbc:hive2://10.211.55.29:10000/default
[0328 17:24:56 620 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29uty0tmi85t0ga|2e55dd0c]-HelperThread-#1] hive.jdbc.HiveConnection - Will try to open client transport with JDBC Uri: jdbc:hive2://10.211.55.29:10000/default
[0328 17:24:56 720 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29uty0tmi85t0ga|2e55dd0c]-HelperThread-#0] hive.jdbc.HiveConnection - Could not open client transport with JDBC Uri: jdbc:hive2://10.211.55.29:10000/default
[0328 17:24:56 720 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29uty0tmi85t0ga|2e55dd0c]-HelperThread-#1] hive.jdbc.HiveConnection - Could not open client transport with JDBC Uri: jdbc:hive2://10.211.55.29:10000/default
[0328 17:24:56 720 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29uty0tmi85t0ga|2e55dd0c]-HelperThread-#0] hive.jdbc.HiveConnection - Transport Used for JDBC connection: null
[0328 17:24:56 721 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29uty0tmi85t0ga|2e55dd0c]-HelperThread-#1] hive.jdbc.HiveConnection - Transport Used for JDBC connection: null
[0328 17:24:57 725 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29uty0tmi85t0ga|2e55dd0c]-HelperThread-#0] hive.jdbc.Utils - Supplied authorities: 10.211.55.29:10000
[0328 17:24:57 725 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29uty0tmi85t0ga|2e55dd0c]-HelperThread-#1] hive.jdbc.Utils - Supplied authorities: 10.211.55.29:10000
[0328 17:24:57 726 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29uty0tmi85t0ga|2e55dd0c]-HelperThread-#0] hive.jdbc.Utils - Resolved authority: 10.211.55.29:10000
[0328 17:24:57 726 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29uty0tmi85t0ga|2e55dd0c]-HelperThread-#1] hive.jdbc.Utils - Resolved authority: 10.211.55.29:10000
[0328 17:24:57 727 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29uty0tmi85t0ga|2e55dd0c]-HelperThread-#0] hive.jdbc.HiveConnection - Will try to open client transport with JDBC Uri: jdbc:hive2://10.211.55.29:10000/default
[0328 17:24:57 727 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29uty0tmi85t0ga|2e55dd0c]-HelperThread-#1] hive.jdbc.HiveConnection - Will try to open client transport with JDBC Uri: jdbc:hive2://10.211.55.29:10000/default
[0328 17:24:57 828 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29uty0tmi85t0ga|2e55dd0c]-HelperThread-#1] hive.jdbc.HiveConnection - Could not open client transport with JDBC Uri: jdbc:hive2://10.211.55.29:10000/default
[0328 17:24:57 828 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29uty0tmi85t0ga|2e55dd0c]-HelperThread-#0] hive.jdbc.HiveConnection - Could not open client transport with JDBC Uri: jdbc:hive2://10.211.55.29:10000/default
[0328 17:24:57 829 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29uty0tmi85t0ga|2e55dd0c]-HelperThread-#0] hive.jdbc.HiveConnection - Transport Used for JDBC connection: null
[0328 17:24:57 829 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29uty0tmi85t0ga|2e55dd0c]-HelperThread-#1] hive.jdbc.HiveConnection - Transport Used for JDBC connection: null
[0328 17:24:58 833 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29uty0tmi85t0ga|2e55dd0c]-HelperThread-#1] hive.jdbc.Utils - Supplied authorities: 10.211.55.29:10000
[0328 17:24:58 833 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29uty0tmi85t0ga|2e55dd0c]-HelperThread-#0] hive.jdbc.Utils - Supplied authorities: 10.211.55.29:10000
[0328 17:24:58 834 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29uty0tmi85t0ga|2e55dd0c]-HelperThread-#1] hive.jdbc.Utils - Resolved authority: 10.211.55.29:10000
[0328 17:24:58 834 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29uty0tmi85t0ga|2e55dd0c]-HelperThread-#0] hive.jdbc.Utils - Resolved authority: 10.211.55.29:10000
[0328 17:24:58 834 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29uty0tmi85t0ga|2e55dd0c]-HelperThread-#0] hive.jdbc.HiveConnection - Will try to open client transport with JDBC Uri: jdbc:hive2://10.211.55.29:10000/default
[0328 17:24:58 834 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29uty0tmi85t0ga|2e55dd0c]-HelperThread-#1] hive.jdbc.HiveConnection - Will try to open client transport with JDBC Uri: jdbc:hive2://10.211.55.29:10000/default
[0328 17:24:58 935 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29uty0tmi85t0ga|2e55dd0c]-HelperThread-#0] hive.jdbc.HiveConnection - Could not open client transport with JDBC Uri: jdbc:hive2://10.211.55.29:10000/default
[0328 17:24:58 935 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29uty0tmi85t0ga|2e55dd0c]-HelperThread-#1] hive.jdbc.HiveConnection - Could not open client transport with JDBC Uri: jdbc:hive2://10.211.55.29:10000/default
[0328 17:24:58 935 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29uty0tmi85t0ga|2e55dd0c]-HelperThread-#0] hive.jdbc.HiveConnection - Transport Used for JDBC connection: null
[0328 17:24:58 936 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29uty0tmi85t0ga|2e55dd0c]-HelperThread-#1] hive.jdbc.HiveConnection - Transport Used for JDBC connection: null
[0328 17:24:59 941 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29uty0tmi85t0ga|2e55dd0c]-HelperThread-#1] hive.jdbc.Utils - Supplied authorities: 10.211.55.29:10000
[0328 17:24:59 941 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29uty0tmi85t0ga|2e55dd0c]-HelperThread-#2] hive.jdbc.Utils - Supplied authorities: 10.211.55.29:10000
[0328 17:24:59 942 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29uty0tmi85t0ga|2e55dd0c]-HelperThread-#1] hive.jdbc.Utils - Resolved authority: 10.211.55.29:10000
[0328 17:24:59 942 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29uty0tmi85t0ga|2e55dd0c]-HelperThread-#2] hive.jdbc.Utils - Resolved authority: 10.211.55.29:10000
[0328 17:24:59 943 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29uty0tmi85t0ga|2e55dd0c]-HelperThread-#1] hive.jdbc.HiveConnection - Will try to open client transport with JDBC Uri: jdbc:hive2://10.211.55.29:10000/default
[0328 17:24:59 943 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29uty0tmi85t0ga|2e55dd0c]-HelperThread-#2] hive.jdbc.HiveConnection - Will try to open client transport with JDBC Uri: jdbc:hive2://10.211.55.29:10000/default
[0328 17:25:00 044 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29uty0tmi85t0ga|2e55dd0c]-HelperThread-#2] hive.jdbc.HiveConnection - Could not open client transport with JDBC Uri: jdbc:hive2://10.211.55.29:10000/default
[0328 17:25:00 044 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29uty0tmi85t0ga|2e55dd0c]-HelperThread-#1] hive.jdbc.HiveConnection - Could not open client transport with JDBC Uri: jdbc:hive2://10.211.55.29:10000/default
[0328 17:25:00 044 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29uty0tmi85t0ga|2e55dd0c]-HelperThread-#2] hive.jdbc.HiveConnection - Transport Used for JDBC connection: null
[0328 17:25:00 044 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29uty0tmi85t0ga|2e55dd0c]-HelperThread-#1] hive.jdbc.HiveConnection - Transport Used for JDBC connection: null
[0328 17:25:01 049 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29uty0tmi85t0ga|2e55dd0c]-HelperThread-#1] hive.jdbc.Utils - Supplied authorities: 10.211.55.29:10000
[0328 17:25:01 049 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29uty0tmi85t0ga|2e55dd0c]-HelperThread-#0] hive.jdbc.Utils - Supplied authorities: 10.211.55.29:10000
[0328 17:25:01 049 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29uty0tmi85t0ga|2e55dd0c]-HelperThread-#1] hive.jdbc.Utils - Resolved authority: 10.211.55.29:10000
[0328 17:25:01 049 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29uty0tmi85t0ga|2e55dd0c]-HelperThread-#0] hive.jdbc.Utils - Resolved authority: 10.211.55.29:10000
[0328 17:25:01 050 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29uty0tmi85t0ga|2e55dd0c]-HelperThread-#1] hive.jdbc.HiveConnection - Will try to open client transport with JDBC Uri: jdbc:hive2://10.211.55.29:10000/default
[0328 17:25:01 050 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29uty0tmi85t0ga|2e55dd0c]-HelperThread-#0] hive.jdbc.HiveConnection - Will try to open client transport with JDBC Uri: jdbc:hive2://10.211.55.29:10000/default
[0328 17:25:01 189 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29uty0tmi85t0ga|2e55dd0c]-HelperThread-#1] hive.jdbc.HiveConnection - Could not open client transport with JDBC Uri: jdbc:hive2://10.211.55.29:10000/default
[0328 17:25:01 189 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29uty0tmi85t0ga|2e55dd0c]-HelperThread-#0] hive.jdbc.HiveConnection - Could not open client transport with JDBC Uri: jdbc:hive2://10.211.55.29:10000/default
[0328 17:25:01 189 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29uty0tmi85t0ga|2e55dd0c]-HelperThread-#1] hive.jdbc.HiveConnection - Transport Used for JDBC connection: null
[0328 17:25:01 190 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29uty0tmi85t0ga|2e55dd0c]-HelperThread-#0] hive.jdbc.HiveConnection - Transport Used for JDBC connection: null
[0328 17:25:02 194 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29uty0tmi85t0ga|2e55dd0c]-HelperThread-#0] hive.jdbc.Utils - Supplied authorities: 10.211.55.29:10000
[0328 17:25:02 194 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29uty0tmi85t0ga|2e55dd0c]-HelperThread-#1] hive.jdbc.Utils - Supplied authorities: 10.211.55.29:10000
[0328 17:25:02 195 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29uty0tmi85t0ga|2e55dd0c]-HelperThread-#0] hive.jdbc.Utils - Resolved authority: 10.211.55.29:10000
[0328 17:25:02 195 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29uty0tmi85t0ga|2e55dd0c]-HelperThread-#1] hive.jdbc.Utils - Resolved authority: 10.211.55.29:10000
[0328 17:25:02 195 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29uty0tmi85t0ga|2e55dd0c]-HelperThread-#0] hive.jdbc.HiveConnection - Will try to open client transport with JDBC Uri: jdbc:hive2://10.211.55.29:10000/default
[0328 17:25:02 195 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29uty0tmi85t0ga|2e55dd0c]-HelperThread-#1] hive.jdbc.HiveConnection - Will try to open client transport with JDBC Uri: jdbc:hive2://10.211.55.29:10000/default
[0328 17:25:02 297 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29uty0tmi85t0ga|2e55dd0c]-HelperThread-#0] hive.jdbc.HiveConnection - Could not open client transport with JDBC Uri: jdbc:hive2://10.211.55.29:10000/default
[0328 17:25:02 297 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29uty0tmi85t0ga|2e55dd0c]-HelperThread-#1] hive.jdbc.HiveConnection - Could not open client transport with JDBC Uri: jdbc:hive2://10.211.55.29:10000/default
[0328 17:25:02 297 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29uty0tmi85t0ga|2e55dd0c]-HelperThread-#0] hive.jdbc.HiveConnection - Transport Used for JDBC connection: null
[0328 17:25:02 297 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29uty0tmi85t0ga|2e55dd0c]-HelperThread-#1] hive.jdbc.HiveConnection - Transport Used for JDBC connection: null
[0328 17:25:03 301 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29uty0tmi85t0ga|2e55dd0c]-HelperThread-#1] hive.jdbc.Utils - Supplied authorities: 10.211.55.29:10000
[0328 17:25:03 301 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29uty0tmi85t0ga|2e55dd0c]-HelperThread-#2] hive.jdbc.Utils - Supplied authorities: 10.211.55.29:10000
[0328 17:25:03 302 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29uty0tmi85t0ga|2e55dd0c]-HelperThread-#1] hive.jdbc.Utils - Resolved authority: 10.211.55.29:10000
[0328 17:25:03 302 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29uty0tmi85t0ga|2e55dd0c]-HelperThread-#2] hive.jdbc.Utils - Resolved authority: 10.211.55.29:10000
[0328 17:25:03 302 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29uty0tmi85t0ga|2e55dd0c]-HelperThread-#2] hive.jdbc.HiveConnection - Will try to open client transport with JDBC Uri: jdbc:hive2://10.211.55.29:10000/default
[0328 17:25:03 302 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29uty0tmi85t0ga|2e55dd0c]-HelperThread-#1] hive.jdbc.HiveConnection - Will try to open client transport with JDBC Uri: jdbc:hive2://10.211.55.29:10000/default
[0328 17:25:03 404 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29uty0tmi85t0ga|2e55dd0c]-HelperThread-#2] hive.jdbc.HiveConnection - Could not open client transport with JDBC Uri: jdbc:hive2://10.211.55.29:10000/default
[0328 17:25:03 404 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29uty0tmi85t0ga|2e55dd0c]-HelperThread-#1] hive.jdbc.HiveConnection - Could not open client transport with JDBC Uri: jdbc:hive2://10.211.55.29:10000/default
[0328 17:25:03 404 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29uty0tmi85t0ga|2e55dd0c]-HelperThread-#2] hive.jdbc.HiveConnection - Transport Used for JDBC connection: null
[0328 17:25:03 404 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29uty0tmi85t0ga|2e55dd0c]-HelperThread-#1] hive.jdbc.HiveConnection - Transport Used for JDBC connection: null
[0328 17:25:04 410 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29uty0tmi85t0ga|2e55dd0c]-HelperThread-#1] hive.jdbc.Utils - Supplied authorities: 10.211.55.29:10000
[0328 17:25:04 410 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29uty0tmi85t0ga|2e55dd0c]-HelperThread-#0] hive.jdbc.Utils - Supplied authorities: 10.211.55.29:10000
[0328 17:25:04 410 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29uty0tmi85t0ga|2e55dd0c]-HelperThread-#1] hive.jdbc.Utils - Resolved authority: 10.211.55.29:10000
[0328 17:25:04 410 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29uty0tmi85t0ga|2e55dd0c]-HelperThread-#0] hive.jdbc.Utils - Resolved authority: 10.211.55.29:10000
[0328 17:25:04 411 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29uty0tmi85t0ga|2e55dd0c]-HelperThread-#1] hive.jdbc.HiveConnection - Will try to open client transport with JDBC Uri: jdbc:hive2://10.211.55.29:10000/default
[0328 17:25:04 411 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29uty0tmi85t0ga|2e55dd0c]-HelperThread-#0] hive.jdbc.HiveConnection - Will try to open client transport with JDBC Uri: jdbc:hive2://10.211.55.29:10000/default
[0328 17:25:04 512 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29uty0tmi85t0ga|2e55dd0c]-HelperThread-#1] hive.jdbc.HiveConnection - Could not open client transport with JDBC Uri: jdbc:hive2://10.211.55.29:10000/default
[0328 17:25:04 512 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29uty0tmi85t0ga|2e55dd0c]-HelperThread-#0] hive.jdbc.HiveConnection - Could not open client transport with JDBC Uri: jdbc:hive2://10.211.55.29:10000/default
[0328 17:25:04 512 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29uty0tmi85t0ga|2e55dd0c]-HelperThread-#1] hive.jdbc.HiveConnection - Transport Used for JDBC connection: null
[0328 17:25:04 512 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29uty0tmi85t0ga|2e55dd0c]-HelperThread-#0] hive.jdbc.HiveConnection - Transport Used for JDBC connection: null
[0328 17:25:27 022 INFO ] [MLog-Init-Reporter] v2.log.MLog - MLog clients using slf4j logging.
[0328 17:25:27 408 INFO ] [main] v2.c3p0.C3P0Registry - Initializing c3p0-0.9.5.2 [built 08-December-2015 22:06:04 -0800; debug? true; trace: 10]
[0328 17:25:27 658 INFO ] [main] pmv6.dao.HiveDao - start to execute the sql :insert into test_table_double values (20180329, 010000, 88.38998903338411)
[0328 17:25:27 698 INFO ] [main] c3p0.impl.AbstractPoolBackedDataSource - Initializing c3p0 pool... com.mchange.v2.c3p0.ComboPooledDataSource [ acquireIncrement -> 1, acquireRetryAttempts -> 30, acquireRetryDelay -> 1000, autoCommitOnClose -> false, automaticTestTable -> null, breakAfterAcquireFailure -> false, checkoutTimeout -> 0, connectionCustomizerClassName -> null, connectionTesterClassName -> com.mchange.v2.c3p0.impl.DefaultConnectionTester, contextClassLoaderSource -> caller, dataSourceName -> 1hge0w29uty1ohtdp162j|80ec1f8, debugUnreturnedConnectionStackTraces -> false, description -> null, driverClass -> org.apache.hive.jdbc.HiveDriver, extensions -> {}, factoryClassLocation -> null, forceIgnoreUnresolvedTransactions -> false, forceSynchronousCheckins -> false, forceUseNamedDriverClass -> false, identityToken -> 1hge0w29uty1ohtdp162j|80ec1f8, idleConnectionTestPeriod -> 0, initialPoolSize -> 3, jdbcUrl -> jdbc:hive2://10.211.55.29:10000/default, maxAdministrativeTaskTime -> 0, maxConnectionAge -> 0, maxIdleTime -> 0, maxIdleTimeExcessConnections -> 0, maxPoolSize -> 2, maxStatements -> 0, maxStatementsPerConnection -> 0, minPoolSize -> 1, numHelperThreads -> 3, preferredTestQuery -> null, privilegeSpawnedThreads -> false, properties -> {user=******, password=******}, propertyCycle -> 0, statementCacheNumDeferredCloseThreads -> 0, testConnectionOnCheckin -> false, testConnectionOnCheckout -> false, unreturnedConnectionTimeout -> 0, userOverrides -> {}, usesTraditionalReflectiveProxies -> false ]
[0328 17:25:27 737 WARN ] [main] v2.resourcepool.BasicResourcePool - Bad pool size config, start 3 > max 2. Using 2 as start.
[0328 17:25:27 760 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29uty1ohtdp162j|80ec1f8]-HelperThread-#1] hive.jdbc.Utils - Supplied authorities: 10.211.55.29:10000
[0328 17:25:27 760 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29uty1ohtdp162j|80ec1f8]-HelperThread-#2] hive.jdbc.Utils - Supplied authorities: 10.211.55.29:10000
[0328 17:25:27 760 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29uty1ohtdp162j|80ec1f8]-HelperThread-#2] hive.jdbc.Utils - Resolved authority: 10.211.55.29:10000
[0328 17:25:27 760 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29uty1ohtdp162j|80ec1f8]-HelperThread-#1] hive.jdbc.Utils - Resolved authority: 10.211.55.29:10000
[0328 17:25:27 831 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29uty1ohtdp162j|80ec1f8]-HelperThread-#2] hive.jdbc.HiveConnection - Will try to open client transport with JDBC Uri: jdbc:hive2://10.211.55.29:10000/default
[0328 17:25:27 831 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29uty1ohtdp162j|80ec1f8]-HelperThread-#1] hive.jdbc.HiveConnection - Will try to open client transport with JDBC Uri: jdbc:hive2://10.211.55.29:10000/default
[0328 17:25:27 934 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29uty1ohtdp162j|80ec1f8]-HelperThread-#2] hive.jdbc.HiveConnection - Could not open client transport with JDBC Uri: jdbc:hive2://10.211.55.29:10000/default
[0328 17:25:27 935 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29uty1ohtdp162j|80ec1f8]-HelperThread-#1] hive.jdbc.HiveConnection - Could not open client transport with JDBC Uri: jdbc:hive2://10.211.55.29:10000/default
[0328 17:25:27 935 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29uty1ohtdp162j|80ec1f8]-HelperThread-#2] hive.jdbc.HiveConnection - Transport Used for JDBC connection: null
[0328 17:25:27 935 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29uty1ohtdp162j|80ec1f8]-HelperThread-#1] hive.jdbc.HiveConnection - Transport Used for JDBC connection: null
[0328 17:25:28 940 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29uty1ohtdp162j|80ec1f8]-HelperThread-#1] hive.jdbc.Utils - Supplied authorities: 10.211.55.29:10000
[0328 17:25:28 940 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29uty1ohtdp162j|80ec1f8]-HelperThread-#2] hive.jdbc.Utils - Supplied authorities: 10.211.55.29:10000
[0328 17:25:28 940 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29uty1ohtdp162j|80ec1f8]-HelperThread-#1] hive.jdbc.Utils - Resolved authority: 10.211.55.29:10000
[0328 17:25:28 940 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29uty1ohtdp162j|80ec1f8]-HelperThread-#2] hive.jdbc.Utils - Resolved authority: 10.211.55.29:10000
[0328 17:25:28 941 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29uty1ohtdp162j|80ec1f8]-HelperThread-#1] hive.jdbc.HiveConnection - Will try to open client transport with JDBC Uri: jdbc:hive2://10.211.55.29:10000/default
[0328 17:25:28 941 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29uty1ohtdp162j|80ec1f8]-HelperThread-#2] hive.jdbc.HiveConnection - Will try to open client transport with JDBC Uri: jdbc:hive2://10.211.55.29:10000/default
[0328 17:25:29 041 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29uty1ohtdp162j|80ec1f8]-HelperThread-#2] hive.jdbc.HiveConnection - Could not open client transport with JDBC Uri: jdbc:hive2://10.211.55.29:10000/default
[0328 17:25:29 041 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29uty1ohtdp162j|80ec1f8]-HelperThread-#1] hive.jdbc.HiveConnection - Could not open client transport with JDBC Uri: jdbc:hive2://10.211.55.29:10000/default
[0328 17:25:29 042 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29uty1ohtdp162j|80ec1f8]-HelperThread-#1] hive.jdbc.HiveConnection - Transport Used for JDBC connection: null
[0328 17:25:29 042 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29uty1ohtdp162j|80ec1f8]-HelperThread-#2] hive.jdbc.HiveConnection - Transport Used for JDBC connection: null
[0328 17:25:30 045 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29uty1ohtdp162j|80ec1f8]-HelperThread-#2] hive.jdbc.Utils - Supplied authorities: 10.211.55.29:10000
[0328 17:25:30 045 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29uty1ohtdp162j|80ec1f8]-HelperThread-#1] hive.jdbc.Utils - Supplied authorities: 10.211.55.29:10000
[0328 17:25:30 046 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29uty1ohtdp162j|80ec1f8]-HelperThread-#2] hive.jdbc.Utils - Resolved authority: 10.211.55.29:10000
[0328 17:25:30 046 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29uty1ohtdp162j|80ec1f8]-HelperThread-#1] hive.jdbc.Utils - Resolved authority: 10.211.55.29:10000
[0328 17:25:30 047 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29uty1ohtdp162j|80ec1f8]-HelperThread-#2] hive.jdbc.HiveConnection - Will try to open client transport with JDBC Uri: jdbc:hive2://10.211.55.29:10000/default
[0328 17:25:30 047 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29uty1ohtdp162j|80ec1f8]-HelperThread-#1] hive.jdbc.HiveConnection - Will try to open client transport with JDBC Uri: jdbc:hive2://10.211.55.29:10000/default
[0328 17:25:32 968 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29uty1ohtdp162j|80ec1f8]-HelperThread-#2] hive.jdbc.Utils - Supplied authorities: 10.211.55.29:10000
[0328 17:25:32 968 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29uty1ohtdp162j|80ec1f8]-HelperThread-#2] hive.jdbc.Utils - Resolved authority: 10.211.55.29:10000
[0328 17:25:32 969 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29uty1ohtdp162j|80ec1f8]-HelperThread-#2] hive.jdbc.HiveConnection - Will try to open client transport with JDBC Uri: jdbc:hive2://10.211.55.29:10000/default
[0328 17:25:32 969 ERROR] [main] pmv6.dao.HiveDao - ERROR SQL: insert into test_table_double values (20180329, 010000, 88.38998903338411)
[0328 17:25:32 970 ERROR] [main] pmv6.dao.HiveDao - java.lang.RuntimeException: Cannot create staging directory 'hdfs://localhost:9000/home/hive/warehouse/test_table_double/.hive-staging_hive_2018-03-28_02-25-32_774_5343360943625609490-1': Permission denied: user=hive, access=WRITE, inode="/home/hive/warehouse/test_table_double":chen:supergroup:drwxr-xr-x
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.check(FSPermissionChecker.java:308)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:214)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:190)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkPermission(FSDirectory.java:1752)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkPermission(FSDirectory.java:1736)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkAncestorAccess(FSDirectory.java:1719)
	at org.apache.hadoop.hdfs.server.namenode.FSDirMkdirOp.mkdirs(FSDirMkdirOp.java:69)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.mkdirs(FSNamesystem.java:3867)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.mkdirs(NameNodeRpcServer.java:984)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.mkdirs(ClientNamenodeProtocolServerSideTranslatorPB.java:634)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:616)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:982)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2217)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2213)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1754)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2213)

java.sql.SQLException: java.lang.RuntimeException: Cannot create staging directory 'hdfs://localhost:9000/home/hive/warehouse/test_table_double/.hive-staging_hive_2018-03-28_02-25-32_774_5343360943625609490-1': Permission denied: user=hive, access=WRITE, inode="/home/hive/warehouse/test_table_double":chen:supergroup:drwxr-xr-x
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.check(FSPermissionChecker.java:308)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:214)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:190)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkPermission(FSDirectory.java:1752)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkPermission(FSDirectory.java:1736)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkAncestorAccess(FSDirectory.java:1719)
	at org.apache.hadoop.hdfs.server.namenode.FSDirMkdirOp.mkdirs(FSDirMkdirOp.java:69)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.mkdirs(FSNamesystem.java:3867)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.mkdirs(NameNodeRpcServer.java:984)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.mkdirs(ClientNamenodeProtocolServerSideTranslatorPB.java:634)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:616)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:982)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2217)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2213)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1754)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2213)

	at org.apache.hive.jdbc.HiveStatement.execute(HiveStatement.java:296)
	at org.apache.hive.jdbc.HivePreparedStatement.execute(HivePreparedStatement.java:98)
	at com.mchange.v2.c3p0.impl.NewProxyPreparedStatement.execute(NewProxyPreparedStatement.java:67)
	at com.inspur.pmv6.dao.HiveDao.executesql(HiveDao.java:152)
	at com.inspur.pmv6.Entrance.lambda$null$0(Entrance.java:83)
	at java.util.stream.Streams$RangeIntSpliterator.forEachRemaining(Streams.java:110)
	at java.util.stream.IntPipeline$Head.forEach(IntPipeline.java:557)
	at com.inspur.pmv6.Entrance.lambda$myTestCodes$1(Entrance.java:76)
	at java.util.stream.Streams$RangeIntSpliterator.forEachRemaining(Streams.java:110)
	at java.util.stream.IntPipeline$Head.forEach(IntPipeline.java:557)
	at com.inspur.pmv6.Entrance.myTestCodes(Entrance.java:74)
	at com.inspur.pmv6.Entrance.main(Entrance.java:43)
[0328 17:25:33 019 INFO ] [main] pmv6.dao.HiveDao - start to execute the sql :insert into test_table_double values (20180329, 020000, 76.07421965055366)
[0328 17:25:33 205 ERROR] [main] pmv6.dao.HiveDao - ERROR SQL: insert into test_table_double values (20180329, 020000, 76.07421965055366)
[0328 17:25:33 206 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29uty1ohtdp162j|80ec1f8]-HelperThread-#0] hive.jdbc.Utils - Supplied authorities: 10.211.55.29:10000
[0328 17:25:33 206 ERROR] [main] pmv6.dao.HiveDao - java.lang.RuntimeException: Cannot create staging directory 'hdfs://localhost:9000/home/hive/warehouse/test_table_double/.hive-staging_hive_2018-03-28_02-25-33_109_142461815778386932-2': Permission denied: user=hive, access=WRITE, inode="/home/hive/warehouse/test_table_double":chen:supergroup:drwxr-xr-x
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.check(FSPermissionChecker.java:308)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:214)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:190)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkPermission(FSDirectory.java:1752)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkPermission(FSDirectory.java:1736)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkAncestorAccess(FSDirectory.java:1719)
	at org.apache.hadoop.hdfs.server.namenode.FSDirMkdirOp.mkdirs(FSDirMkdirOp.java:69)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.mkdirs(FSNamesystem.java:3867)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.mkdirs(NameNodeRpcServer.java:984)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.mkdirs(ClientNamenodeProtocolServerSideTranslatorPB.java:634)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:616)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:982)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2217)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2213)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1754)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2213)

java.sql.SQLException: java.lang.RuntimeException: Cannot create staging directory 'hdfs://localhost:9000/home/hive/warehouse/test_table_double/.hive-staging_hive_2018-03-28_02-25-33_109_142461815778386932-2': Permission denied: user=hive, access=WRITE, inode="/home/hive/warehouse/test_table_double":chen:supergroup:drwxr-xr-x
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.check(FSPermissionChecker.java:308)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:214)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:190)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkPermission(FSDirectory.java:1752)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkPermission(FSDirectory.java:1736)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkAncestorAccess(FSDirectory.java:1719)
	at org.apache.hadoop.hdfs.server.namenode.FSDirMkdirOp.mkdirs(FSDirMkdirOp.java:69)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.mkdirs(FSNamesystem.java:3867)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.mkdirs(NameNodeRpcServer.java:984)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.mkdirs(ClientNamenodeProtocolServerSideTranslatorPB.java:634)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:616)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:982)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2217)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2213)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1754)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2213)

	at org.apache.hive.jdbc.HiveStatement.execute(HiveStatement.java:296)
	at org.apache.hive.jdbc.HivePreparedStatement.execute(HivePreparedStatement.java:98)
	at com.mchange.v2.c3p0.impl.NewProxyPreparedStatement.execute(NewProxyPreparedStatement.java:67)
	at com.inspur.pmv6.dao.HiveDao.executesql(HiveDao.java:152)
	at com.inspur.pmv6.Entrance.lambda$null$0(Entrance.java:83)
	at java.util.stream.Streams$RangeIntSpliterator.forEachRemaining(Streams.java:110)
	at java.util.stream.IntPipeline$Head.forEach(IntPipeline.java:557)
	at com.inspur.pmv6.Entrance.lambda$myTestCodes$1(Entrance.java:76)
	at java.util.stream.Streams$RangeIntSpliterator.forEachRemaining(Streams.java:110)
	at java.util.stream.IntPipeline$Head.forEach(IntPipeline.java:557)
	at com.inspur.pmv6.Entrance.myTestCodes(Entrance.java:74)
	at com.inspur.pmv6.Entrance.main(Entrance.java:43)
[0328 17:25:33 206 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29uty1ohtdp162j|80ec1f8]-HelperThread-#0] hive.jdbc.Utils - Resolved authority: 10.211.55.29:10000
[0328 17:25:33 208 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29uty1ohtdp162j|80ec1f8]-HelperThread-#0] hive.jdbc.HiveConnection - Will try to open client transport with JDBC Uri: jdbc:hive2://10.211.55.29:10000/default
[0328 17:25:33 208 INFO ] [main] pmv6.dao.HiveDao - start to execute the sql :insert into test_table_double values (20180329, 030000, 35.26064269160412)
[0328 17:25:33 459 ERROR] [main] pmv6.dao.HiveDao - ERROR SQL: insert into test_table_double values (20180329, 030000, 35.26064269160412)
[0328 17:25:33 459 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29uty1ohtdp162j|80ec1f8]-HelperThread-#2] hive.jdbc.Utils - Supplied authorities: 10.211.55.29:10000
[0328 17:25:33 459 ERROR] [main] pmv6.dao.HiveDao - java.lang.RuntimeException: Cannot create staging directory 'hdfs://localhost:9000/home/hive/warehouse/test_table_double/.hive-staging_hive_2018-03-28_02-25-33_354_6508928743105747014-3': Permission denied: user=hive, access=WRITE, inode="/home/hive/warehouse/test_table_double":chen:supergroup:drwxr-xr-x
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.check(FSPermissionChecker.java:308)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:214)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:190)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkPermission(FSDirectory.java:1752)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkPermission(FSDirectory.java:1736)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkAncestorAccess(FSDirectory.java:1719)
	at org.apache.hadoop.hdfs.server.namenode.FSDirMkdirOp.mkdirs(FSDirMkdirOp.java:69)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.mkdirs(FSNamesystem.java:3867)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.mkdirs(NameNodeRpcServer.java:984)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.mkdirs(ClientNamenodeProtocolServerSideTranslatorPB.java:634)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:616)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:982)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2217)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2213)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1754)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2213)

java.sql.SQLException: java.lang.RuntimeException: Cannot create staging directory 'hdfs://localhost:9000/home/hive/warehouse/test_table_double/.hive-staging_hive_2018-03-28_02-25-33_354_6508928743105747014-3': Permission denied: user=hive, access=WRITE, inode="/home/hive/warehouse/test_table_double":chen:supergroup:drwxr-xr-x
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.check(FSPermissionChecker.java:308)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:214)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:190)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkPermission(FSDirectory.java:1752)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkPermission(FSDirectory.java:1736)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkAncestorAccess(FSDirectory.java:1719)
	at org.apache.hadoop.hdfs.server.namenode.FSDirMkdirOp.mkdirs(FSDirMkdirOp.java:69)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.mkdirs(FSNamesystem.java:3867)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.mkdirs(NameNodeRpcServer.java:984)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.mkdirs(ClientNamenodeProtocolServerSideTranslatorPB.java:634)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:616)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:982)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2217)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2213)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1754)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2213)

	at org.apache.hive.jdbc.HiveStatement.execute(HiveStatement.java:296)
	at org.apache.hive.jdbc.HivePreparedStatement.execute(HivePreparedStatement.java:98)
	at com.mchange.v2.c3p0.impl.NewProxyPreparedStatement.execute(NewProxyPreparedStatement.java:67)
	at com.inspur.pmv6.dao.HiveDao.executesql(HiveDao.java:152)
	at com.inspur.pmv6.Entrance.lambda$null$0(Entrance.java:83)
	at java.util.stream.Streams$RangeIntSpliterator.forEachRemaining(Streams.java:110)
	at java.util.stream.IntPipeline$Head.forEach(IntPipeline.java:557)
	at com.inspur.pmv6.Entrance.lambda$myTestCodes$1(Entrance.java:76)
	at java.util.stream.Streams$RangeIntSpliterator.forEachRemaining(Streams.java:110)
	at java.util.stream.IntPipeline$Head.forEach(IntPipeline.java:557)
	at com.inspur.pmv6.Entrance.myTestCodes(Entrance.java:74)
	at com.inspur.pmv6.Entrance.main(Entrance.java:43)
[0328 17:25:33 459 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29uty1ohtdp162j|80ec1f8]-HelperThread-#2] hive.jdbc.Utils - Resolved authority: 10.211.55.29:10000
[0328 17:25:33 461 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29uty1ohtdp162j|80ec1f8]-HelperThread-#2] hive.jdbc.HiveConnection - Will try to open client transport with JDBC Uri: jdbc:hive2://10.211.55.29:10000/default
[0328 17:25:33 461 INFO ] [main] pmv6.dao.HiveDao - start to execute the sql :insert into test_table_double values (20180329, 040000, 98.59081656028279)
[0328 17:25:33 809 ERROR] [main] pmv6.dao.HiveDao - ERROR SQL: insert into test_table_double values (20180329, 040000, 98.59081656028279)
[0328 17:25:33 810 ERROR] [main] pmv6.dao.HiveDao - java.lang.RuntimeException: Cannot create staging directory 'hdfs://localhost:9000/home/hive/warehouse/test_table_double/.hive-staging_hive_2018-03-28_02-25-33_710_1682697040834041290-4': Permission denied: user=hive, access=WRITE, inode="/home/hive/warehouse/test_table_double":chen:supergroup:drwxr-xr-x
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.check(FSPermissionChecker.java:308)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:214)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:190)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkPermission(FSDirectory.java:1752)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkPermission(FSDirectory.java:1736)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkAncestorAccess(FSDirectory.java:1719)
	at org.apache.hadoop.hdfs.server.namenode.FSDirMkdirOp.mkdirs(FSDirMkdirOp.java:69)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.mkdirs(FSNamesystem.java:3867)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.mkdirs(NameNodeRpcServer.java:984)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.mkdirs(ClientNamenodeProtocolServerSideTranslatorPB.java:634)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:616)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:982)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2217)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2213)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1754)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2213)

java.sql.SQLException: java.lang.RuntimeException: Cannot create staging directory 'hdfs://localhost:9000/home/hive/warehouse/test_table_double/.hive-staging_hive_2018-03-28_02-25-33_710_1682697040834041290-4': Permission denied: user=hive, access=WRITE, inode="/home/hive/warehouse/test_table_double":chen:supergroup:drwxr-xr-x
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.check(FSPermissionChecker.java:308)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:214)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:190)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkPermission(FSDirectory.java:1752)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkPermission(FSDirectory.java:1736)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkAncestorAccess(FSDirectory.java:1719)
	at org.apache.hadoop.hdfs.server.namenode.FSDirMkdirOp.mkdirs(FSDirMkdirOp.java:69)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.mkdirs(FSNamesystem.java:3867)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.mkdirs(NameNodeRpcServer.java:984)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.mkdirs(ClientNamenodeProtocolServerSideTranslatorPB.java:634)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:616)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:982)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2217)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2213)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1754)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2213)

	at org.apache.hive.jdbc.HiveStatement.execute(HiveStatement.java:296)
	at org.apache.hive.jdbc.HivePreparedStatement.execute(HivePreparedStatement.java:98)
	at com.mchange.v2.c3p0.impl.NewProxyPreparedStatement.execute(NewProxyPreparedStatement.java:67)
	at com.inspur.pmv6.dao.HiveDao.executesql(HiveDao.java:152)
	at com.inspur.pmv6.Entrance.lambda$null$0(Entrance.java:83)
	at java.util.stream.Streams$RangeIntSpliterator.forEachRemaining(Streams.java:110)
	at java.util.stream.IntPipeline$Head.forEach(IntPipeline.java:557)
	at com.inspur.pmv6.Entrance.lambda$myTestCodes$1(Entrance.java:76)
	at java.util.stream.Streams$RangeIntSpliterator.forEachRemaining(Streams.java:110)
	at java.util.stream.IntPipeline$Head.forEach(IntPipeline.java:557)
	at com.inspur.pmv6.Entrance.myTestCodes(Entrance.java:74)
	at com.inspur.pmv6.Entrance.main(Entrance.java:43)
[0328 17:25:33 810 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29uty1ohtdp162j|80ec1f8]-HelperThread-#2] hive.jdbc.Utils - Supplied authorities: 10.211.55.29:10000
[0328 17:25:33 812 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29uty1ohtdp162j|80ec1f8]-HelperThread-#2] hive.jdbc.Utils - Resolved authority: 10.211.55.29:10000
[0328 17:25:33 813 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29uty1ohtdp162j|80ec1f8]-HelperThread-#2] hive.jdbc.HiveConnection - Will try to open client transport with JDBC Uri: jdbc:hive2://10.211.55.29:10000/default
[0328 17:25:33 821 INFO ] [main] pmv6.dao.HiveDao - start to execute the sql :insert into test_table_double values (20180329, 050000, 28.228453784942296)
[0328 17:25:33 949 ERROR] [main] pmv6.dao.HiveDao - ERROR SQL: insert into test_table_double values (20180329, 050000, 28.228453784942296)
[0328 17:25:33 949 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29uty1ohtdp162j|80ec1f8]-HelperThread-#1] hive.jdbc.Utils - Supplied authorities: 10.211.55.29:10000
[0328 17:25:33 949 ERROR] [main] pmv6.dao.HiveDao - java.lang.RuntimeException: Cannot create staging directory 'hdfs://localhost:9000/home/hive/warehouse/test_table_double/.hive-staging_hive_2018-03-28_02-25-33_868_6822296386242256498-5': Permission denied: user=hive, access=WRITE, inode="/home/hive/warehouse/test_table_double":chen:supergroup:drwxr-xr-x
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.check(FSPermissionChecker.java:308)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:214)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:190)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkPermission(FSDirectory.java:1752)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkPermission(FSDirectory.java:1736)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkAncestorAccess(FSDirectory.java:1719)
	at org.apache.hadoop.hdfs.server.namenode.FSDirMkdirOp.mkdirs(FSDirMkdirOp.java:69)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.mkdirs(FSNamesystem.java:3867)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.mkdirs(NameNodeRpcServer.java:984)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.mkdirs(ClientNamenodeProtocolServerSideTranslatorPB.java:634)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:616)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:982)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2217)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2213)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1754)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2213)

java.sql.SQLException: java.lang.RuntimeException: Cannot create staging directory 'hdfs://localhost:9000/home/hive/warehouse/test_table_double/.hive-staging_hive_2018-03-28_02-25-33_868_6822296386242256498-5': Permission denied: user=hive, access=WRITE, inode="/home/hive/warehouse/test_table_double":chen:supergroup:drwxr-xr-x
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.check(FSPermissionChecker.java:308)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:214)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:190)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkPermission(FSDirectory.java:1752)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkPermission(FSDirectory.java:1736)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkAncestorAccess(FSDirectory.java:1719)
	at org.apache.hadoop.hdfs.server.namenode.FSDirMkdirOp.mkdirs(FSDirMkdirOp.java:69)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.mkdirs(FSNamesystem.java:3867)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.mkdirs(NameNodeRpcServer.java:984)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.mkdirs(ClientNamenodeProtocolServerSideTranslatorPB.java:634)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:616)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:982)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2217)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2213)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1754)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2213)

	at org.apache.hive.jdbc.HiveStatement.execute(HiveStatement.java:296)
	at org.apache.hive.jdbc.HivePreparedStatement.execute(HivePreparedStatement.java:98)
	at com.mchange.v2.c3p0.impl.NewProxyPreparedStatement.execute(NewProxyPreparedStatement.java:67)
	at com.inspur.pmv6.dao.HiveDao.executesql(HiveDao.java:152)
	at com.inspur.pmv6.Entrance.lambda$null$0(Entrance.java:83)
	at java.util.stream.Streams$RangeIntSpliterator.forEachRemaining(Streams.java:110)
	at java.util.stream.IntPipeline$Head.forEach(IntPipeline.java:557)
	at com.inspur.pmv6.Entrance.lambda$myTestCodes$1(Entrance.java:76)
	at java.util.stream.Streams$RangeIntSpliterator.forEachRemaining(Streams.java:110)
	at java.util.stream.IntPipeline$Head.forEach(IntPipeline.java:557)
	at com.inspur.pmv6.Entrance.myTestCodes(Entrance.java:74)
	at com.inspur.pmv6.Entrance.main(Entrance.java:43)
[0328 17:25:33 949 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29uty1ohtdp162j|80ec1f8]-HelperThread-#1] hive.jdbc.Utils - Resolved authority: 10.211.55.29:10000
[0328 17:25:33 950 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29uty1ohtdp162j|80ec1f8]-HelperThread-#1] hive.jdbc.HiveConnection - Will try to open client transport with JDBC Uri: jdbc:hive2://10.211.55.29:10000/default
[0328 17:25:33 951 INFO ] [main] pmv6.dao.HiveDao - start to execute the sql :insert into test_table_double values (20180329, 060000, 37.97751371782868)
[0328 17:25:34 314 ERROR] [main] pmv6.dao.HiveDao - ERROR SQL: insert into test_table_double values (20180329, 060000, 37.97751371782868)
[0328 17:25:34 314 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29uty1ohtdp162j|80ec1f8]-HelperThread-#2] hive.jdbc.Utils - Supplied authorities: 10.211.55.29:10000
[0328 17:25:34 314 ERROR] [main] pmv6.dao.HiveDao - java.lang.RuntimeException: Cannot create staging directory 'hdfs://localhost:9000/home/hive/warehouse/test_table_double/.hive-staging_hive_2018-03-28_02-25-34_230_2684855297041279002-6': Permission denied: user=hive, access=WRITE, inode="/home/hive/warehouse/test_table_double":chen:supergroup:drwxr-xr-x
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.check(FSPermissionChecker.java:308)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:214)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:190)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkPermission(FSDirectory.java:1752)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkPermission(FSDirectory.java:1736)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkAncestorAccess(FSDirectory.java:1719)
	at org.apache.hadoop.hdfs.server.namenode.FSDirMkdirOp.mkdirs(FSDirMkdirOp.java:69)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.mkdirs(FSNamesystem.java:3867)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.mkdirs(NameNodeRpcServer.java:984)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.mkdirs(ClientNamenodeProtocolServerSideTranslatorPB.java:634)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:616)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:982)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2217)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2213)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1754)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2213)

java.sql.SQLException: java.lang.RuntimeException: Cannot create staging directory 'hdfs://localhost:9000/home/hive/warehouse/test_table_double/.hive-staging_hive_2018-03-28_02-25-34_230_2684855297041279002-6': Permission denied: user=hive, access=WRITE, inode="/home/hive/warehouse/test_table_double":chen:supergroup:drwxr-xr-x
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.check(FSPermissionChecker.java:308)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:214)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:190)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkPermission(FSDirectory.java:1752)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkPermission(FSDirectory.java:1736)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkAncestorAccess(FSDirectory.java:1719)
	at org.apache.hadoop.hdfs.server.namenode.FSDirMkdirOp.mkdirs(FSDirMkdirOp.java:69)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.mkdirs(FSNamesystem.java:3867)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.mkdirs(NameNodeRpcServer.java:984)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.mkdirs(ClientNamenodeProtocolServerSideTranslatorPB.java:634)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:616)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:982)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2217)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2213)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1754)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2213)

	at org.apache.hive.jdbc.HiveStatement.execute(HiveStatement.java:296)
	at org.apache.hive.jdbc.HivePreparedStatement.execute(HivePreparedStatement.java:98)
	at com.mchange.v2.c3p0.impl.NewProxyPreparedStatement.execute(NewProxyPreparedStatement.java:67)
	at com.inspur.pmv6.dao.HiveDao.executesql(HiveDao.java:152)
	at com.inspur.pmv6.Entrance.lambda$null$0(Entrance.java:83)
	at java.util.stream.Streams$RangeIntSpliterator.forEachRemaining(Streams.java:110)
	at java.util.stream.IntPipeline$Head.forEach(IntPipeline.java:557)
	at com.inspur.pmv6.Entrance.lambda$myTestCodes$1(Entrance.java:76)
	at java.util.stream.Streams$RangeIntSpliterator.forEachRemaining(Streams.java:110)
	at java.util.stream.IntPipeline$Head.forEach(IntPipeline.java:557)
	at com.inspur.pmv6.Entrance.myTestCodes(Entrance.java:74)
	at com.inspur.pmv6.Entrance.main(Entrance.java:43)
[0328 17:25:34 314 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29uty1ohtdp162j|80ec1f8]-HelperThread-#2] hive.jdbc.Utils - Resolved authority: 10.211.55.29:10000
[0328 17:25:34 316 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29uty1ohtdp162j|80ec1f8]-HelperThread-#2] hive.jdbc.HiveConnection - Will try to open client transport with JDBC Uri: jdbc:hive2://10.211.55.29:10000/default
[0328 17:25:34 317 INFO ] [main] pmv6.dao.HiveDao - start to execute the sql :insert into test_table_double values (20180329, 070000, 53.0686217604072)
[0328 17:25:34 451 ERROR] [main] pmv6.dao.HiveDao - ERROR SQL: insert into test_table_double values (20180329, 070000, 53.0686217604072)
[0328 17:25:34 451 ERROR] [main] pmv6.dao.HiveDao - java.lang.RuntimeException: Cannot create staging directory 'hdfs://localhost:9000/home/hive/warehouse/test_table_double/.hive-staging_hive_2018-03-28_02-25-34_359_3180633909815557198-7': Permission denied: user=hive, access=WRITE, inode="/home/hive/warehouse/test_table_double":chen:supergroup:drwxr-xr-x
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.check(FSPermissionChecker.java:308)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:214)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:190)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkPermission(FSDirectory.java:1752)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkPermission(FSDirectory.java:1736)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkAncestorAccess(FSDirectory.java:1719)
	at org.apache.hadoop.hdfs.server.namenode.FSDirMkdirOp.mkdirs(FSDirMkdirOp.java:69)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.mkdirs(FSNamesystem.java:3867)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.mkdirs(NameNodeRpcServer.java:984)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.mkdirs(ClientNamenodeProtocolServerSideTranslatorPB.java:634)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:616)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:982)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2217)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2213)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1754)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2213)

java.sql.SQLException: java.lang.RuntimeException: Cannot create staging directory 'hdfs://localhost:9000/home/hive/warehouse/test_table_double/.hive-staging_hive_2018-03-28_02-25-34_359_3180633909815557198-7': Permission denied: user=hive, access=WRITE, inode="/home/hive/warehouse/test_table_double":chen:supergroup:drwxr-xr-x
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.check(FSPermissionChecker.java:308)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:214)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:190)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkPermission(FSDirectory.java:1752)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkPermission(FSDirectory.java:1736)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkAncestorAccess(FSDirectory.java:1719)
	at org.apache.hadoop.hdfs.server.namenode.FSDirMkdirOp.mkdirs(FSDirMkdirOp.java:69)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.mkdirs(FSNamesystem.java:3867)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.mkdirs(NameNodeRpcServer.java:984)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.mkdirs(ClientNamenodeProtocolServerSideTranslatorPB.java:634)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:616)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:982)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2217)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2213)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1754)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2213)

	at org.apache.hive.jdbc.HiveStatement.execute(HiveStatement.java:296)
	at org.apache.hive.jdbc.HivePreparedStatement.execute(HivePreparedStatement.java:98)
	at com.mchange.v2.c3p0.impl.NewProxyPreparedStatement.execute(NewProxyPreparedStatement.java:67)
	at com.inspur.pmv6.dao.HiveDao.executesql(HiveDao.java:152)
	at com.inspur.pmv6.Entrance.lambda$null$0(Entrance.java:83)
	at java.util.stream.Streams$RangeIntSpliterator.forEachRemaining(Streams.java:110)
	at java.util.stream.IntPipeline$Head.forEach(IntPipeline.java:557)
	at com.inspur.pmv6.Entrance.lambda$myTestCodes$1(Entrance.java:76)
	at java.util.stream.Streams$RangeIntSpliterator.forEachRemaining(Streams.java:110)
	at java.util.stream.IntPipeline$Head.forEach(IntPipeline.java:557)
	at com.inspur.pmv6.Entrance.myTestCodes(Entrance.java:74)
	at com.inspur.pmv6.Entrance.main(Entrance.java:43)
[0328 17:25:34 451 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29uty1ohtdp162j|80ec1f8]-HelperThread-#0] hive.jdbc.Utils - Supplied authorities: 10.211.55.29:10000
[0328 17:25:34 452 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29uty1ohtdp162j|80ec1f8]-HelperThread-#0] hive.jdbc.Utils - Resolved authority: 10.211.55.29:10000
[0328 17:25:34 453 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29uty1ohtdp162j|80ec1f8]-HelperThread-#0] hive.jdbc.HiveConnection - Will try to open client transport with JDBC Uri: jdbc:hive2://10.211.55.29:10000/default
[0328 17:25:34 453 INFO ] [main] pmv6.dao.HiveDao - start to execute the sql :insert into test_table_double values (20180329, 080000, 3.7678911672682447)
[0328 17:25:34 782 ERROR] [main] pmv6.dao.HiveDao - ERROR SQL: insert into test_table_double values (20180329, 080000, 3.7678911672682447)
[0328 17:25:34 782 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29uty1ohtdp162j|80ec1f8]-HelperThread-#0] hive.jdbc.Utils - Supplied authorities: 10.211.55.29:10000
[0328 17:25:34 782 ERROR] [main] pmv6.dao.HiveDao - java.lang.RuntimeException: Cannot create staging directory 'hdfs://localhost:9000/home/hive/warehouse/test_table_double/.hive-staging_hive_2018-03-28_02-25-34_694_3242940139706024424-8': Permission denied: user=hive, access=WRITE, inode="/home/hive/warehouse/test_table_double":chen:supergroup:drwxr-xr-x
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.check(FSPermissionChecker.java:308)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:214)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:190)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkPermission(FSDirectory.java:1752)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkPermission(FSDirectory.java:1736)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkAncestorAccess(FSDirectory.java:1719)
	at org.apache.hadoop.hdfs.server.namenode.FSDirMkdirOp.mkdirs(FSDirMkdirOp.java:69)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.mkdirs(FSNamesystem.java:3867)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.mkdirs(NameNodeRpcServer.java:984)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.mkdirs(ClientNamenodeProtocolServerSideTranslatorPB.java:634)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:616)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:982)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2217)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2213)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1754)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2213)

java.sql.SQLException: java.lang.RuntimeException: Cannot create staging directory 'hdfs://localhost:9000/home/hive/warehouse/test_table_double/.hive-staging_hive_2018-03-28_02-25-34_694_3242940139706024424-8': Permission denied: user=hive, access=WRITE, inode="/home/hive/warehouse/test_table_double":chen:supergroup:drwxr-xr-x
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.check(FSPermissionChecker.java:308)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:214)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:190)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkPermission(FSDirectory.java:1752)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkPermission(FSDirectory.java:1736)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkAncestorAccess(FSDirectory.java:1719)
	at org.apache.hadoop.hdfs.server.namenode.FSDirMkdirOp.mkdirs(FSDirMkdirOp.java:69)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.mkdirs(FSNamesystem.java:3867)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.mkdirs(NameNodeRpcServer.java:984)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.mkdirs(ClientNamenodeProtocolServerSideTranslatorPB.java:634)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:616)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:982)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2217)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2213)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1754)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2213)

	at org.apache.hive.jdbc.HiveStatement.execute(HiveStatement.java:296)
	at org.apache.hive.jdbc.HivePreparedStatement.execute(HivePreparedStatement.java:98)
	at com.mchange.v2.c3p0.impl.NewProxyPreparedStatement.execute(NewProxyPreparedStatement.java:67)
	at com.inspur.pmv6.dao.HiveDao.executesql(HiveDao.java:152)
	at com.inspur.pmv6.Entrance.lambda$null$0(Entrance.java:83)
	at java.util.stream.Streams$RangeIntSpliterator.forEachRemaining(Streams.java:110)
	at java.util.stream.IntPipeline$Head.forEach(IntPipeline.java:557)
	at com.inspur.pmv6.Entrance.lambda$myTestCodes$1(Entrance.java:76)
	at java.util.stream.Streams$RangeIntSpliterator.forEachRemaining(Streams.java:110)
	at java.util.stream.IntPipeline$Head.forEach(IntPipeline.java:557)
	at com.inspur.pmv6.Entrance.myTestCodes(Entrance.java:74)
	at com.inspur.pmv6.Entrance.main(Entrance.java:43)
[0328 17:25:34 782 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29uty1ohtdp162j|80ec1f8]-HelperThread-#0] hive.jdbc.Utils - Resolved authority: 10.211.55.29:10000
[0328 17:25:34 783 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29uty1ohtdp162j|80ec1f8]-HelperThread-#0] hive.jdbc.HiveConnection - Will try to open client transport with JDBC Uri: jdbc:hive2://10.211.55.29:10000/default
[0328 17:25:34 783 INFO ] [main] pmv6.dao.HiveDao - start to execute the sql :insert into test_table_double values (20180329, 090000, 50.03030167840444)
[0328 17:25:34 907 ERROR] [main] pmv6.dao.HiveDao - ERROR SQL: insert into test_table_double values (20180329, 090000, 50.03030167840444)
[0328 17:25:34 907 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29uty1ohtdp162j|80ec1f8]-HelperThread-#1] hive.jdbc.Utils - Supplied authorities: 10.211.55.29:10000
[0328 17:25:34 907 ERROR] [main] pmv6.dao.HiveDao - java.lang.RuntimeException: Cannot create staging directory 'hdfs://localhost:9000/home/hive/warehouse/test_table_double/.hive-staging_hive_2018-03-28_02-25-34_824_5779311664349780224-9': Permission denied: user=hive, access=WRITE, inode="/home/hive/warehouse/test_table_double":chen:supergroup:drwxr-xr-x
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.check(FSPermissionChecker.java:308)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:214)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:190)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkPermission(FSDirectory.java:1752)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkPermission(FSDirectory.java:1736)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkAncestorAccess(FSDirectory.java:1719)
	at org.apache.hadoop.hdfs.server.namenode.FSDirMkdirOp.mkdirs(FSDirMkdirOp.java:69)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.mkdirs(FSNamesystem.java:3867)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.mkdirs(NameNodeRpcServer.java:984)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.mkdirs(ClientNamenodeProtocolServerSideTranslatorPB.java:634)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:616)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:982)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2217)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2213)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1754)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2213)

java.sql.SQLException: java.lang.RuntimeException: Cannot create staging directory 'hdfs://localhost:9000/home/hive/warehouse/test_table_double/.hive-staging_hive_2018-03-28_02-25-34_824_5779311664349780224-9': Permission denied: user=hive, access=WRITE, inode="/home/hive/warehouse/test_table_double":chen:supergroup:drwxr-xr-x
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.check(FSPermissionChecker.java:308)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:214)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:190)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkPermission(FSDirectory.java:1752)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkPermission(FSDirectory.java:1736)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkAncestorAccess(FSDirectory.java:1719)
	at org.apache.hadoop.hdfs.server.namenode.FSDirMkdirOp.mkdirs(FSDirMkdirOp.java:69)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.mkdirs(FSNamesystem.java:3867)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.mkdirs(NameNodeRpcServer.java:984)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.mkdirs(ClientNamenodeProtocolServerSideTranslatorPB.java:634)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:616)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:982)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2217)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2213)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1754)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2213)

	at org.apache.hive.jdbc.HiveStatement.execute(HiveStatement.java:296)
	at org.apache.hive.jdbc.HivePreparedStatement.execute(HivePreparedStatement.java:98)
	at com.mchange.v2.c3p0.impl.NewProxyPreparedStatement.execute(NewProxyPreparedStatement.java:67)
	at com.inspur.pmv6.dao.HiveDao.executesql(HiveDao.java:152)
	at com.inspur.pmv6.Entrance.lambda$null$0(Entrance.java:83)
	at java.util.stream.Streams$RangeIntSpliterator.forEachRemaining(Streams.java:110)
	at java.util.stream.IntPipeline$Head.forEach(IntPipeline.java:557)
	at com.inspur.pmv6.Entrance.lambda$myTestCodes$1(Entrance.java:76)
	at java.util.stream.Streams$RangeIntSpliterator.forEachRemaining(Streams.java:110)
	at java.util.stream.IntPipeline$Head.forEach(IntPipeline.java:557)
	at com.inspur.pmv6.Entrance.myTestCodes(Entrance.java:74)
	at com.inspur.pmv6.Entrance.main(Entrance.java:43)
[0328 17:25:34 907 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29uty1ohtdp162j|80ec1f8]-HelperThread-#1] hive.jdbc.Utils - Resolved authority: 10.211.55.29:10000
[0328 17:25:34 908 INFO ] [C3P0PooledConnectionPoolManager[identityToken->1hge0w29uty1ohtdp162j|80ec1f8]-HelperThread-#1] hive.jdbc.HiveConnection - Will try to open client transport with JDBC Uri: jdbc:hive2://10.211.55.29:10000/default
[0328 17:25:34 909 INFO ] [main] pmv6.dao.HiveDao - start to execute the sql :insert into test_table_double values (20180329, 100000, 15.039941545374303)
